{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>pH</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>type</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.4</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.56</td>\n",
       "      <td>34.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>7.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.68</td>\n",
       "      <td>67.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>7.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.26</td>\n",
       "      <td>5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>54.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>11.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.16</td>\n",
       "      <td>6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.58</td>\n",
       "      <td>60.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.4</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.56</td>\n",
       "      <td>34.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  chlorides  citric_acid  density  fixed_acidity  \\\n",
       "0      9.4      0.076         0.00   0.9978            7.4   \n",
       "1      9.8      0.098         0.00   0.9968            7.8   \n",
       "2      9.8      0.092         0.04   0.9970            7.8   \n",
       "3      9.8      0.075         0.56   0.9980           11.2   \n",
       "4      9.4      0.076         0.00   0.9978            7.4   \n",
       "\n",
       "   free_sulfur_dioxide    pH  quality  residual_sugar  sulphates  \\\n",
       "0                 11.0  3.51        5             1.9       0.56   \n",
       "1                 25.0  3.20        5             2.6       0.68   \n",
       "2                 15.0  3.26        5             2.3       0.65   \n",
       "3                 17.0  3.16        6             1.9       0.58   \n",
       "4                 11.0  3.51        5             1.9       0.56   \n",
       "\n",
       "   total_sulfur_dioxide type  volatile_acidity  \n",
       "0                  34.0  red              0.70  \n",
       "1                  67.0  red              0.88  \n",
       "2                  54.0  red              0.76  \n",
       "3                  60.0  red              0.28  \n",
       "4                  34.0  red              0.70  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_qa = pd.read_csv('data/wine-qa.csv')\n",
    "wine_qa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>pH</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.491801</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>0.318633</td>\n",
       "      <td>0.994697</td>\n",
       "      <td>7.215307</td>\n",
       "      <td>30.525319</td>\n",
       "      <td>3.218501</td>\n",
       "      <td>5.818378</td>\n",
       "      <td>5.443235</td>\n",
       "      <td>0.531268</td>\n",
       "      <td>115.744574</td>\n",
       "      <td>0.339666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.192712</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>0.145318</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>1.296434</td>\n",
       "      <td>17.749400</td>\n",
       "      <td>0.160787</td>\n",
       "      <td>0.873255</td>\n",
       "      <td>4.757804</td>\n",
       "      <td>0.148806</td>\n",
       "      <td>56.521855</td>\n",
       "      <td>0.164636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.500000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.300000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.300000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.996990</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.900000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.580000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           alcohol    chlorides  citric_acid      density  fixed_acidity  \\\n",
       "count  6497.000000  6497.000000  6497.000000  6497.000000    6497.000000   \n",
       "mean     10.491801     0.056034     0.318633     0.994697       7.215307   \n",
       "std       1.192712     0.035034     0.145318     0.002999       1.296434   \n",
       "min       8.000000     0.009000     0.000000     0.987110       3.800000   \n",
       "25%       9.500000     0.038000     0.250000     0.992340       6.400000   \n",
       "50%      10.300000     0.047000     0.310000     0.994890       7.000000   \n",
       "75%      11.300000     0.065000     0.390000     0.996990       7.700000   \n",
       "max      14.900000     0.611000     1.660000     1.038980      15.900000   \n",
       "\n",
       "       free_sulfur_dioxide           pH      quality  residual_sugar  \\\n",
       "count          6497.000000  6497.000000  6497.000000     6497.000000   \n",
       "mean             30.525319     3.218501     5.818378        5.443235   \n",
       "std              17.749400     0.160787     0.873255        4.757804   \n",
       "min               1.000000     2.720000     3.000000        0.600000   \n",
       "25%              17.000000     3.110000     5.000000        1.800000   \n",
       "50%              29.000000     3.210000     6.000000        3.000000   \n",
       "75%              41.000000     3.320000     6.000000        8.100000   \n",
       "max             289.000000     4.010000     9.000000       65.800000   \n",
       "\n",
       "         sulphates  total_sulfur_dioxide  volatile_acidity  \n",
       "count  6497.000000           6497.000000       6497.000000  \n",
       "mean      0.531268            115.744574          0.339666  \n",
       "std       0.148806             56.521855          0.164636  \n",
       "min       0.220000              6.000000          0.080000  \n",
       "25%       0.430000             77.000000          0.230000  \n",
       "50%       0.510000            118.000000          0.290000  \n",
       "75%       0.600000            156.000000          0.400000  \n",
       "max       2.000000            440.000000          1.580000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_qa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wine_qa['quality']\n",
    "X = wine_qa.drop(columns=['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.fit(X['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = label_encoder.transform(X['type'])\n",
    "X = X.drop(columns=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "prep = StandardScaler()\n",
    "prep.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.915464</td>\n",
       "      <td>0.569958</td>\n",
       "      <td>-2.192833</td>\n",
       "      <td>1.034993</td>\n",
       "      <td>0.142473</td>\n",
       "      <td>-1.100140</td>\n",
       "      <td>1.813090</td>\n",
       "      <td>-0.744778</td>\n",
       "      <td>0.193097</td>\n",
       "      <td>-1.446359</td>\n",
       "      <td>2.188833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.580068</td>\n",
       "      <td>1.197975</td>\n",
       "      <td>-2.192833</td>\n",
       "      <td>0.701486</td>\n",
       "      <td>0.451036</td>\n",
       "      <td>-0.311320</td>\n",
       "      <td>-0.115073</td>\n",
       "      <td>-0.597640</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>-0.862469</td>\n",
       "      <td>3.282235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.580068</td>\n",
       "      <td>1.026697</td>\n",
       "      <td>-1.917553</td>\n",
       "      <td>0.768188</td>\n",
       "      <td>0.451036</td>\n",
       "      <td>-0.874763</td>\n",
       "      <td>0.258120</td>\n",
       "      <td>-0.660699</td>\n",
       "      <td>0.797958</td>\n",
       "      <td>-1.092486</td>\n",
       "      <td>2.553300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.580068</td>\n",
       "      <td>0.541412</td>\n",
       "      <td>1.661085</td>\n",
       "      <td>1.101694</td>\n",
       "      <td>3.073817</td>\n",
       "      <td>-0.762074</td>\n",
       "      <td>-0.363868</td>\n",
       "      <td>-0.744778</td>\n",
       "      <td>0.327510</td>\n",
       "      <td>-0.986324</td>\n",
       "      <td>-0.362438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.915464</td>\n",
       "      <td>0.569958</td>\n",
       "      <td>-2.192833</td>\n",
       "      <td>1.034993</td>\n",
       "      <td>0.142473</td>\n",
       "      <td>-1.100140</td>\n",
       "      <td>1.813090</td>\n",
       "      <td>-0.744778</td>\n",
       "      <td>0.193097</td>\n",
       "      <td>-1.446359</td>\n",
       "      <td>2.188833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.915464  0.569958 -2.192833  1.034993  0.142473 -1.100140  1.813090   \n",
       "1 -0.580068  1.197975 -2.192833  0.701486  0.451036 -0.311320 -0.115073   \n",
       "2 -0.580068  1.026697 -1.917553  0.768188  0.451036 -0.874763  0.258120   \n",
       "3 -0.580068  0.541412  1.661085  1.101694  3.073817 -0.762074 -0.363868   \n",
       "4 -0.915464  0.569958 -2.192833  1.034993  0.142473 -1.100140  1.813090   \n",
       "\n",
       "          7         8         9        10  type  \n",
       "0 -0.744778  0.193097 -1.446359  2.188833     0  \n",
       "1 -0.597640  0.999579 -0.862469  3.282235     0  \n",
       "2 -0.660699  0.797958 -1.092486  2.553300     0  \n",
       "3 -0.744778  0.327510 -0.986324 -0.362438     0  \n",
       "4 -0.744778  0.193097 -1.446359  2.188833     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trans = pd.DataFrame(prep.transform(X))\n",
    "X_trans['type'] = color\n",
    "X_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trans,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-0.076974</td>\n",
       "      <td>0.370134</td>\n",
       "      <td>-2.192833</td>\n",
       "      <td>-0.245672</td>\n",
       "      <td>-0.474652</td>\n",
       "      <td>-1.494550</td>\n",
       "      <td>0.693511</td>\n",
       "      <td>-0.807837</td>\n",
       "      <td>-1.083833</td>\n",
       "      <td>-1.906393</td>\n",
       "      <td>1.642132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-0.580068</td>\n",
       "      <td>1.768899</td>\n",
       "      <td>1.041706</td>\n",
       "      <td>1.168395</td>\n",
       "      <td>2.842395</td>\n",
       "      <td>-1.381861</td>\n",
       "      <td>0.506915</td>\n",
       "      <td>-0.765798</td>\n",
       "      <td>1.470026</td>\n",
       "      <td>-1.800231</td>\n",
       "      <td>0.305752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>-1.502407</td>\n",
       "      <td>-0.343521</td>\n",
       "      <td>2.074005</td>\n",
       "      <td>0.934941</td>\n",
       "      <td>-0.088949</td>\n",
       "      <td>1.209975</td>\n",
       "      <td>-0.612663</td>\n",
       "      <td>1.336174</td>\n",
       "      <td>-0.478971</td>\n",
       "      <td>0.641490</td>\n",
       "      <td>0.609474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>0.845365</td>\n",
       "      <td>-0.914446</td>\n",
       "      <td>0.559966</td>\n",
       "      <td>-0.632540</td>\n",
       "      <td>-0.011808</td>\n",
       "      <td>1.435352</td>\n",
       "      <td>-1.110254</td>\n",
       "      <td>0.453346</td>\n",
       "      <td>-1.419867</td>\n",
       "      <td>1.083831</td>\n",
       "      <td>-0.301694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>-0.412370</td>\n",
       "      <td>-1.114269</td>\n",
       "      <td>0.009406</td>\n",
       "      <td>-0.405755</td>\n",
       "      <td>-0.397511</td>\n",
       "      <td>0.083090</td>\n",
       "      <td>-0.612663</td>\n",
       "      <td>-0.366423</td>\n",
       "      <td>-0.613385</td>\n",
       "      <td>-0.296272</td>\n",
       "      <td>-1.273607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "1369 -0.076974  0.370134 -2.192833 -0.245672 -0.474652 -1.494550  0.693511   \n",
       "342  -0.580068  1.768899  1.041706  1.168395  2.842395 -1.381861  0.506915   \n",
       "1688 -1.502407 -0.343521  2.074005  0.934941 -0.088949  1.209975 -0.612663   \n",
       "2349  0.845365 -0.914446  0.559966 -0.632540 -0.011808  1.435352 -1.110254   \n",
       "5238 -0.412370 -1.114269  0.009406 -0.405755 -0.397511  0.083090 -0.612663   \n",
       "\n",
       "             7         8         9        10  type  \n",
       "1369 -0.807837 -1.083833 -1.906393  1.642132     0  \n",
       "342  -0.765798  1.470026 -1.800231  0.305752     0  \n",
       "1688  1.336174 -0.478971  0.641490  0.609474     1  \n",
       "2349  0.453346 -1.419867  1.083831 -0.301694     1  \n",
       "5238 -0.366423 -0.613385 -0.296272 -1.273607     1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_shape=(12,),kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 91        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 255\n",
      "Trainable params: 255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 12),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'dense_input'}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 12),\n",
       "    'dtype': 'float32',\n",
       "    'units': 12,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': {'class_name': 'L2',\n",
       "     'config': {'l2': 0.009999999776482582}},\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 7,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.10520744e-01,  2.85707712e-01, -3.99877667e-01,\n",
       "          1.81577206e-02, -3.23844552e-01,  3.12265873e-01,\n",
       "         -4.65228200e-01, -6.82663918e-02,  1.93341851e-01,\n",
       "          9.50884819e-02,  5.94103336e-03, -1.81459427e-01],\n",
       "        [-1.08848691e-01,  1.66613698e-01,  2.43338346e-02,\n",
       "          4.25999284e-01, -2.93905735e-01,  3.05199146e-01,\n",
       "         -1.08429790e-01,  2.11684346e-01,  2.99996972e-01,\n",
       "          2.27087498e-01, -3.42893600e-01,  5.75900078e-03],\n",
       "        [-3.47257853e-02, -3.79054785e-01,  4.37046289e-02,\n",
       "          1.48160100e-01,  3.47066164e-01,  3.23179603e-01,\n",
       "          3.34020257e-01, -3.47297072e-01, -5.71887493e-02,\n",
       "          3.46008420e-01,  2.58013248e-01,  3.76356840e-01],\n",
       "        [-4.37344790e-01, -4.86390948e-01, -2.51067638e-01,\n",
       "         -3.16718102e-01, -3.13313007e-01,  4.26860809e-01,\n",
       "          4.31985378e-01, -1.49663925e-01,  3.96862030e-01,\n",
       "          2.16537595e-01, -4.69577312e-03, -1.30688190e-01],\n",
       "        [-2.68605232e-01, -2.84691334e-01,  2.66671181e-04,\n",
       "         -5.73844910e-02,  1.51833177e-01,  3.18428993e-01,\n",
       "          2.37542868e-01,  2.45600939e-02, -4.28411484e-01,\n",
       "          1.36902452e-01, -2.93958783e-01, -4.97033000e-01],\n",
       "        [-2.93148875e-01, -7.13787079e-02,  2.09477901e-01,\n",
       "         -4.97662544e-01,  6.11151457e-02, -1.23950005e-01,\n",
       "          1.71927094e-01,  3.42234373e-02,  4.09767866e-01,\n",
       "          4.58289385e-02, -2.40450740e-01,  1.50135875e-01],\n",
       "        [ 3.57606411e-02, -1.69299006e-01, -1.69553518e-01,\n",
       "          2.88469315e-01,  3.51280451e-01, -2.96772480e-01,\n",
       "         -4.66156840e-01,  1.86664104e-01,  2.98489571e-01,\n",
       "         -1.36833429e-01, -4.11251664e-01,  1.06629014e-01],\n",
       "        [ 1.18045568e-01,  2.79143810e-01,  1.87487602e-02,\n",
       "         -1.96402192e-01,  4.76379871e-01,  1.24196529e-01,\n",
       "         -2.21647024e-01, -2.56114006e-02,  5.29571772e-02,\n",
       "         -2.60055423e-01, -3.47514153e-01, -1.89198256e-02],\n",
       "        [ 3.97277474e-01,  1.28731728e-02,  2.47739792e-01,\n",
       "          2.25745678e-01, -5.65594435e-02,  4.92639780e-01,\n",
       "          9.54596996e-02,  1.12867951e-01, -3.46659780e-01,\n",
       "          4.05677915e-01, -2.64022350e-02, -4.06094074e-01],\n",
       "        [ 1.34297967e-01, -2.03372121e-01,  4.90634680e-01,\n",
       "          3.81730437e-01,  7.87453651e-02,  2.39107370e-01,\n",
       "         -2.62549520e-01,  4.32870030e-01,  2.88046479e-01,\n",
       "          6.48181438e-02, -2.99271941e-01,  3.72567177e-02],\n",
       "        [-2.39883065e-01,  1.02199912e-01, -4.48437214e-01,\n",
       "          6.15273714e-02, -4.05539870e-01,  1.13214254e-01,\n",
       "          3.43077540e-01, -3.13587189e-02, -3.83539438e-01,\n",
       "         -2.13181615e-01,  3.05040121e-01,  4.53004003e-01],\n",
       "        [-4.05437946e-01, -2.61256218e-01, -1.36063814e-01,\n",
       "         -1.07811689e-01,  2.23668575e-01,  4.01189923e-01,\n",
       "         -9.77331400e-02, -2.19724536e-01, -7.40298033e-02,\n",
       "         -3.31137061e-01,  4.17297482e-01, -2.33386993e-01]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.4193498 , -0.16388622,  0.5255881 ,  0.21291363, -0.51405776,\n",
       "         -0.46232563, -0.00187546],\n",
       "        [ 0.41693497, -0.2829881 ,  0.33281422,  0.21467   , -0.27865547,\n",
       "          0.38596797, -0.35672355],\n",
       "        [-0.14826685,  0.35169262, -0.27996096,  0.00489426,  0.02976495,\n",
       "          0.17222923,  0.24007887],\n",
       "        [ 0.34697586, -0.33855307,  0.18077004, -0.15875223,  0.0311799 ,\n",
       "          0.33648902,  0.44986218],\n",
       "        [ 0.06779128, -0.20067945,  0.0366444 ,  0.39755815, -0.15835714,\n",
       "          0.11157227,  0.35031366],\n",
       "        [-0.12192807,  0.3675807 , -0.35381564,  0.2709279 ,  0.21643502,\n",
       "          0.08614236,  0.0278458 ],\n",
       "        [ 0.33884972,  0.12259567, -0.51341265, -0.35343045, -0.50316495,\n",
       "         -0.01550764, -0.3324491 ],\n",
       "        [ 0.06302524, -0.40528154, -0.47343847, -0.3795612 ,  0.05440259,\n",
       "          0.14360636, -0.25067234],\n",
       "        [ 0.1826365 , -0.13095227, -0.29026   ,  0.11721128,  0.02096581,\n",
       "          0.23286027,  0.49954456],\n",
       "        [-0.06106836,  0.34988457, -0.3862477 ,  0.11940324,  0.26037514,\n",
       "          0.24529964,  0.08637106],\n",
       "        [ 0.40348256,  0.43507743, -0.03234911, -0.4635895 ,  0.09797037,\n",
       "         -0.12084484,  0.39035487],\n",
       "        [ 0.2589605 , -0.00062138, -0.14611006, -0.14144689, -0.17386541,\n",
       "          0.31656998,  0.10699898]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.43144575],\n",
       "        [ 0.5387425 ],\n",
       "        [-0.591118  ],\n",
       "        [ 0.5138474 ],\n",
       "        [ 0.5717346 ],\n",
       "        [-0.26628578],\n",
       "        [ 0.74219114]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg, bs = model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg.shape # 1 weight per input per neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.43144575]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg[:1,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.shape # 1 bias per neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-0.076974</td>\n",
       "      <td>0.370134</td>\n",
       "      <td>-2.192833</td>\n",
       "      <td>-0.245672</td>\n",
       "      <td>-0.474652</td>\n",
       "      <td>-1.494550</td>\n",
       "      <td>0.693511</td>\n",
       "      <td>-0.807837</td>\n",
       "      <td>-1.083833</td>\n",
       "      <td>-1.906393</td>\n",
       "      <td>1.642132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-0.580068</td>\n",
       "      <td>1.768899</td>\n",
       "      <td>1.041706</td>\n",
       "      <td>1.168395</td>\n",
       "      <td>2.842395</td>\n",
       "      <td>-1.381861</td>\n",
       "      <td>0.506915</td>\n",
       "      <td>-0.765798</td>\n",
       "      <td>1.470026</td>\n",
       "      <td>-1.800231</td>\n",
       "      <td>0.305752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>-1.502407</td>\n",
       "      <td>-0.343521</td>\n",
       "      <td>2.074005</td>\n",
       "      <td>0.934941</td>\n",
       "      <td>-0.088949</td>\n",
       "      <td>1.209975</td>\n",
       "      <td>-0.612663</td>\n",
       "      <td>1.336174</td>\n",
       "      <td>-0.478971</td>\n",
       "      <td>0.641490</td>\n",
       "      <td>0.609474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>0.845365</td>\n",
       "      <td>-0.914446</td>\n",
       "      <td>0.559966</td>\n",
       "      <td>-0.632540</td>\n",
       "      <td>-0.011808</td>\n",
       "      <td>1.435352</td>\n",
       "      <td>-1.110254</td>\n",
       "      <td>0.453346</td>\n",
       "      <td>-1.419867</td>\n",
       "      <td>1.083831</td>\n",
       "      <td>-0.301694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>-0.412370</td>\n",
       "      <td>-1.114269</td>\n",
       "      <td>0.009406</td>\n",
       "      <td>-0.405755</td>\n",
       "      <td>-0.397511</td>\n",
       "      <td>0.083090</td>\n",
       "      <td>-0.612663</td>\n",
       "      <td>-0.366423</td>\n",
       "      <td>-0.613385</td>\n",
       "      <td>-0.296272</td>\n",
       "      <td>-1.273607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "1369 -0.076974  0.370134 -2.192833 -0.245672 -0.474652 -1.494550  0.693511   \n",
       "342  -0.580068  1.768899  1.041706  1.168395  2.842395 -1.381861  0.506915   \n",
       "1688 -1.502407 -0.343521  2.074005  0.934941 -0.088949  1.209975 -0.612663   \n",
       "2349  0.845365 -0.914446  0.559966 -0.632540 -0.011808  1.435352 -1.110254   \n",
       "5238 -0.412370 -1.114269  0.009406 -0.405755 -0.397511  0.083090 -0.612663   \n",
       "\n",
       "             7         8         9        10  type  \n",
       "1369 -0.807837 -1.083833 -1.906393  1.642132     0  \n",
       "342  -0.765798  1.470026 -1.800231  0.305752     0  \n",
       "1688  1.336174 -0.478971  0.641490  0.609474     1  \n",
       "2349  0.453346 -1.419867  1.083831 -0.301694     1  \n",
       "5238 -0.366423 -0.613385 -0.296272 -1.273607     1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>-0.010017</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>-0.020659</td>\n",
       "      <td>0.009337</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.004912</td>\n",
       "      <td>-0.016029</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>0.749795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.998592</td>\n",
       "      <td>1.015484</td>\n",
       "      <td>0.998050</td>\n",
       "      <td>0.984149</td>\n",
       "      <td>1.005451</td>\n",
       "      <td>0.979858</td>\n",
       "      <td>1.005730</td>\n",
       "      <td>0.990776</td>\n",
       "      <td>1.006323</td>\n",
       "      <td>1.000881</td>\n",
       "      <td>1.008327</td>\n",
       "      <td>0.433176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.089350</td>\n",
       "      <td>-1.257000</td>\n",
       "      <td>-2.192833</td>\n",
       "      <td>-2.530192</td>\n",
       "      <td>-2.557448</td>\n",
       "      <td>-1.663583</td>\n",
       "      <td>-2.976217</td>\n",
       "      <td>-1.018034</td>\n",
       "      <td>-2.091935</td>\n",
       "      <td>-1.941780</td>\n",
       "      <td>-1.577330</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.831615</td>\n",
       "      <td>-0.514799</td>\n",
       "      <td>-0.541153</td>\n",
       "      <td>-0.782618</td>\n",
       "      <td>-0.628933</td>\n",
       "      <td>-0.762074</td>\n",
       "      <td>-0.674862</td>\n",
       "      <td>-0.765798</td>\n",
       "      <td>-0.680592</td>\n",
       "      <td>-0.703226</td>\n",
       "      <td>-0.666161</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.160823</td>\n",
       "      <td>-0.257883</td>\n",
       "      <td>-0.059414</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>-0.166089</td>\n",
       "      <td>-0.142287</td>\n",
       "      <td>-0.052874</td>\n",
       "      <td>-0.513561</td>\n",
       "      <td>-0.142937</td>\n",
       "      <td>0.022213</td>\n",
       "      <td>-0.301694</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.677667</td>\n",
       "      <td>0.255949</td>\n",
       "      <td>0.491146</td>\n",
       "      <td>0.742341</td>\n",
       "      <td>0.373895</td>\n",
       "      <td>0.590188</td>\n",
       "      <td>0.631312</td>\n",
       "      <td>0.558444</td>\n",
       "      <td>0.461924</td>\n",
       "      <td>0.694571</td>\n",
       "      <td>0.427241</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.696231</td>\n",
       "      <td>15.842187</td>\n",
       "      <td>9.231281</td>\n",
       "      <td>5.203824</td>\n",
       "      <td>6.699425</td>\n",
       "      <td>6.534509</td>\n",
       "      <td>4.923029</td>\n",
       "      <td>5.498078</td>\n",
       "      <td>9.870879</td>\n",
       "      <td>4.038668</td>\n",
       "      <td>6.015740</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  4872.000000  4872.000000  4872.000000  4872.000000  4872.000000   \n",
       "mean      0.003266     0.002244    -0.010017     0.004833     0.001373   \n",
       "std       0.998592     1.015484     0.998050     0.984149     1.005451   \n",
       "min      -2.089350    -1.257000    -2.192833    -2.530192    -2.557448   \n",
       "25%      -0.831615    -0.514799    -0.541153    -0.782618    -0.628933   \n",
       "50%      -0.160823    -0.257883    -0.059414     0.067824    -0.166089   \n",
       "75%       0.677667     0.255949     0.491146     0.742341     0.373895   \n",
       "max       3.696231    15.842187     9.231281     5.203824     6.699425   \n",
       "\n",
       "                 5            6            7            8            9  \\\n",
       "count  4872.000000  4872.000000  4872.000000  4872.000000  4872.000000   \n",
       "mean     -0.020659     0.009337     0.000820     0.004912    -0.016029   \n",
       "std       0.979858     1.005730     0.990776     1.006323     1.000881   \n",
       "min      -1.663583    -2.976217    -1.018034    -2.091935    -1.941780   \n",
       "25%      -0.762074    -0.674862    -0.765798    -0.680592    -0.703226   \n",
       "50%      -0.142287    -0.052874    -0.513561    -0.142937     0.022213   \n",
       "75%       0.590188     0.631312     0.558444     0.461924     0.694571   \n",
       "max       6.534509     4.923029     5.498078     9.870879     4.038668   \n",
       "\n",
       "                10         type  \n",
       "count  4872.000000  4872.000000  \n",
       "mean      0.007147     0.749795  \n",
       "std       1.008327     0.433176  \n",
       "min      -1.577330     0.000000  \n",
       "25%      -0.666161     0.000000  \n",
       "50%      -0.301694     1.000000  \n",
       "75%       0.427241     1.000000  \n",
       "max       6.015740     1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= 'mse',\n",
    "              optimizer= 'adam',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "39/39 - 0s - loss: 26.3196 - mae: 4.9872 - val_loss: 22.0174 - val_mae: 4.4753\n",
      "Epoch 2/200\n",
      "39/39 - 0s - loss: 18.0603 - mae: 3.9687 - val_loss: 13.7975 - val_mae: 3.3544\n",
      "Epoch 3/200\n",
      "39/39 - 0s - loss: 10.5973 - mae: 2.8565 - val_loss: 7.6586 - val_mae: 2.3446\n",
      "Epoch 4/200\n",
      "39/39 - 0s - loss: 5.5850 - mae: 1.9363 - val_loss: 4.2208 - val_mae: 1.6154\n",
      "Epoch 5/200\n",
      "39/39 - 0s - loss: 3.1563 - mae: 1.3599 - val_loss: 2.9159 - val_mae: 1.2806\n",
      "Epoch 6/200\n",
      "39/39 - 0s - loss: 2.3512 - mae: 1.1512 - val_loss: 2.4729 - val_mae: 1.1688\n",
      "Epoch 7/200\n",
      "39/39 - 0s - loss: 2.0215 - mae: 1.0704 - val_loss: 2.2359 - val_mae: 1.1120\n",
      "Epoch 8/200\n",
      "39/39 - 0s - loss: 1.8334 - mae: 1.0187 - val_loss: 2.0689 - val_mae: 1.0639\n",
      "Epoch 9/200\n",
      "39/39 - 0s - loss: 1.6968 - mae: 0.9785 - val_loss: 1.9386 - val_mae: 1.0281\n",
      "Epoch 10/200\n",
      "39/39 - 0s - loss: 1.5876 - mae: 0.9463 - val_loss: 1.8235 - val_mae: 0.9959\n",
      "Epoch 11/200\n",
      "39/39 - 0s - loss: 1.4937 - mae: 0.9152 - val_loss: 1.7231 - val_mae: 0.9641\n",
      "Epoch 12/200\n",
      "39/39 - 0s - loss: 1.4092 - mae: 0.8871 - val_loss: 1.6295 - val_mae: 0.9362\n",
      "Epoch 13/200\n",
      "39/39 - 0s - loss: 1.3352 - mae: 0.8612 - val_loss: 1.5425 - val_mae: 0.9102\n",
      "Epoch 14/200\n",
      "39/39 - 0s - loss: 1.2676 - mae: 0.8371 - val_loss: 1.4618 - val_mae: 0.8836\n",
      "Epoch 15/200\n",
      "39/39 - 0s - loss: 1.2067 - mae: 0.8145 - val_loss: 1.3910 - val_mae: 0.8608\n",
      "Epoch 16/200\n",
      "39/39 - 0s - loss: 1.1540 - mae: 0.7953 - val_loss: 1.3222 - val_mae: 0.8359\n",
      "Epoch 17/200\n",
      "39/39 - 0s - loss: 1.1077 - mae: 0.7763 - val_loss: 1.2637 - val_mae: 0.8165\n",
      "Epoch 18/200\n",
      "39/39 - 0s - loss: 1.0650 - mae: 0.7604 - val_loss: 1.2111 - val_mae: 0.7976\n",
      "Epoch 19/200\n",
      "39/39 - 0s - loss: 1.0262 - mae: 0.7444 - val_loss: 1.1636 - val_mae: 0.7790\n",
      "Epoch 20/200\n",
      "39/39 - 0s - loss: 0.9916 - mae: 0.7298 - val_loss: 1.1234 - val_mae: 0.7631\n",
      "Epoch 21/200\n",
      "39/39 - 0s - loss: 0.9605 - mae: 0.7165 - val_loss: 1.0817 - val_mae: 0.7480\n",
      "Epoch 22/200\n",
      "39/39 - 0s - loss: 0.9298 - mae: 0.7039 - val_loss: 1.0459 - val_mae: 0.7348\n",
      "Epoch 23/200\n",
      "39/39 - 0s - loss: 0.9094 - mae: 0.6952 - val_loss: 1.0144 - val_mae: 0.7215\n",
      "Epoch 24/200\n",
      "39/39 - 0s - loss: 0.8824 - mae: 0.6826 - val_loss: 0.9889 - val_mae: 0.7116\n",
      "Epoch 25/200\n",
      "39/39 - 0s - loss: 0.8621 - mae: 0.6749 - val_loss: 0.9626 - val_mae: 0.6997\n",
      "Epoch 26/200\n",
      "39/39 - 0s - loss: 0.8438 - mae: 0.6662 - val_loss: 0.9415 - val_mae: 0.6915\n",
      "Epoch 27/200\n",
      "39/39 - 0s - loss: 0.8294 - mae: 0.6612 - val_loss: 0.9169 - val_mae: 0.6812\n",
      "Epoch 28/200\n",
      "39/39 - 0s - loss: 0.8130 - mae: 0.6538 - val_loss: 0.9038 - val_mae: 0.6759\n",
      "Epoch 29/200\n",
      "39/39 - 0s - loss: 0.7991 - mae: 0.6479 - val_loss: 0.8855 - val_mae: 0.6684\n",
      "Epoch 30/200\n",
      "39/39 - 0s - loss: 0.7876 - mae: 0.6422 - val_loss: 0.8718 - val_mae: 0.6632\n",
      "Epoch 31/200\n",
      "39/39 - 0s - loss: 0.7760 - mae: 0.6391 - val_loss: 0.8588 - val_mae: 0.6581\n",
      "Epoch 32/200\n",
      "39/39 - 0s - loss: 0.7657 - mae: 0.6337 - val_loss: 0.8440 - val_mae: 0.6527\n",
      "Epoch 33/200\n",
      "39/39 - 0s - loss: 0.7545 - mae: 0.6286 - val_loss: 0.8333 - val_mae: 0.6485\n",
      "Epoch 34/200\n",
      "39/39 - 0s - loss: 0.7452 - mae: 0.6259 - val_loss: 0.8224 - val_mae: 0.6444\n",
      "Epoch 35/200\n",
      "39/39 - 0s - loss: 0.7360 - mae: 0.6224 - val_loss: 0.8095 - val_mae: 0.6388\n",
      "Epoch 36/200\n",
      "39/39 - 0s - loss: 0.7290 - mae: 0.6189 - val_loss: 0.8006 - val_mae: 0.6355\n",
      "Epoch 37/200\n",
      "39/39 - 0s - loss: 0.7206 - mae: 0.6161 - val_loss: 0.7884 - val_mae: 0.6313\n",
      "Epoch 38/200\n",
      "39/39 - 0s - loss: 0.7131 - mae: 0.6120 - val_loss: 0.7837 - val_mae: 0.6292\n",
      "Epoch 39/200\n",
      "39/39 - 0s - loss: 0.7068 - mae: 0.6103 - val_loss: 0.7794 - val_mae: 0.6284\n",
      "Epoch 40/200\n",
      "39/39 - 0s - loss: 0.7043 - mae: 0.6111 - val_loss: 0.7622 - val_mae: 0.6203\n",
      "Epoch 41/200\n",
      "39/39 - 0s - loss: 0.6905 - mae: 0.6038 - val_loss: 0.7592 - val_mae: 0.6198\n",
      "Epoch 42/200\n",
      "39/39 - 0s - loss: 0.6863 - mae: 0.6019 - val_loss: 0.7571 - val_mae: 0.6192\n",
      "Epoch 43/200\n",
      "39/39 - 0s - loss: 0.6790 - mae: 0.5995 - val_loss: 0.7422 - val_mae: 0.6133\n",
      "Epoch 44/200\n",
      "39/39 - 0s - loss: 0.6735 - mae: 0.5977 - val_loss: 0.7416 - val_mae: 0.6135\n",
      "Epoch 45/200\n",
      "39/39 - 0s - loss: 0.6660 - mae: 0.5943 - val_loss: 0.7345 - val_mae: 0.6106\n",
      "Epoch 46/200\n",
      "39/39 - 0s - loss: 0.6604 - mae: 0.5916 - val_loss: 0.7239 - val_mae: 0.6065\n",
      "Epoch 47/200\n",
      "39/39 - 0s - loss: 0.6549 - mae: 0.5905 - val_loss: 0.7174 - val_mae: 0.6040\n",
      "Epoch 48/200\n",
      "39/39 - 0s - loss: 0.6507 - mae: 0.5882 - val_loss: 0.7153 - val_mae: 0.6034\n",
      "Epoch 49/200\n",
      "39/39 - 0s - loss: 0.6459 - mae: 0.5871 - val_loss: 0.7048 - val_mae: 0.5985\n",
      "Epoch 50/200\n",
      "39/39 - 0s - loss: 0.6412 - mae: 0.5844 - val_loss: 0.7018 - val_mae: 0.5974\n",
      "Epoch 51/200\n",
      "39/39 - 0s - loss: 0.6361 - mae: 0.5829 - val_loss: 0.6980 - val_mae: 0.5963\n",
      "Epoch 52/200\n",
      "39/39 - 0s - loss: 0.6304 - mae: 0.5797 - val_loss: 0.6903 - val_mae: 0.5939\n",
      "Epoch 53/200\n",
      "39/39 - 0s - loss: 0.6269 - mae: 0.5778 - val_loss: 0.6898 - val_mae: 0.5939\n",
      "Epoch 54/200\n",
      "39/39 - 0s - loss: 0.6219 - mae: 0.5767 - val_loss: 0.6786 - val_mae: 0.5888\n",
      "Epoch 55/200\n",
      "39/39 - 0s - loss: 0.6180 - mae: 0.5746 - val_loss: 0.6814 - val_mae: 0.5903\n",
      "Epoch 56/200\n",
      "39/39 - 0s - loss: 0.6120 - mae: 0.5727 - val_loss: 0.6749 - val_mae: 0.5874\n",
      "Epoch 57/200\n",
      "39/39 - 0s - loss: 0.6120 - mae: 0.5743 - val_loss: 0.6666 - val_mae: 0.5846\n",
      "Epoch 58/200\n",
      "39/39 - 0s - loss: 0.6056 - mae: 0.5696 - val_loss: 0.6668 - val_mae: 0.5858\n",
      "Epoch 59/200\n",
      "39/39 - 0s - loss: 0.6010 - mae: 0.5680 - val_loss: 0.6583 - val_mae: 0.5819\n",
      "Epoch 60/200\n",
      "39/39 - 0s - loss: 0.5972 - mae: 0.5666 - val_loss: 0.6525 - val_mae: 0.5794\n",
      "Epoch 61/200\n",
      "39/39 - 0s - loss: 0.5940 - mae: 0.5645 - val_loss: 0.6521 - val_mae: 0.5805\n",
      "Epoch 62/200\n",
      "39/39 - 0s - loss: 0.5926 - mae: 0.5654 - val_loss: 0.6449 - val_mae: 0.5758\n",
      "Epoch 63/200\n",
      "39/39 - 0s - loss: 0.5875 - mae: 0.5619 - val_loss: 0.6475 - val_mae: 0.5793\n",
      "Epoch 64/200\n",
      "39/39 - 0s - loss: 0.5846 - mae: 0.5616 - val_loss: 0.6386 - val_mae: 0.5738\n",
      "Epoch 65/200\n",
      "39/39 - 0s - loss: 0.5810 - mae: 0.5599 - val_loss: 0.6341 - val_mae: 0.5724\n",
      "Epoch 66/200\n",
      "39/39 - 0s - loss: 0.5798 - mae: 0.5590 - val_loss: 0.6330 - val_mae: 0.5722\n",
      "Epoch 67/200\n",
      "39/39 - 0s - loss: 0.5743 - mae: 0.5566 - val_loss: 0.6300 - val_mae: 0.5710\n",
      "Epoch 68/200\n",
      "39/39 - 0s - loss: 0.5744 - mae: 0.5572 - val_loss: 0.6177 - val_mae: 0.5656\n",
      "Epoch 69/200\n",
      "39/39 - 0s - loss: 0.5819 - mae: 0.5606 - val_loss: 0.6148 - val_mae: 0.5662\n",
      "Epoch 70/200\n",
      "39/39 - 0s - loss: 0.5671 - mae: 0.5546 - val_loss: 0.6151 - val_mae: 0.5670\n",
      "Epoch 71/200\n",
      "39/39 - 0s - loss: 0.5657 - mae: 0.5541 - val_loss: 0.6114 - val_mae: 0.5645\n",
      "Epoch 72/200\n",
      "39/39 - 0s - loss: 0.5619 - mae: 0.5520 - val_loss: 0.6073 - val_mae: 0.5627\n",
      "Epoch 73/200\n",
      "39/39 - 0s - loss: 0.5604 - mae: 0.5509 - val_loss: 0.6091 - val_mae: 0.5659\n",
      "Epoch 74/200\n",
      "39/39 - 0s - loss: 0.5569 - mae: 0.5504 - val_loss: 0.6045 - val_mae: 0.5620\n",
      "Epoch 75/200\n",
      "39/39 - 0s - loss: 0.5543 - mae: 0.5488 - val_loss: 0.6025 - val_mae: 0.5607\n",
      "Epoch 76/200\n",
      "39/39 - 0s - loss: 0.5520 - mae: 0.5478 - val_loss: 0.5999 - val_mae: 0.5595\n",
      "Epoch 77/200\n",
      "39/39 - 0s - loss: 0.5525 - mae: 0.5487 - val_loss: 0.5964 - val_mae: 0.5595\n",
      "Epoch 78/200\n",
      "39/39 - 0s - loss: 0.5487 - mae: 0.5469 - val_loss: 0.5926 - val_mae: 0.5563\n",
      "Epoch 79/200\n",
      "39/39 - 0s - loss: 0.5484 - mae: 0.5462 - val_loss: 0.5928 - val_mae: 0.5580\n",
      "Epoch 80/200\n",
      "39/39 - 0s - loss: 0.5457 - mae: 0.5457 - val_loss: 0.5888 - val_mae: 0.5561\n",
      "Epoch 81/200\n",
      "39/39 - 0s - loss: 0.5439 - mae: 0.5455 - val_loss: 0.5885 - val_mae: 0.5562\n",
      "Epoch 82/200\n",
      "39/39 - 0s - loss: 0.5428 - mae: 0.5450 - val_loss: 0.5867 - val_mae: 0.5557\n",
      "Epoch 83/200\n",
      "39/39 - 0s - loss: 0.5401 - mae: 0.5435 - val_loss: 0.5835 - val_mae: 0.5543\n",
      "Epoch 84/200\n",
      "39/39 - 0s - loss: 0.5381 - mae: 0.5424 - val_loss: 0.5839 - val_mae: 0.5548\n",
      "Epoch 85/200\n",
      "39/39 - 0s - loss: 0.5361 - mae: 0.5417 - val_loss: 0.5820 - val_mae: 0.5534\n",
      "Epoch 86/200\n",
      "39/39 - 0s - loss: 0.5349 - mae: 0.5416 - val_loss: 0.5864 - val_mae: 0.5560\n",
      "Epoch 87/200\n",
      "39/39 - 0s - loss: 0.5336 - mae: 0.5405 - val_loss: 0.5791 - val_mae: 0.5529\n",
      "Epoch 88/200\n",
      "39/39 - 0s - loss: 0.5335 - mae: 0.5408 - val_loss: 0.5797 - val_mae: 0.5552\n",
      "Epoch 89/200\n",
      "39/39 - 0s - loss: 0.5309 - mae: 0.5400 - val_loss: 0.5805 - val_mae: 0.5549\n",
      "Epoch 90/200\n",
      "39/39 - 0s - loss: 0.5301 - mae: 0.5404 - val_loss: 0.5784 - val_mae: 0.5547\n",
      "Epoch 91/200\n",
      "39/39 - 0s - loss: 0.5274 - mae: 0.5379 - val_loss: 0.5825 - val_mae: 0.5569\n",
      "Epoch 92/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 - 0s - loss: 0.5276 - mae: 0.5400 - val_loss: 0.5744 - val_mae: 0.5545\n",
      "Epoch 93/200\n",
      "39/39 - 0s - loss: 0.5289 - mae: 0.5398 - val_loss: 0.5720 - val_mae: 0.5517\n",
      "Epoch 94/200\n",
      "39/39 - 0s - loss: 0.5266 - mae: 0.5394 - val_loss: 0.5706 - val_mae: 0.5509\n",
      "Epoch 95/200\n",
      "39/39 - 0s - loss: 0.5241 - mae: 0.5378 - val_loss: 0.5688 - val_mae: 0.5495\n",
      "Epoch 96/200\n",
      "39/39 - 0s - loss: 0.5241 - mae: 0.5384 - val_loss: 0.5720 - val_mae: 0.5547\n",
      "Epoch 97/200\n",
      "39/39 - 0s - loss: 0.5220 - mae: 0.5380 - val_loss: 0.5671 - val_mae: 0.5509\n",
      "Epoch 98/200\n",
      "39/39 - 0s - loss: 0.5195 - mae: 0.5364 - val_loss: 0.5694 - val_mae: 0.5499\n",
      "Epoch 99/200\n",
      "39/39 - 0s - loss: 0.5198 - mae: 0.5366 - val_loss: 0.5632 - val_mae: 0.5477\n",
      "Epoch 100/200\n",
      "39/39 - 0s - loss: 0.5179 - mae: 0.5363 - val_loss: 0.5671 - val_mae: 0.5507\n",
      "Epoch 101/200\n",
      "39/39 - 0s - loss: 0.5183 - mae: 0.5359 - val_loss: 0.5632 - val_mae: 0.5501\n",
      "Epoch 102/200\n",
      "39/39 - 0s - loss: 0.5172 - mae: 0.5356 - val_loss: 0.5641 - val_mae: 0.5517\n",
      "Epoch 103/200\n",
      "39/39 - 0s - loss: 0.5179 - mae: 0.5373 - val_loss: 0.5649 - val_mae: 0.5527\n",
      "Epoch 104/200\n",
      "39/39 - 0s - loss: 0.5163 - mae: 0.5367 - val_loss: 0.5604 - val_mae: 0.5483\n",
      "Epoch 105/200\n",
      "39/39 - 0s - loss: 0.5165 - mae: 0.5364 - val_loss: 0.5572 - val_mae: 0.5473\n",
      "Epoch 106/200\n",
      "39/39 - 0s - loss: 0.5151 - mae: 0.5368 - val_loss: 0.5591 - val_mae: 0.5482\n",
      "Epoch 107/200\n",
      "39/39 - 0s - loss: 0.5145 - mae: 0.5355 - val_loss: 0.5559 - val_mae: 0.5467\n",
      "Epoch 108/200\n",
      "39/39 - 0s - loss: 0.5126 - mae: 0.5351 - val_loss: 0.5544 - val_mae: 0.5459\n",
      "Epoch 109/200\n",
      "39/39 - 0s - loss: 0.5108 - mae: 0.5345 - val_loss: 0.5553 - val_mae: 0.5456\n",
      "Epoch 110/200\n",
      "39/39 - 0s - loss: 0.5093 - mae: 0.5339 - val_loss: 0.5526 - val_mae: 0.5459\n",
      "Epoch 111/200\n",
      "39/39 - 0s - loss: 0.5079 - mae: 0.5338 - val_loss: 0.5526 - val_mae: 0.5454\n",
      "Epoch 112/200\n",
      "39/39 - 0s - loss: 0.5111 - mae: 0.5346 - val_loss: 0.5514 - val_mae: 0.5458\n",
      "Epoch 113/200\n",
      "39/39 - 0s - loss: 0.5088 - mae: 0.5337 - val_loss: 0.5512 - val_mae: 0.5451\n",
      "Epoch 114/200\n",
      "39/39 - 0s - loss: 0.5076 - mae: 0.5331 - val_loss: 0.5498 - val_mae: 0.5445\n",
      "Epoch 115/200\n",
      "39/39 - 0s - loss: 0.5079 - mae: 0.5341 - val_loss: 0.5488 - val_mae: 0.5463\n",
      "Epoch 116/200\n",
      "39/39 - 0s - loss: 0.5069 - mae: 0.5330 - val_loss: 0.5501 - val_mae: 0.5460\n",
      "Epoch 117/200\n",
      "39/39 - 0s - loss: 0.5102 - mae: 0.5360 - val_loss: 0.5475 - val_mae: 0.5450\n",
      "Epoch 118/200\n",
      "39/39 - 0s - loss: 0.5063 - mae: 0.5333 - val_loss: 0.5461 - val_mae: 0.5456\n",
      "Epoch 119/200\n",
      "39/39 - 0s - loss: 0.5043 - mae: 0.5345 - val_loss: 0.5468 - val_mae: 0.5451\n",
      "Epoch 120/200\n",
      "39/39 - 0s - loss: 0.5029 - mae: 0.5316 - val_loss: 0.5482 - val_mae: 0.5447\n",
      "Epoch 121/200\n",
      "39/39 - 0s - loss: 0.5027 - mae: 0.5326 - val_loss: 0.5414 - val_mae: 0.5428\n",
      "Epoch 122/200\n",
      "39/39 - 0s - loss: 0.5044 - mae: 0.5331 - val_loss: 0.5430 - val_mae: 0.5449\n",
      "Epoch 123/200\n",
      "39/39 - 0s - loss: 0.5004 - mae: 0.5313 - val_loss: 0.5479 - val_mae: 0.5482\n",
      "Epoch 124/200\n",
      "39/39 - 0s - loss: 0.5015 - mae: 0.5320 - val_loss: 0.5434 - val_mae: 0.5454\n",
      "Epoch 125/200\n",
      "39/39 - 0s - loss: 0.5010 - mae: 0.5328 - val_loss: 0.5427 - val_mae: 0.5433\n",
      "Epoch 126/200\n",
      "39/39 - 0s - loss: 0.4990 - mae: 0.5311 - val_loss: 0.5422 - val_mae: 0.5429\n",
      "Epoch 127/200\n",
      "39/39 - 0s - loss: 0.4982 - mae: 0.5306 - val_loss: 0.5419 - val_mae: 0.5450\n",
      "Epoch 128/200\n",
      "39/39 - 0s - loss: 0.4983 - mae: 0.5317 - val_loss: 0.5438 - val_mae: 0.5487\n",
      "Epoch 129/200\n",
      "39/39 - 0s - loss: 0.4988 - mae: 0.5314 - val_loss: 0.5397 - val_mae: 0.5435\n",
      "Epoch 130/200\n",
      "39/39 - 0s - loss: 0.4987 - mae: 0.5329 - val_loss: 0.5376 - val_mae: 0.5440\n",
      "Epoch 131/200\n",
      "39/39 - 0s - loss: 0.4958 - mae: 0.5305 - val_loss: 0.5447 - val_mae: 0.5466\n",
      "Epoch 132/200\n",
      "39/39 - 0s - loss: 0.4970 - mae: 0.5319 - val_loss: 0.5384 - val_mae: 0.5444\n",
      "Epoch 133/200\n",
      "39/39 - 0s - loss: 0.4949 - mae: 0.5302 - val_loss: 0.5394 - val_mae: 0.5447\n",
      "Epoch 134/200\n",
      "39/39 - 0s - loss: 0.4957 - mae: 0.5313 - val_loss: 0.5391 - val_mae: 0.5448\n",
      "Epoch 135/200\n",
      "39/39 - 0s - loss: 0.4985 - mae: 0.5325 - val_loss: 0.5393 - val_mae: 0.5446\n",
      "Epoch 136/200\n",
      "39/39 - 0s - loss: 0.4977 - mae: 0.5343 - val_loss: 0.5358 - val_mae: 0.5424\n",
      "Epoch 137/200\n",
      "39/39 - 0s - loss: 0.4941 - mae: 0.5305 - val_loss: 0.5365 - val_mae: 0.5451\n",
      "Epoch 138/200\n",
      "39/39 - 0s - loss: 0.4978 - mae: 0.5323 - val_loss: 0.5387 - val_mae: 0.5461\n",
      "Epoch 139/200\n",
      "39/39 - 0s - loss: 0.4932 - mae: 0.5304 - val_loss: 0.5370 - val_mae: 0.5455\n",
      "Epoch 140/200\n",
      "39/39 - 0s - loss: 0.4943 - mae: 0.5309 - val_loss: 0.5391 - val_mae: 0.5450\n",
      "Epoch 141/200\n",
      "39/39 - 0s - loss: 0.4933 - mae: 0.5303 - val_loss: 0.5320 - val_mae: 0.5424\n",
      "Epoch 142/200\n",
      "39/39 - 0s - loss: 0.4924 - mae: 0.5303 - val_loss: 0.5336 - val_mae: 0.5439\n",
      "Epoch 143/200\n",
      "39/39 - 0s - loss: 0.4936 - mae: 0.5313 - val_loss: 0.5327 - val_mae: 0.5447\n",
      "Epoch 144/200\n",
      "39/39 - 0s - loss: 0.4921 - mae: 0.5307 - val_loss: 0.5389 - val_mae: 0.5504\n",
      "Epoch 145/200\n",
      "39/39 - 0s - loss: 0.4912 - mae: 0.5309 - val_loss: 0.5309 - val_mae: 0.5410\n",
      "Epoch 146/200\n",
      "39/39 - 0s - loss: 0.4886 - mae: 0.5292 - val_loss: 0.5364 - val_mae: 0.5484\n",
      "Epoch 147/200\n",
      "39/39 - 0s - loss: 0.4904 - mae: 0.5303 - val_loss: 0.5301 - val_mae: 0.5422\n",
      "Epoch 148/200\n",
      "39/39 - 0s - loss: 0.4900 - mae: 0.5303 - val_loss: 0.5482 - val_mae: 0.5584\n",
      "Epoch 149/200\n",
      "39/39 - 0s - loss: 0.4961 - mae: 0.5342 - val_loss: 0.5318 - val_mae: 0.5427\n",
      "Epoch 150/200\n",
      "39/39 - 0s - loss: 0.4885 - mae: 0.5292 - val_loss: 0.5306 - val_mae: 0.5457\n",
      "Epoch 151/200\n",
      "39/39 - 0s - loss: 0.4963 - mae: 0.5336 - val_loss: 0.5299 - val_mae: 0.5417\n",
      "Epoch 152/200\n",
      "39/39 - 0s - loss: 0.4894 - mae: 0.5297 - val_loss: 0.5308 - val_mae: 0.5438\n",
      "Epoch 153/200\n",
      "39/39 - 0s - loss: 0.4876 - mae: 0.5289 - val_loss: 0.5285 - val_mae: 0.5431\n",
      "Epoch 154/200\n",
      "39/39 - 0s - loss: 0.4882 - mae: 0.5299 - val_loss: 0.5279 - val_mae: 0.5447\n",
      "Epoch 155/200\n",
      "39/39 - 0s - loss: 0.4862 - mae: 0.5282 - val_loss: 0.5296 - val_mae: 0.5451\n",
      "Epoch 156/200\n",
      "39/39 - 0s - loss: 0.4904 - mae: 0.5314 - val_loss: 0.5275 - val_mae: 0.5431\n",
      "Epoch 157/200\n",
      "39/39 - 0s - loss: 0.4871 - mae: 0.5294 - val_loss: 0.5282 - val_mae: 0.5440\n",
      "Epoch 158/200\n",
      "39/39 - 0s - loss: 0.4863 - mae: 0.5293 - val_loss: 0.5271 - val_mae: 0.5421\n",
      "Epoch 159/200\n",
      "39/39 - 0s - loss: 0.4871 - mae: 0.5292 - val_loss: 0.5250 - val_mae: 0.5416\n",
      "Epoch 160/200\n",
      "39/39 - 0s - loss: 0.4863 - mae: 0.5282 - val_loss: 0.5241 - val_mae: 0.5413\n",
      "Epoch 161/200\n",
      "39/39 - 0s - loss: 0.4923 - mae: 0.5329 - val_loss: 0.5303 - val_mae: 0.5466\n",
      "Epoch 162/200\n",
      "39/39 - 0s - loss: 0.4854 - mae: 0.5290 - val_loss: 0.5264 - val_mae: 0.5438\n",
      "Epoch 163/200\n",
      "39/39 - 0s - loss: 0.4827 - mae: 0.5279 - val_loss: 0.5273 - val_mae: 0.5458\n",
      "Epoch 164/200\n",
      "39/39 - 0s - loss: 0.4842 - mae: 0.5289 - val_loss: 0.5271 - val_mae: 0.5448\n",
      "Epoch 165/200\n",
      "39/39 - 0s - loss: 0.4844 - mae: 0.5284 - val_loss: 0.5271 - val_mae: 0.5455\n",
      "Epoch 166/200\n",
      "39/39 - 0s - loss: 0.4852 - mae: 0.5278 - val_loss: 0.5271 - val_mae: 0.5464\n",
      "Epoch 167/200\n",
      "39/39 - 0s - loss: 0.4847 - mae: 0.5282 - val_loss: 0.5222 - val_mae: 0.5414\n",
      "Epoch 168/200\n",
      "39/39 - 0s - loss: 0.4829 - mae: 0.5278 - val_loss: 0.5225 - val_mae: 0.5413\n",
      "Epoch 169/200\n",
      "39/39 - 0s - loss: 0.4845 - mae: 0.5287 - val_loss: 0.5302 - val_mae: 0.5489\n",
      "Epoch 170/200\n",
      "39/39 - 0s - loss: 0.4849 - mae: 0.5286 - val_loss: 0.5276 - val_mae: 0.5453\n",
      "Epoch 171/200\n",
      "39/39 - 0s - loss: 0.4816 - mae: 0.5279 - val_loss: 0.5217 - val_mae: 0.5429\n",
      "Epoch 172/200\n",
      "39/39 - 0s - loss: 0.4828 - mae: 0.5271 - val_loss: 0.5222 - val_mae: 0.5424\n",
      "Epoch 173/200\n",
      "39/39 - 0s - loss: 0.4824 - mae: 0.5279 - val_loss: 0.5202 - val_mae: 0.5414\n",
      "Epoch 174/200\n",
      "39/39 - 0s - loss: 0.4822 - mae: 0.5281 - val_loss: 0.5237 - val_mae: 0.5427\n",
      "Epoch 175/200\n",
      "39/39 - 0s - loss: 0.4891 - mae: 0.5327 - val_loss: 0.5221 - val_mae: 0.5414\n",
      "Epoch 176/200\n",
      "39/39 - 0s - loss: 0.4819 - mae: 0.5276 - val_loss: 0.5194 - val_mae: 0.5410\n",
      "Epoch 177/200\n",
      "39/39 - 0s - loss: 0.4814 - mae: 0.5273 - val_loss: 0.5210 - val_mae: 0.5434\n",
      "Epoch 178/200\n",
      "39/39 - 0s - loss: 0.4823 - mae: 0.5286 - val_loss: 0.5242 - val_mae: 0.5475\n",
      "Epoch 179/200\n",
      "39/39 - 0s - loss: 0.4820 - mae: 0.5286 - val_loss: 0.5225 - val_mae: 0.5450\n",
      "Epoch 180/200\n",
      "39/39 - 0s - loss: 0.4824 - mae: 0.5285 - val_loss: 0.5199 - val_mae: 0.5418\n",
      "Epoch 181/200\n",
      "39/39 - 0s - loss: 0.4772 - mae: 0.5263 - val_loss: 0.5305 - val_mae: 0.5493\n",
      "Epoch 182/200\n",
      "39/39 - 0s - loss: 0.4802 - mae: 0.5262 - val_loss: 0.5194 - val_mae: 0.5431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200\n",
      "39/39 - 0s - loss: 0.4781 - mae: 0.5258 - val_loss: 0.5227 - val_mae: 0.5439\n",
      "Epoch 184/200\n",
      "39/39 - 0s - loss: 0.4777 - mae: 0.5269 - val_loss: 0.5253 - val_mae: 0.5474\n",
      "Epoch 185/200\n",
      "39/39 - 0s - loss: 0.4807 - mae: 0.5283 - val_loss: 0.5208 - val_mae: 0.5454\n",
      "Epoch 186/200\n",
      "39/39 - 0s - loss: 0.4786 - mae: 0.5266 - val_loss: 0.5198 - val_mae: 0.5418\n",
      "Epoch 187/200\n",
      "39/39 - 0s - loss: 0.4790 - mae: 0.5279 - val_loss: 0.5178 - val_mae: 0.5429\n",
      "Epoch 188/200\n",
      "39/39 - 0s - loss: 0.4781 - mae: 0.5269 - val_loss: 0.5179 - val_mae: 0.5430\n",
      "Epoch 189/200\n",
      "39/39 - 0s - loss: 0.4787 - mae: 0.5273 - val_loss: 0.5222 - val_mae: 0.5448\n",
      "Epoch 190/200\n",
      "39/39 - 0s - loss: 0.4795 - mae: 0.5282 - val_loss: 0.5177 - val_mae: 0.5426\n",
      "Epoch 191/200\n",
      "39/39 - 0s - loss: 0.4800 - mae: 0.5290 - val_loss: 0.5263 - val_mae: 0.5489\n",
      "Epoch 192/200\n",
      "39/39 - 0s - loss: 0.4777 - mae: 0.5282 - val_loss: 0.5171 - val_mae: 0.5426\n",
      "Epoch 193/200\n",
      "39/39 - 0s - loss: 0.4771 - mae: 0.5271 - val_loss: 0.5176 - val_mae: 0.5423\n",
      "Epoch 194/200\n",
      "39/39 - 0s - loss: 0.4766 - mae: 0.5262 - val_loss: 0.5182 - val_mae: 0.5443\n",
      "Epoch 195/200\n",
      "39/39 - 0s - loss: 0.4772 - mae: 0.5274 - val_loss: 0.5183 - val_mae: 0.5426\n",
      "Epoch 196/200\n",
      "39/39 - 0s - loss: 0.4781 - mae: 0.5270 - val_loss: 0.5207 - val_mae: 0.5430\n",
      "Epoch 197/200\n",
      "39/39 - 0s - loss: 0.4774 - mae: 0.5280 - val_loss: 0.5263 - val_mae: 0.5501\n",
      "Epoch 198/200\n",
      "39/39 - 0s - loss: 0.4788 - mae: 0.5286 - val_loss: 0.5184 - val_mae: 0.5431\n",
      "Epoch 199/200\n",
      "39/39 - 0s - loss: 0.4787 - mae: 0.5286 - val_loss: 0.5222 - val_mae: 0.5456\n",
      "Epoch 200/200\n",
      "39/39 - 0s - loss: 0.4770 - mae: 0.5262 - val_loss: 0.5183 - val_mae: 0.5424\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 904us/step - loss: 0.5034 - mae: 0.5410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdbd03375e0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_trans, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 - 0s - loss: 0.5118 - mae: 0.5394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5117650032043457, 0.5393674969673157]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test,y_test,batch_size=42,verbose=2)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.title('Loss / Mean Squared Error')\n",
    "pyplot.plot(history.history['loss'], label='train_loss')\n",
    "pyplot.plot(history.history['val_loss'], label='train_val')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       ...,\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "481     8\n",
       "4199    7\n",
       "1073    6\n",
       "2608    6\n",
       "543     6\n",
       "       ..\n",
       "2384    6\n",
       "3567    6\n",
       "957     6\n",
       "6123    6\n",
       "1855    7\n",
       "Name: quality, Length: 1625, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2765281121953278"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score(y_test,y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5723076923076923"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2745619290100344"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_nn =  pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_nn['error'] = ('mse', 'r2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_nn['Full_NN'] = (0.57,0.28) \n",
    "df_score_nn['NN_redwine'] = (0.60,0.13) \n",
    "df_score_nn['NN_whitewine'] = (0.75,0.09) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>Full_NN</th>\n",
       "      <th>NN_redwine</th>\n",
       "      <th>NN_whitewine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  error  Full_NN  NN_redwine  NN_whitewine\n",
       "0   mse     0.56        0.60          0.75\n",
       "1    r2     0.28        0.13          0.09"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
