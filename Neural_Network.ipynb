{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>pH</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>type</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.4</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.56</td>\n",
       "      <td>34.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>7.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.68</td>\n",
       "      <td>67.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>7.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.26</td>\n",
       "      <td>5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>54.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>11.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.16</td>\n",
       "      <td>6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.58</td>\n",
       "      <td>60.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.4</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.56</td>\n",
       "      <td>34.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  chlorides  citric_acid  density  fixed_acidity  \\\n",
       "0      9.4      0.076         0.00   0.9978            7.4   \n",
       "1      9.8      0.098         0.00   0.9968            7.8   \n",
       "2      9.8      0.092         0.04   0.9970            7.8   \n",
       "3      9.8      0.075         0.56   0.9980           11.2   \n",
       "4      9.4      0.076         0.00   0.9978            7.4   \n",
       "\n",
       "   free_sulfur_dioxide    pH  quality  residual_sugar  sulphates  \\\n",
       "0                 11.0  3.51        5             1.9       0.56   \n",
       "1                 25.0  3.20        5             2.6       0.68   \n",
       "2                 15.0  3.26        5             2.3       0.65   \n",
       "3                 17.0  3.16        6             1.9       0.58   \n",
       "4                 11.0  3.51        5             1.9       0.56   \n",
       "\n",
       "   total_sulfur_dioxide type  volatile_acidity  \n",
       "0                  34.0  red              0.70  \n",
       "1                  67.0  red              0.88  \n",
       "2                  54.0  red              0.76  \n",
       "3                  60.0  red              0.28  \n",
       "4                  34.0  red              0.70  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_qa = pd.read_csv('data/wine-qa.csv')\n",
    "wine_qa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>pH</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.491801</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>0.318633</td>\n",
       "      <td>0.994697</td>\n",
       "      <td>7.215307</td>\n",
       "      <td>30.525319</td>\n",
       "      <td>3.218501</td>\n",
       "      <td>5.818378</td>\n",
       "      <td>5.443235</td>\n",
       "      <td>0.531268</td>\n",
       "      <td>115.744574</td>\n",
       "      <td>0.339666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.192712</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>0.145318</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>1.296434</td>\n",
       "      <td>17.749400</td>\n",
       "      <td>0.160787</td>\n",
       "      <td>0.873255</td>\n",
       "      <td>4.757804</td>\n",
       "      <td>0.148806</td>\n",
       "      <td>56.521855</td>\n",
       "      <td>0.164636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.500000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.300000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.300000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.996990</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.900000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.580000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           alcohol    chlorides  citric_acid      density  fixed_acidity  \\\n",
       "count  6497.000000  6497.000000  6497.000000  6497.000000    6497.000000   \n",
       "mean     10.491801     0.056034     0.318633     0.994697       7.215307   \n",
       "std       1.192712     0.035034     0.145318     0.002999       1.296434   \n",
       "min       8.000000     0.009000     0.000000     0.987110       3.800000   \n",
       "25%       9.500000     0.038000     0.250000     0.992340       6.400000   \n",
       "50%      10.300000     0.047000     0.310000     0.994890       7.000000   \n",
       "75%      11.300000     0.065000     0.390000     0.996990       7.700000   \n",
       "max      14.900000     0.611000     1.660000     1.038980      15.900000   \n",
       "\n",
       "       free_sulfur_dioxide           pH      quality  residual_sugar  \\\n",
       "count          6497.000000  6497.000000  6497.000000     6497.000000   \n",
       "mean             30.525319     3.218501     5.818378        5.443235   \n",
       "std              17.749400     0.160787     0.873255        4.757804   \n",
       "min               1.000000     2.720000     3.000000        0.600000   \n",
       "25%              17.000000     3.110000     5.000000        1.800000   \n",
       "50%              29.000000     3.210000     6.000000        3.000000   \n",
       "75%              41.000000     3.320000     6.000000        8.100000   \n",
       "max             289.000000     4.010000     9.000000       65.800000   \n",
       "\n",
       "         sulphates  total_sulfur_dioxide  volatile_acidity  \n",
       "count  6497.000000           6497.000000       6497.000000  \n",
       "mean      0.531268            115.744574          0.339666  \n",
       "std       0.148806             56.521855          0.164636  \n",
       "min       0.220000              6.000000          0.080000  \n",
       "25%       0.430000             77.000000          0.230000  \n",
       "50%       0.510000            118.000000          0.290000  \n",
       "75%       0.600000            156.000000          0.400000  \n",
       "max       2.000000            440.000000          1.580000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_qa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wine_qa['quality']\n",
    "X = wine_qa.drop(columns=['quality','citric_acid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.fit(X['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = label_encoder.transform(X['type'])\n",
    "X = X.drop(columns=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('powertransformer', PowerTransformer())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "prep = make_pipeline(StandardScaler(),PowerTransformer())\n",
    "prep.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.953370</td>\n",
       "      <td>1.072372</td>\n",
       "      <td>1.033622</td>\n",
       "      <td>0.388848</td>\n",
       "      <td>-1.240947</td>\n",
       "      <td>1.695009</td>\n",
       "      <td>-0.851699</td>\n",
       "      <td>0.419033</td>\n",
       "      <td>-1.434050</td>\n",
       "      <td>1.729941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.505147</td>\n",
       "      <td>1.498094</td>\n",
       "      <td>0.716893</td>\n",
       "      <td>0.682413</td>\n",
       "      <td>-0.190511</td>\n",
       "      <td>-0.047834</td>\n",
       "      <td>-0.530613</td>\n",
       "      <td>1.092829</td>\n",
       "      <td>-0.864553</td>\n",
       "      <td>2.104292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.505147</td>\n",
       "      <td>1.399968</td>\n",
       "      <td>0.780642</td>\n",
       "      <td>0.682413</td>\n",
       "      <td>-0.918777</td>\n",
       "      <td>0.323952</td>\n",
       "      <td>-0.664079</td>\n",
       "      <td>0.943554</td>\n",
       "      <td>-1.089511</td>\n",
       "      <td>1.866502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.505147</td>\n",
       "      <td>1.047689</td>\n",
       "      <td>1.096401</td>\n",
       "      <td>2.226182</td>\n",
       "      <td>-0.763993</td>\n",
       "      <td>-0.309721</td>\n",
       "      <td>-0.851699</td>\n",
       "      <td>0.548089</td>\n",
       "      <td>-0.985790</td>\n",
       "      <td>-0.165669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.953370</td>\n",
       "      <td>1.072372</td>\n",
       "      <td>1.033622</td>\n",
       "      <td>0.388848</td>\n",
       "      <td>-1.240947</td>\n",
       "      <td>1.695009</td>\n",
       "      <td>-0.851699</td>\n",
       "      <td>0.419033</td>\n",
       "      <td>-1.434050</td>\n",
       "      <td>1.729941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.953370  1.072372  1.033622  0.388848 -1.240947  1.695009 -0.851699   \n",
       "1 -0.505147  1.498094  0.716893  0.682413 -0.190511 -0.047834 -0.530613   \n",
       "2 -0.505147  1.399968  0.780642  0.682413 -0.918777  0.323952 -0.664079   \n",
       "3 -0.505147  1.047689  1.096401  2.226182 -0.763993 -0.309721 -0.851699   \n",
       "4 -0.953370  1.072372  1.033622  0.388848 -1.240947  1.695009 -0.851699   \n",
       "\n",
       "          7         8         9  type  \n",
       "0  0.419033 -1.434050  1.729941     0  \n",
       "1  1.092829 -0.864553  2.104292     0  \n",
       "2  0.943554 -1.089511  1.866502     0  \n",
       "3  0.548089 -0.985790 -0.165669     0  \n",
       "4  0.419033 -1.434050  1.729941     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trans = pd.DataFrame(prep.transform(X))\n",
    "X_trans['type'] = color\n",
    "X_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trans,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.174459</td>\n",
       "      <td>1.022383</td>\n",
       "      <td>1.033622</td>\n",
       "      <td>0.306964</td>\n",
       "      <td>-1.158870</td>\n",
       "      <td>0.730997</td>\n",
       "      <td>0.542933</td>\n",
       "      <td>1.723310</td>\n",
       "      <td>-0.516633</td>\n",
       "      <td>0.934137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>-1.695822</td>\n",
       "      <td>0.582690</td>\n",
       "      <td>2.267500</td>\n",
       "      <td>1.454079</td>\n",
       "      <td>0.943693</td>\n",
       "      <td>-0.861356</td>\n",
       "      <td>1.743362</td>\n",
       "      <td>0.726969</td>\n",
       "      <td>2.145601</td>\n",
       "      <td>0.329251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>-2.233160</td>\n",
       "      <td>0.222666</td>\n",
       "      <td>-0.105830</td>\n",
       "      <td>-0.883128</td>\n",
       "      <td>0.355150</td>\n",
       "      <td>-0.309721</td>\n",
       "      <td>-0.243067</td>\n",
       "      <td>-0.206818</td>\n",
       "      <td>-0.060174</td>\n",
       "      <td>0.099628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>-1.314622</td>\n",
       "      <td>-0.121363</td>\n",
       "      <td>1.202730</td>\n",
       "      <td>-0.390660</td>\n",
       "      <td>0.614957</td>\n",
       "      <td>-1.076385</td>\n",
       "      <td>1.563113</td>\n",
       "      <td>-0.032374</td>\n",
       "      <td>0.028287</td>\n",
       "      <td>-0.801963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>-0.724284</td>\n",
       "      <td>0.416010</td>\n",
       "      <td>1.654231</td>\n",
       "      <td>0.130100</td>\n",
       "      <td>1.074887</td>\n",
       "      <td>0.954024</td>\n",
       "      <td>1.720839</td>\n",
       "      <td>-1.243290</td>\n",
       "      <td>0.743558</td>\n",
       "      <td>-0.801963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "40    0.174459  1.022383  1.033622  0.306964 -1.158870  0.730997  0.542933   \n",
       "3849 -1.695822  0.582690  2.267500  1.454079  0.943693 -0.861356  1.743362   \n",
       "5434 -2.233160  0.222666 -0.105830 -0.883128  0.355150 -0.309721 -0.243067   \n",
       "4528 -1.314622 -0.121363  1.202730 -0.390660  0.614957 -1.076385  1.563113   \n",
       "3730 -0.724284  0.416010  1.654231  0.130100  1.074887  0.954024  1.720839   \n",
       "\n",
       "             7         8         9  type  \n",
       "40    1.723310 -0.516633  0.934137     0  \n",
       "3849  0.726969  2.145601  0.329251     1  \n",
       "5434 -0.206818 -0.060174  0.099628     1  \n",
       "4528 -0.032374  0.028287 -0.801963     1  \n",
       "3730 -1.243290  0.743558 -0.801963     1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_shape=(11,),kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                144       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 313\n",
      "Trainable params: 313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 11),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'dense_input'}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 11),\n",
       "    'dtype': 'float32',\n",
       "    'units': 12,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': {'class_name': 'L2',\n",
       "     'config': {'l2': 0.009999999776482582}},\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 12,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.03883874, -0.4980698 ,  0.13570589, -0.3134572 ,  0.03424484,\n",
       "          0.37607372,  0.37953424, -0.15386435,  0.372831  ,  0.07431835,\n",
       "         -0.3329022 ,  0.40097624],\n",
       "        [-0.10893041,  0.06913799,  0.16777879,  0.29372764, -0.28722858,\n",
       "          0.02724361,  0.01260412,  0.3350134 , -0.3212804 , -0.12203479,\n",
       "         -0.17131945, -0.22153118],\n",
       "        [-0.41385606, -0.18812442,  0.04103732,  0.12712604,  0.38579255,\n",
       "          0.08055931, -0.24996999,  0.21560025, -0.10350189,  0.46808958,\n",
       "         -0.39157277,  0.30884004],\n",
       "        [-0.22148383, -0.11575323, -0.48074743, -0.47223815,  0.14011896,\n",
       "         -0.33954185, -0.08660486, -0.17023557, -0.13966465,  0.4701792 ,\n",
       "          0.03453428, -0.41418618],\n",
       "        [ 0.23177671, -0.3736542 ,  0.39658993, -0.30511206,  0.38460284,\n",
       "          0.10720783, -0.33401018,  0.25652224,  0.2005145 ,  0.10818416,\n",
       "          0.1497271 ,  0.3740055 ],\n",
       "        [ 0.31449324, -0.28461033,  0.14355868, -0.19441399, -0.10494977,\n",
       "         -0.26418933,  0.3003549 ,  0.33281648, -0.01395071,  0.4131047 ,\n",
       "          0.27668303, -0.27833366],\n",
       "        [-0.23842832,  0.25547743, -0.09223408, -0.27997625, -0.28957394,\n",
       "         -0.0460338 , -0.1083627 ,  0.03952175, -0.06282523, -0.02124357,\n",
       "          0.19846761,  0.41693872],\n",
       "        [ 0.04316181, -0.1135534 , -0.4832512 , -0.3529703 , -0.256682  ,\n",
       "         -0.38862476, -0.34339696,  0.19871575, -0.06514099,  0.35065073,\n",
       "         -0.21478677, -0.2733603 ],\n",
       "        [ 0.0215221 ,  0.49551004,  0.24707228, -0.37544316,  0.2605095 ,\n",
       "         -0.04372451,  0.40879476,  0.08382165, -0.20162126,  0.0220055 ,\n",
       "         -0.4913422 , -0.11954162],\n",
       "        [-0.36958027,  0.43392622, -0.43748578,  0.39740962,  0.29603535,\n",
       "         -0.2907679 , -0.39204416,  0.49041706,  0.3669684 , -0.11475715,\n",
       "         -0.00476253,  0.27300233],\n",
       "        [ 0.5012439 ,  0.27901936, -0.32713646, -0.2627289 , -0.05440986,\n",
       "          0.34315914,  0.27216935,  0.07527995,  0.12262428,  0.42583388,\n",
       "          0.46456814,  0.43419325]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.3903091 ,  0.3215629 ,  0.19015574, -0.10008419,  0.4936533 ,\n",
       "          0.13712215,  0.15137923, -0.38120914,  0.19041562, -0.00150812,\n",
       "          0.28449094, -0.39778435],\n",
       "        [-0.2993728 , -0.4104644 , -0.32700765, -0.02975571, -0.47176147,\n",
       "          0.08549297, -0.3780476 , -0.364465  , -0.10682392, -0.34883583,\n",
       "         -0.3578564 ,  0.33554995],\n",
       "        [ 0.31201708,  0.3773359 ,  0.20715976, -0.46092832,  0.13436341,\n",
       "         -0.31716812, -0.15002489,  0.11433005,  0.20024633,  0.16362083,\n",
       "         -0.17964411,  0.3394525 ],\n",
       "        [ 0.17898512,  0.09727848,  0.0011766 ,  0.2686125 , -0.05942523,\n",
       "         -0.36689794, -0.36981428,  0.22825778,  0.07150328, -0.1675551 ,\n",
       "         -0.43542433, -0.02442551],\n",
       "        [-0.23770106, -0.13468003,  0.14197326, -0.07337713,  0.00872207,\n",
       "          0.1290884 ,  0.09640586,  0.36692846,  0.29432654,  0.22670257,\n",
       "          0.2741748 ,  0.40024126],\n",
       "        [-0.24372363, -0.27969635, -0.06252372,  0.32365596, -0.19828212,\n",
       "         -0.06889772, -0.1649344 , -0.15279281,  0.11286008, -0.28798163,\n",
       "          0.39070117, -0.08955097],\n",
       "        [-0.11037922,  0.41619027,  0.46613646,  0.06431842,  0.18742216,\n",
       "          0.2691381 ,  0.43807518,  0.34826827, -0.31383157, -0.12119949,\n",
       "          0.39460373, -0.19601429],\n",
       "        [ 0.2628504 , -0.21908212, -0.35289598,  0.4712752 , -0.3765067 ,\n",
       "          0.17042792, -0.19191694, -0.164078  , -0.29667366, -0.34219444,\n",
       "          0.13082123,  0.07739699],\n",
       "        [-0.09694839,  0.06184816,  0.3601508 , -0.21211994, -0.45632148,\n",
       "          0.02271605,  0.14424586,  0.18478882,  0.02584064, -0.38295496,\n",
       "          0.17058766, -0.18829668],\n",
       "        [-0.4045912 , -0.43656957, -0.05028129,  0.3678285 , -0.46761203,\n",
       "          0.23582113, -0.07198215, -0.35415757, -0.21343625, -0.26526642,\n",
       "         -0.28057766, -0.10521007],\n",
       "        [-0.15645671,  0.1783315 ,  0.05825841,  0.13953888,  0.21807921,\n",
       "         -0.14635658,  0.29641366,  0.08567977, -0.2949822 ,  0.00581229,\n",
       "         -0.19900858, -0.1346153 ],\n",
       "        [ 0.00242603, -0.29449403,  0.1304673 ,  0.04281485, -0.24123979,\n",
       "         -0.24892819, -0.28149128, -0.3335656 , -0.12688816, -0.4502883 ,\n",
       "         -0.22344911, -0.11362934]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.16557097],\n",
       "        [-0.6157696 ],\n",
       "        [-0.57814187],\n",
       "        [-0.56637526],\n",
       "        [-0.5641106 ],\n",
       "        [ 0.14284378],\n",
       "        [ 0.38218856],\n",
       "        [-0.12354773],\n",
       "        [-0.46786606],\n",
       "        [-0.33254156],\n",
       "        [-0.06810176],\n",
       "        [-0.1436323 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg, bs = model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg.shape # 1 weight per input per neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16557097]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg[:1,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.shape # 1 bias per neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.174459</td>\n",
       "      <td>1.022383</td>\n",
       "      <td>1.033622</td>\n",
       "      <td>0.306964</td>\n",
       "      <td>-1.158870</td>\n",
       "      <td>0.730997</td>\n",
       "      <td>0.542933</td>\n",
       "      <td>1.723310</td>\n",
       "      <td>-0.516633</td>\n",
       "      <td>0.934137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>-1.695822</td>\n",
       "      <td>0.582690</td>\n",
       "      <td>2.267500</td>\n",
       "      <td>1.454079</td>\n",
       "      <td>0.943693</td>\n",
       "      <td>-0.861356</td>\n",
       "      <td>1.743362</td>\n",
       "      <td>0.726969</td>\n",
       "      <td>2.145601</td>\n",
       "      <td>0.329251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>-2.233160</td>\n",
       "      <td>0.222666</td>\n",
       "      <td>-0.105830</td>\n",
       "      <td>-0.883128</td>\n",
       "      <td>0.355150</td>\n",
       "      <td>-0.309721</td>\n",
       "      <td>-0.243067</td>\n",
       "      <td>-0.206818</td>\n",
       "      <td>-0.060174</td>\n",
       "      <td>0.099628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>-1.314622</td>\n",
       "      <td>-0.121363</td>\n",
       "      <td>1.202730</td>\n",
       "      <td>-0.390660</td>\n",
       "      <td>0.614957</td>\n",
       "      <td>-1.076385</td>\n",
       "      <td>1.563113</td>\n",
       "      <td>-0.032374</td>\n",
       "      <td>0.028287</td>\n",
       "      <td>-0.801963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>-0.724284</td>\n",
       "      <td>0.416010</td>\n",
       "      <td>1.654231</td>\n",
       "      <td>0.130100</td>\n",
       "      <td>1.074887</td>\n",
       "      <td>0.954024</td>\n",
       "      <td>1.720839</td>\n",
       "      <td>-1.243290</td>\n",
       "      <td>0.743558</td>\n",
       "      <td>-0.801963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "40    0.174459  1.022383  1.033622  0.306964 -1.158870  0.730997  0.542933   \n",
       "3849 -1.695822  0.582690  2.267500  1.454079  0.943693 -0.861356  1.743362   \n",
       "5434 -2.233160  0.222666 -0.105830 -0.883128  0.355150 -0.309721 -0.243067   \n",
       "4528 -1.314622 -0.121363  1.202730 -0.390660  0.614957 -1.076385  1.563113   \n",
       "3730 -0.724284  0.416010  1.654231  0.130100  1.074887  0.954024  1.720839   \n",
       "\n",
       "             7         8         9  type  \n",
       "40    1.723310 -0.516633  0.934137     0  \n",
       "3849  0.726969  2.145601  0.329251     1  \n",
       "5434 -0.206818 -0.060174  0.099628     1  \n",
       "4528 -0.032374  0.028287 -0.801963     1  \n",
       "3730 -1.243290  0.743558 -0.801963     1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001264</td>\n",
       "      <td>-0.002183</td>\n",
       "      <td>0.004224</td>\n",
       "      <td>0.008886</td>\n",
       "      <td>-0.007261</td>\n",
       "      <td>-0.008774</td>\n",
       "      <td>0.009877</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>-0.002659</td>\n",
       "      <td>0.755337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.997999</td>\n",
       "      <td>0.999190</td>\n",
       "      <td>1.001317</td>\n",
       "      <td>0.993669</td>\n",
       "      <td>1.000480</td>\n",
       "      <td>1.005566</td>\n",
       "      <td>1.000498</td>\n",
       "      <td>1.002226</td>\n",
       "      <td>1.002245</td>\n",
       "      <td>0.998554</td>\n",
       "      <td>0.429932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.801674</td>\n",
       "      <td>-3.846119</td>\n",
       "      <td>-2.681231</td>\n",
       "      <td>-5.076634</td>\n",
       "      <td>-2.114337</td>\n",
       "      <td>-3.656202</td>\n",
       "      <td>-1.538962</td>\n",
       "      <td>-3.405513</td>\n",
       "      <td>-1.913711</td>\n",
       "      <td>-2.824694</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.837615</td>\n",
       "      <td>-0.685937</td>\n",
       "      <td>-0.765344</td>\n",
       "      <td>-0.628774</td>\n",
       "      <td>-0.763993</td>\n",
       "      <td>-0.668007</td>\n",
       "      <td>-0.900341</td>\n",
       "      <td>-0.692091</td>\n",
       "      <td>-0.673495</td>\n",
       "      <td>-0.686199</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.004737</td>\n",
       "      <td>-0.059408</td>\n",
       "      <td>0.098744</td>\n",
       "      <td>0.034769</td>\n",
       "      <td>0.066034</td>\n",
       "      <td>-0.047834</td>\n",
       "      <td>-0.321837</td>\n",
       "      <td>0.050423</td>\n",
       "      <td>0.028287</td>\n",
       "      <td>-0.073295</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.783502</td>\n",
       "      <td>0.727783</td>\n",
       "      <td>0.780642</td>\n",
       "      <td>0.613444</td>\n",
       "      <td>0.712535</td>\n",
       "      <td>0.674253</td>\n",
       "      <td>0.936988</td>\n",
       "      <td>0.669100</td>\n",
       "      <td>0.707528</td>\n",
       "      <td>0.694061</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.659226</td>\n",
       "      <td>3.237403</td>\n",
       "      <td>12.552618</td>\n",
       "      <td>3.449920</td>\n",
       "      <td>4.044401</td>\n",
       "      <td>4.049913</td>\n",
       "      <td>2.847312</td>\n",
       "      <td>4.450583</td>\n",
       "      <td>4.584748</td>\n",
       "      <td>3.009259</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  4872.000000  4872.000000  4872.000000  4872.000000  4872.000000   \n",
       "mean      0.001264    -0.002183     0.004224     0.008886    -0.007261   \n",
       "std       0.997999     0.999190     1.001317     0.993669     1.000480   \n",
       "min      -2.801674    -3.846119    -2.681231    -5.076634    -2.114337   \n",
       "25%      -0.837615    -0.685937    -0.765344    -0.628774    -0.763993   \n",
       "50%      -0.004737    -0.059408     0.098744     0.034769     0.066034   \n",
       "75%       0.783502     0.727783     0.780642     0.613444     0.712535   \n",
       "max       2.659226     3.237403    12.552618     3.449920     4.044401   \n",
       "\n",
       "                 5            6            7            8            9  \\\n",
       "count  4872.000000  4872.000000  4872.000000  4872.000000  4872.000000   \n",
       "mean     -0.008774     0.009877    -0.001215     0.002084    -0.002659   \n",
       "std       1.005566     1.000498     1.002226     1.002245     0.998554   \n",
       "min      -3.656202    -1.538962    -3.405513    -1.913711    -2.824694   \n",
       "25%      -0.668007    -0.900341    -0.692091    -0.673495    -0.686199   \n",
       "50%      -0.047834    -0.321837     0.050423     0.028287    -0.073295   \n",
       "75%       0.674253     0.936988     0.669100     0.707528     0.694061   \n",
       "max       4.049913     2.847312     4.450583     4.584748     3.009259   \n",
       "\n",
       "              type  \n",
       "count  4872.000000  \n",
       "mean      0.755337  \n",
       "std       0.429932  \n",
       "min       0.000000  \n",
       "25%       1.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= 'mse',\n",
    "              optimizer= 'adam',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "39/39 - 0s - loss: 34.6079 - mae: 5.8097 - val_loss: 35.0146 - val_mae: 5.8443\n",
      "Epoch 2/200\n",
      "39/39 - 0s - loss: 34.5855 - mae: 5.8096 - val_loss: 34.9831 - val_mae: 5.8430\n",
      "Epoch 3/200\n",
      "39/39 - 0s - loss: 33.7746 - mae: 5.7386 - val_loss: 31.3206 - val_mae: 5.5251\n",
      "Epoch 4/200\n",
      "39/39 - 0s - loss: 25.7119 - mae: 4.9838 - val_loss: 20.2501 - val_mae: 4.4031\n",
      "Epoch 5/200\n",
      "39/39 - 0s - loss: 14.9148 - mae: 3.6761 - val_loss: 10.1592 - val_mae: 2.9132\n",
      "Epoch 6/200\n",
      "39/39 - 0s - loss: 6.9006 - mae: 2.2446 - val_loss: 4.6280 - val_mae: 1.7566\n",
      "Epoch 7/200\n",
      "39/39 - 0s - loss: 3.2580 - mae: 1.4480 - val_loss: 2.3052 - val_mae: 1.1973\n",
      "Epoch 8/200\n",
      "39/39 - 0s - loss: 1.7322 - mae: 1.0210 - val_loss: 1.3822 - val_mae: 0.8831\n",
      "Epoch 9/200\n",
      "39/39 - 0s - loss: 1.2356 - mae: 0.8387 - val_loss: 1.1177 - val_mae: 0.7828\n",
      "Epoch 10/200\n",
      "39/39 - 0s - loss: 1.0863 - mae: 0.7750 - val_loss: 1.0210 - val_mae: 0.7428\n",
      "Epoch 11/200\n",
      "39/39 - 0s - loss: 1.0146 - mae: 0.7430 - val_loss: 0.9563 - val_mae: 0.7159\n",
      "Epoch 12/200\n",
      "39/39 - 0s - loss: 0.9610 - mae: 0.7197 - val_loss: 0.9131 - val_mae: 0.6971\n",
      "Epoch 13/200\n",
      "39/39 - 0s - loss: 0.9179 - mae: 0.6997 - val_loss: 0.8769 - val_mae: 0.6794\n",
      "Epoch 14/200\n",
      "39/39 - 0s - loss: 0.8866 - mae: 0.6866 - val_loss: 0.8503 - val_mae: 0.6670\n",
      "Epoch 15/200\n",
      "39/39 - 0s - loss: 0.8616 - mae: 0.6751 - val_loss: 0.8289 - val_mae: 0.6574\n",
      "Epoch 16/200\n",
      "39/39 - 0s - loss: 0.8412 - mae: 0.6670 - val_loss: 0.8149 - val_mae: 0.6506\n",
      "Epoch 17/200\n",
      "39/39 - 0s - loss: 0.8238 - mae: 0.6583 - val_loss: 0.7980 - val_mae: 0.6427\n",
      "Epoch 18/200\n",
      "39/39 - 0s - loss: 0.8106 - mae: 0.6538 - val_loss: 0.7886 - val_mae: 0.6386\n",
      "Epoch 19/200\n",
      "39/39 - 0s - loss: 0.7972 - mae: 0.6482 - val_loss: 0.7721 - val_mae: 0.6320\n",
      "Epoch 20/200\n",
      "39/39 - 0s - loss: 0.7865 - mae: 0.6431 - val_loss: 0.7623 - val_mae: 0.6291\n",
      "Epoch 21/200\n",
      "39/39 - 0s - loss: 0.7761 - mae: 0.6397 - val_loss: 0.7525 - val_mae: 0.6248\n",
      "Epoch 22/200\n",
      "39/39 - 0s - loss: 0.7736 - mae: 0.6394 - val_loss: 0.7462 - val_mae: 0.6213\n",
      "Epoch 23/200\n",
      "39/39 - 0s - loss: 0.7601 - mae: 0.6337 - val_loss: 0.7410 - val_mae: 0.6186\n",
      "Epoch 24/200\n",
      "39/39 - 0s - loss: 0.7534 - mae: 0.6304 - val_loss: 0.7352 - val_mae: 0.6170\n",
      "Epoch 25/200\n",
      "39/39 - 0s - loss: 0.7468 - mae: 0.6273 - val_loss: 0.7269 - val_mae: 0.6136\n",
      "Epoch 26/200\n",
      "39/39 - 0s - loss: 0.7388 - mae: 0.6255 - val_loss: 0.7195 - val_mae: 0.6117\n",
      "Epoch 27/200\n",
      "39/39 - 0s - loss: 0.7334 - mae: 0.6238 - val_loss: 0.7141 - val_mae: 0.6096\n",
      "Epoch 28/200\n",
      "39/39 - 0s - loss: 0.7277 - mae: 0.6212 - val_loss: 0.7066 - val_mae: 0.6066\n",
      "Epoch 29/200\n",
      "39/39 - 0s - loss: 0.7235 - mae: 0.6203 - val_loss: 0.7013 - val_mae: 0.6045\n",
      "Epoch 30/200\n",
      "39/39 - 0s - loss: 0.7176 - mae: 0.6175 - val_loss: 0.6956 - val_mae: 0.6020\n",
      "Epoch 31/200\n",
      "39/39 - 0s - loss: 0.7114 - mae: 0.6161 - val_loss: 0.6926 - val_mae: 0.6019\n",
      "Epoch 32/200\n",
      "39/39 - 0s - loss: 0.7049 - mae: 0.6123 - val_loss: 0.6861 - val_mae: 0.5997\n",
      "Epoch 33/200\n",
      "39/39 - 0s - loss: 0.7001 - mae: 0.6116 - val_loss: 0.6800 - val_mae: 0.5967\n",
      "Epoch 34/200\n",
      "39/39 - 0s - loss: 0.6952 - mae: 0.6103 - val_loss: 0.6735 - val_mae: 0.5938\n",
      "Epoch 35/200\n",
      "39/39 - 0s - loss: 0.6918 - mae: 0.6088 - val_loss: 0.6706 - val_mae: 0.5923\n",
      "Epoch 36/200\n",
      "39/39 - 0s - loss: 0.6840 - mae: 0.6067 - val_loss: 0.6736 - val_mae: 0.5938\n",
      "Epoch 37/200\n",
      "39/39 - 0s - loss: 0.6800 - mae: 0.6053 - val_loss: 0.6626 - val_mae: 0.5898\n",
      "Epoch 38/200\n",
      "39/39 - 0s - loss: 0.6764 - mae: 0.6045 - val_loss: 0.6604 - val_mae: 0.5877\n",
      "Epoch 39/200\n",
      "39/39 - 0s - loss: 0.6726 - mae: 0.6017 - val_loss: 0.6550 - val_mae: 0.5866\n",
      "Epoch 40/200\n",
      "39/39 - 0s - loss: 0.6672 - mae: 0.6001 - val_loss: 0.6521 - val_mae: 0.5846\n",
      "Epoch 41/200\n",
      "39/39 - 0s - loss: 0.6624 - mae: 0.5987 - val_loss: 0.6474 - val_mae: 0.5832\n",
      "Epoch 42/200\n",
      "39/39 - 0s - loss: 0.6579 - mae: 0.5969 - val_loss: 0.6470 - val_mae: 0.5835\n",
      "Epoch 43/200\n",
      "39/39 - 0s - loss: 0.6550 - mae: 0.5960 - val_loss: 0.6400 - val_mae: 0.5816\n",
      "Epoch 44/200\n",
      "39/39 - 0s - loss: 0.6521 - mae: 0.5966 - val_loss: 0.6366 - val_mae: 0.5792\n",
      "Epoch 45/200\n",
      "39/39 - 0s - loss: 0.6484 - mae: 0.5940 - val_loss: 0.6355 - val_mae: 0.5791\n",
      "Epoch 46/200\n",
      "39/39 - 0s - loss: 0.6440 - mae: 0.5921 - val_loss: 0.6301 - val_mae: 0.5765\n",
      "Epoch 47/200\n",
      "39/39 - 0s - loss: 0.6391 - mae: 0.5908 - val_loss: 0.6277 - val_mae: 0.5762\n",
      "Epoch 48/200\n",
      "39/39 - 0s - loss: 0.6360 - mae: 0.5896 - val_loss: 0.6249 - val_mae: 0.5759\n",
      "Epoch 49/200\n",
      "39/39 - 0s - loss: 0.6329 - mae: 0.5886 - val_loss: 0.6207 - val_mae: 0.5732\n",
      "Epoch 50/200\n",
      "39/39 - 0s - loss: 0.6282 - mae: 0.5864 - val_loss: 0.6202 - val_mae: 0.5733\n",
      "Epoch 51/200\n",
      "39/39 - 0s - loss: 0.6250 - mae: 0.5853 - val_loss: 0.6198 - val_mae: 0.5734\n",
      "Epoch 52/200\n",
      "39/39 - 0s - loss: 0.6256 - mae: 0.5858 - val_loss: 0.6157 - val_mae: 0.5713\n",
      "Epoch 53/200\n",
      "39/39 - 0s - loss: 0.6206 - mae: 0.5838 - val_loss: 0.6162 - val_mae: 0.5717\n",
      "Epoch 54/200\n",
      "39/39 - 0s - loss: 0.6172 - mae: 0.5823 - val_loss: 0.6138 - val_mae: 0.5715\n",
      "Epoch 55/200\n",
      "39/39 - 0s - loss: 0.6153 - mae: 0.5830 - val_loss: 0.6083 - val_mae: 0.5686\n",
      "Epoch 56/200\n",
      "39/39 - 0s - loss: 0.6110 - mae: 0.5803 - val_loss: 0.6043 - val_mae: 0.5674\n",
      "Epoch 57/200\n",
      "39/39 - 0s - loss: 0.6107 - mae: 0.5810 - val_loss: 0.5974 - val_mae: 0.5652\n",
      "Epoch 58/200\n",
      "39/39 - 0s - loss: 0.6038 - mae: 0.5775 - val_loss: 0.5951 - val_mae: 0.5637\n",
      "Epoch 59/200\n",
      "39/39 - 0s - loss: 0.6050 - mae: 0.5784 - val_loss: 0.5938 - val_mae: 0.5635\n",
      "Epoch 60/200\n",
      "39/39 - 0s - loss: 0.5995 - mae: 0.5766 - val_loss: 0.5958 - val_mae: 0.5647\n",
      "Epoch 61/200\n",
      "39/39 - 0s - loss: 0.5968 - mae: 0.5746 - val_loss: 0.5889 - val_mae: 0.5619\n",
      "Epoch 62/200\n",
      "39/39 - 0s - loss: 0.5939 - mae: 0.5738 - val_loss: 0.5831 - val_mae: 0.5596\n",
      "Epoch 63/200\n",
      "39/39 - 0s - loss: 0.5939 - mae: 0.5747 - val_loss: 0.5824 - val_mae: 0.5583\n",
      "Epoch 64/200\n",
      "39/39 - 0s - loss: 0.5899 - mae: 0.5726 - val_loss: 0.5814 - val_mae: 0.5590\n",
      "Epoch 65/200\n",
      "39/39 - 0s - loss: 0.5872 - mae: 0.5710 - val_loss: 0.5767 - val_mae: 0.5576\n",
      "Epoch 66/200\n",
      "39/39 - 0s - loss: 0.5862 - mae: 0.5724 - val_loss: 0.5804 - val_mae: 0.5584\n",
      "Epoch 67/200\n",
      "39/39 - 0s - loss: 0.5814 - mae: 0.5689 - val_loss: 0.5742 - val_mae: 0.5554\n",
      "Epoch 68/200\n",
      "39/39 - 0s - loss: 0.5778 - mae: 0.5678 - val_loss: 0.5708 - val_mae: 0.5538\n",
      "Epoch 69/200\n",
      "39/39 - 0s - loss: 0.5756 - mae: 0.5653 - val_loss: 0.5674 - val_mae: 0.5527\n",
      "Epoch 70/200\n",
      "39/39 - 0s - loss: 0.5733 - mae: 0.5663 - val_loss: 0.5643 - val_mae: 0.5513\n",
      "Epoch 71/200\n",
      "39/39 - 0s - loss: 0.5720 - mae: 0.5657 - val_loss: 0.5618 - val_mae: 0.5509\n",
      "Epoch 72/200\n",
      "39/39 - 0s - loss: 0.5689 - mae: 0.5650 - val_loss: 0.5618 - val_mae: 0.5511\n",
      "Epoch 73/200\n",
      "39/39 - 0s - loss: 0.5695 - mae: 0.5647 - val_loss: 0.5618 - val_mae: 0.5500\n",
      "Epoch 74/200\n",
      "39/39 - 0s - loss: 0.5656 - mae: 0.5618 - val_loss: 0.5574 - val_mae: 0.5496\n",
      "Epoch 75/200\n",
      "39/39 - 0s - loss: 0.5615 - mae: 0.5612 - val_loss: 0.5553 - val_mae: 0.5490\n",
      "Epoch 76/200\n",
      "39/39 - 0s - loss: 0.5601 - mae: 0.5610 - val_loss: 0.5567 - val_mae: 0.5499\n",
      "Epoch 77/200\n",
      "39/39 - 0s - loss: 0.5562 - mae: 0.5593 - val_loss: 0.5573 - val_mae: 0.5492\n",
      "Epoch 78/200\n",
      "39/39 - 0s - loss: 0.5555 - mae: 0.5598 - val_loss: 0.5505 - val_mae: 0.5470\n",
      "Epoch 79/200\n",
      "39/39 - 0s - loss: 0.5512 - mae: 0.5574 - val_loss: 0.5438 - val_mae: 0.5441\n",
      "Epoch 80/200\n",
      "39/39 - 0s - loss: 0.5486 - mae: 0.5562 - val_loss: 0.5437 - val_mae: 0.5452\n",
      "Epoch 81/200\n",
      "39/39 - 0s - loss: 0.5487 - mae: 0.5566 - val_loss: 0.5386 - val_mae: 0.5415\n",
      "Epoch 82/200\n",
      "39/39 - 0s - loss: 0.5475 - mae: 0.5566 - val_loss: 0.5372 - val_mae: 0.5422\n",
      "Epoch 83/200\n",
      "39/39 - 0s - loss: 0.5436 - mae: 0.5543 - val_loss: 0.5345 - val_mae: 0.5413\n",
      "Epoch 84/200\n",
      "39/39 - 0s - loss: 0.5413 - mae: 0.5534 - val_loss: 0.5312 - val_mae: 0.5397\n",
      "Epoch 85/200\n",
      "39/39 - 0s - loss: 0.5396 - mae: 0.5523 - val_loss: 0.5336 - val_mae: 0.5404\n",
      "Epoch 86/200\n",
      "39/39 - 0s - loss: 0.5352 - mae: 0.5505 - val_loss: 0.5331 - val_mae: 0.5400\n",
      "Epoch 87/200\n",
      "39/39 - 0s - loss: 0.5347 - mae: 0.5503 - val_loss: 0.5301 - val_mae: 0.5389\n",
      "Epoch 88/200\n",
      "39/39 - 0s - loss: 0.5310 - mae: 0.5485 - val_loss: 0.5309 - val_mae: 0.5392\n",
      "Epoch 89/200\n",
      "39/39 - 0s - loss: 0.5315 - mae: 0.5495 - val_loss: 0.5271 - val_mae: 0.5376\n",
      "Epoch 90/200\n",
      "39/39 - 0s - loss: 0.5280 - mae: 0.5469 - val_loss: 0.5263 - val_mae: 0.5367\n",
      "Epoch 91/200\n",
      "39/39 - 0s - loss: 0.5264 - mae: 0.5467 - val_loss: 0.5225 - val_mae: 0.5363\n",
      "Epoch 92/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 - 0s - loss: 0.5274 - mae: 0.5467 - val_loss: 0.5204 - val_mae: 0.5355\n",
      "Epoch 93/200\n",
      "39/39 - 0s - loss: 0.5242 - mae: 0.5465 - val_loss: 0.5189 - val_mae: 0.5336\n",
      "Epoch 94/200\n",
      "39/39 - 0s - loss: 0.5224 - mae: 0.5453 - val_loss: 0.5228 - val_mae: 0.5354\n",
      "Epoch 95/200\n",
      "39/39 - 0s - loss: 0.5202 - mae: 0.5448 - val_loss: 0.5158 - val_mae: 0.5330\n",
      "Epoch 96/200\n",
      "39/39 - 0s - loss: 0.5190 - mae: 0.5440 - val_loss: 0.5282 - val_mae: 0.5380\n",
      "Epoch 97/200\n",
      "39/39 - 0s - loss: 0.5193 - mae: 0.5435 - val_loss: 0.5217 - val_mae: 0.5361\n",
      "Epoch 98/200\n",
      "39/39 - 0s - loss: 0.5176 - mae: 0.5430 - val_loss: 0.5128 - val_mae: 0.5307\n",
      "Epoch 99/200\n",
      "39/39 - 0s - loss: 0.5176 - mae: 0.5438 - val_loss: 0.5127 - val_mae: 0.5317\n",
      "Epoch 100/200\n",
      "39/39 - 0s - loss: 0.5136 - mae: 0.5422 - val_loss: 0.5153 - val_mae: 0.5326\n",
      "Epoch 101/200\n",
      "39/39 - 0s - loss: 0.5122 - mae: 0.5413 - val_loss: 0.5116 - val_mae: 0.5331\n",
      "Epoch 102/200\n",
      "39/39 - 0s - loss: 0.5120 - mae: 0.5415 - val_loss: 0.5182 - val_mae: 0.5349\n",
      "Epoch 103/200\n",
      "39/39 - 0s - loss: 0.5124 - mae: 0.5411 - val_loss: 0.5106 - val_mae: 0.5311\n",
      "Epoch 104/200\n",
      "39/39 - 0s - loss: 0.5125 - mae: 0.5419 - val_loss: 0.5080 - val_mae: 0.5301\n",
      "Epoch 105/200\n",
      "39/39 - 0s - loss: 0.5103 - mae: 0.5406 - val_loss: 0.5093 - val_mae: 0.5322\n",
      "Epoch 106/200\n",
      "39/39 - 0s - loss: 0.5098 - mae: 0.5415 - val_loss: 0.5093 - val_mae: 0.5309\n",
      "Epoch 107/200\n",
      "39/39 - 0s - loss: 0.5112 - mae: 0.5409 - val_loss: 0.5085 - val_mae: 0.5313\n",
      "Epoch 108/200\n",
      "39/39 - 0s - loss: 0.5056 - mae: 0.5400 - val_loss: 0.5160 - val_mae: 0.5337\n",
      "Epoch 109/200\n",
      "39/39 - 0s - loss: 0.5038 - mae: 0.5374 - val_loss: 0.5081 - val_mae: 0.5310\n",
      "Epoch 110/200\n",
      "39/39 - 0s - loss: 0.5030 - mae: 0.5384 - val_loss: 0.5120 - val_mae: 0.5324\n",
      "Epoch 111/200\n",
      "39/39 - 0s - loss: 0.5033 - mae: 0.5390 - val_loss: 0.5042 - val_mae: 0.5289\n",
      "Epoch 112/200\n",
      "39/39 - 0s - loss: 0.5023 - mae: 0.5375 - val_loss: 0.5102 - val_mae: 0.5317\n",
      "Epoch 113/200\n",
      "39/39 - 0s - loss: 0.5035 - mae: 0.5398 - val_loss: 0.5062 - val_mae: 0.5301\n",
      "Epoch 114/200\n",
      "39/39 - 0s - loss: 0.4997 - mae: 0.5368 - val_loss: 0.5096 - val_mae: 0.5318\n",
      "Epoch 115/200\n",
      "39/39 - 0s - loss: 0.4998 - mae: 0.5376 - val_loss: 0.5093 - val_mae: 0.5320\n",
      "Epoch 116/200\n",
      "39/39 - 0s - loss: 0.4998 - mae: 0.5368 - val_loss: 0.5192 - val_mae: 0.5370\n",
      "Epoch 117/200\n",
      "39/39 - 0s - loss: 0.5009 - mae: 0.5367 - val_loss: 0.5038 - val_mae: 0.5296\n",
      "Epoch 118/200\n",
      "39/39 - 0s - loss: 0.4984 - mae: 0.5369 - val_loss: 0.4992 - val_mae: 0.5293\n",
      "Epoch 119/200\n",
      "39/39 - 0s - loss: 0.5018 - mae: 0.5388 - val_loss: 0.5016 - val_mae: 0.5280\n",
      "Epoch 120/200\n",
      "39/39 - 0s - loss: 0.4987 - mae: 0.5368 - val_loss: 0.5006 - val_mae: 0.5283\n",
      "Epoch 121/200\n",
      "39/39 - 0s - loss: 0.4956 - mae: 0.5359 - val_loss: 0.5004 - val_mae: 0.5276\n",
      "Epoch 122/200\n",
      "39/39 - 0s - loss: 0.4985 - mae: 0.5375 - val_loss: 0.5029 - val_mae: 0.5285\n",
      "Epoch 123/200\n",
      "39/39 - 0s - loss: 0.4952 - mae: 0.5362 - val_loss: 0.5007 - val_mae: 0.5296\n",
      "Epoch 124/200\n",
      "39/39 - 0s - loss: 0.4935 - mae: 0.5342 - val_loss: 0.5013 - val_mae: 0.5307\n",
      "Epoch 125/200\n",
      "39/39 - 0s - loss: 0.4953 - mae: 0.5376 - val_loss: 0.4998 - val_mae: 0.5286\n",
      "Epoch 126/200\n",
      "39/39 - 0s - loss: 0.4946 - mae: 0.5357 - val_loss: 0.4983 - val_mae: 0.5267\n",
      "Epoch 127/200\n",
      "39/39 - 0s - loss: 0.4936 - mae: 0.5348 - val_loss: 0.4969 - val_mae: 0.5279\n",
      "Epoch 128/200\n",
      "39/39 - 0s - loss: 0.4925 - mae: 0.5348 - val_loss: 0.4997 - val_mae: 0.5277\n",
      "Epoch 129/200\n",
      "39/39 - 0s - loss: 0.4906 - mae: 0.5334 - val_loss: 0.4993 - val_mae: 0.5295\n",
      "Epoch 130/200\n",
      "39/39 - 0s - loss: 0.4924 - mae: 0.5345 - val_loss: 0.4966 - val_mae: 0.5296\n",
      "Epoch 131/200\n",
      "39/39 - 0s - loss: 0.4918 - mae: 0.5346 - val_loss: 0.4981 - val_mae: 0.5273\n",
      "Epoch 132/200\n",
      "39/39 - 0s - loss: 0.4902 - mae: 0.5343 - val_loss: 0.4981 - val_mae: 0.5289\n",
      "Epoch 133/200\n",
      "39/39 - 0s - loss: 0.4916 - mae: 0.5349 - val_loss: 0.5029 - val_mae: 0.5286\n",
      "Epoch 134/200\n",
      "39/39 - 0s - loss: 0.4891 - mae: 0.5326 - val_loss: 0.4959 - val_mae: 0.5292\n",
      "Epoch 135/200\n",
      "39/39 - 0s - loss: 0.4892 - mae: 0.5330 - val_loss: 0.5008 - val_mae: 0.5283\n",
      "Epoch 136/200\n",
      "39/39 - 0s - loss: 0.4944 - mae: 0.5349 - val_loss: 0.4943 - val_mae: 0.5276\n",
      "Epoch 137/200\n",
      "39/39 - 0s - loss: 0.4884 - mae: 0.5331 - val_loss: 0.5053 - val_mae: 0.5306\n",
      "Epoch 138/200\n",
      "39/39 - 0s - loss: 0.4874 - mae: 0.5324 - val_loss: 0.4983 - val_mae: 0.5267\n",
      "Epoch 139/200\n",
      "39/39 - 0s - loss: 0.4884 - mae: 0.5318 - val_loss: 0.4999 - val_mae: 0.5275\n",
      "Epoch 140/200\n",
      "39/39 - 0s - loss: 0.4864 - mae: 0.5325 - val_loss: 0.4956 - val_mae: 0.5289\n",
      "Epoch 141/200\n",
      "39/39 - 0s - loss: 0.4877 - mae: 0.5331 - val_loss: 0.4968 - val_mae: 0.5273\n",
      "Epoch 142/200\n",
      "39/39 - 0s - loss: 0.4863 - mae: 0.5326 - val_loss: 0.4940 - val_mae: 0.5265\n",
      "Epoch 143/200\n",
      "39/39 - 0s - loss: 0.4843 - mae: 0.5311 - val_loss: 0.4973 - val_mae: 0.5305\n",
      "Epoch 144/200\n",
      "39/39 - 0s - loss: 0.4876 - mae: 0.5312 - val_loss: 0.4974 - val_mae: 0.5289\n",
      "Epoch 145/200\n",
      "39/39 - 0s - loss: 0.4866 - mae: 0.5335 - val_loss: 0.4964 - val_mae: 0.5279\n",
      "Epoch 146/200\n",
      "39/39 - 0s - loss: 0.4872 - mae: 0.5326 - val_loss: 0.4955 - val_mae: 0.5298\n",
      "Epoch 147/200\n",
      "39/39 - 0s - loss: 0.4826 - mae: 0.5308 - val_loss: 0.4973 - val_mae: 0.5286\n",
      "Epoch 148/200\n",
      "39/39 - 0s - loss: 0.4833 - mae: 0.5309 - val_loss: 0.4947 - val_mae: 0.5294\n",
      "Epoch 149/200\n",
      "39/39 - 0s - loss: 0.4822 - mae: 0.5312 - val_loss: 0.4999 - val_mae: 0.5285\n",
      "Epoch 150/200\n",
      "39/39 - 0s - loss: 0.4825 - mae: 0.5303 - val_loss: 0.4983 - val_mae: 0.5305\n",
      "Epoch 151/200\n",
      "39/39 - 0s - loss: 0.4819 - mae: 0.5304 - val_loss: 0.4944 - val_mae: 0.5289\n",
      "Epoch 152/200\n",
      "39/39 - 0s - loss: 0.4810 - mae: 0.5308 - val_loss: 0.4959 - val_mae: 0.5298\n",
      "Epoch 153/200\n",
      "39/39 - 0s - loss: 0.4826 - mae: 0.5310 - val_loss: 0.4929 - val_mae: 0.5274\n",
      "Epoch 154/200\n",
      "39/39 - 0s - loss: 0.4813 - mae: 0.5306 - val_loss: 0.4948 - val_mae: 0.5277\n",
      "Epoch 155/200\n",
      "39/39 - 0s - loss: 0.4807 - mae: 0.5297 - val_loss: 0.4950 - val_mae: 0.5309\n",
      "Epoch 156/200\n",
      "39/39 - 0s - loss: 0.4835 - mae: 0.5324 - val_loss: 0.4936 - val_mae: 0.5291\n",
      "Epoch 157/200\n",
      "39/39 - 0s - loss: 0.4817 - mae: 0.5306 - val_loss: 0.4945 - val_mae: 0.5308\n",
      "Epoch 158/200\n",
      "39/39 - 0s - loss: 0.4815 - mae: 0.5314 - val_loss: 0.4948 - val_mae: 0.5284\n",
      "Epoch 159/200\n",
      "39/39 - 0s - loss: 0.4793 - mae: 0.5294 - val_loss: 0.4997 - val_mae: 0.5307\n",
      "Epoch 160/200\n",
      "39/39 - 0s - loss: 0.4793 - mae: 0.5294 - val_loss: 0.4971 - val_mae: 0.5282\n",
      "Epoch 161/200\n",
      "39/39 - 0s - loss: 0.4793 - mae: 0.5289 - val_loss: 0.4933 - val_mae: 0.5300\n",
      "Epoch 162/200\n",
      "39/39 - 0s - loss: 0.4797 - mae: 0.5305 - val_loss: 0.4970 - val_mae: 0.5299\n",
      "Epoch 163/200\n",
      "39/39 - 0s - loss: 0.4786 - mae: 0.5304 - val_loss: 0.4937 - val_mae: 0.5284\n",
      "Epoch 164/200\n",
      "39/39 - 0s - loss: 0.4776 - mae: 0.5297 - val_loss: 0.4935 - val_mae: 0.5289\n",
      "Epoch 165/200\n",
      "39/39 - 0s - loss: 0.4791 - mae: 0.5286 - val_loss: 0.4941 - val_mae: 0.5281\n",
      "Epoch 166/200\n",
      "39/39 - 0s - loss: 0.4769 - mae: 0.5286 - val_loss: 0.4926 - val_mae: 0.5282\n",
      "Epoch 167/200\n",
      "39/39 - 0s - loss: 0.4785 - mae: 0.5302 - val_loss: 0.4953 - val_mae: 0.5303\n",
      "Epoch 168/200\n",
      "39/39 - 0s - loss: 0.4798 - mae: 0.5296 - val_loss: 0.4939 - val_mae: 0.5296\n",
      "Epoch 169/200\n",
      "39/39 - 0s - loss: 0.4769 - mae: 0.5291 - val_loss: 0.4967 - val_mae: 0.5305\n",
      "Epoch 170/200\n",
      "39/39 - 0s - loss: 0.4763 - mae: 0.5278 - val_loss: 0.4935 - val_mae: 0.5296\n",
      "Epoch 171/200\n",
      "39/39 - 0s - loss: 0.4794 - mae: 0.5301 - val_loss: 0.5026 - val_mae: 0.5345\n",
      "Epoch 172/200\n",
      "39/39 - 0s - loss: 0.4769 - mae: 0.5286 - val_loss: 0.4958 - val_mae: 0.5328\n",
      "Epoch 173/200\n",
      "39/39 - 0s - loss: 0.4770 - mae: 0.5279 - val_loss: 0.4928 - val_mae: 0.5308\n",
      "Epoch 174/200\n",
      "39/39 - 0s - loss: 0.4738 - mae: 0.5267 - val_loss: 0.4956 - val_mae: 0.5298\n",
      "Epoch 175/200\n",
      "39/39 - 0s - loss: 0.4734 - mae: 0.5279 - val_loss: 0.4978 - val_mae: 0.5314\n",
      "Epoch 176/200\n",
      "39/39 - 0s - loss: 0.4753 - mae: 0.5279 - val_loss: 0.4930 - val_mae: 0.5325\n",
      "Epoch 177/200\n",
      "39/39 - 0s - loss: 0.4748 - mae: 0.5289 - val_loss: 0.4933 - val_mae: 0.5301\n",
      "Epoch 178/200\n",
      "39/39 - 0s - loss: 0.4771 - mae: 0.5287 - val_loss: 0.5016 - val_mae: 0.5315\n",
      "Epoch 179/200\n",
      "39/39 - 0s - loss: 0.4758 - mae: 0.5294 - val_loss: 0.4936 - val_mae: 0.5317\n",
      "Epoch 180/200\n",
      "39/39 - 0s - loss: 0.4734 - mae: 0.5273 - val_loss: 0.5003 - val_mae: 0.5317\n",
      "Epoch 181/200\n",
      "39/39 - 0s - loss: 0.4736 - mae: 0.5265 - val_loss: 0.4956 - val_mae: 0.5299\n",
      "Epoch 182/200\n",
      "39/39 - 0s - loss: 0.4741 - mae: 0.5286 - val_loss: 0.4979 - val_mae: 0.5344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200\n",
      "39/39 - 0s - loss: 0.4761 - mae: 0.5298 - val_loss: 0.4969 - val_mae: 0.5305\n",
      "Epoch 184/200\n",
      "39/39 - 0s - loss: 0.4712 - mae: 0.5257 - val_loss: 0.4955 - val_mae: 0.5323\n",
      "Epoch 185/200\n",
      "39/39 - 0s - loss: 0.4725 - mae: 0.5269 - val_loss: 0.4961 - val_mae: 0.5302\n",
      "Epoch 186/200\n",
      "39/39 - 0s - loss: 0.4711 - mae: 0.5266 - val_loss: 0.4951 - val_mae: 0.5305\n",
      "Epoch 187/200\n",
      "39/39 - 0s - loss: 0.4718 - mae: 0.5255 - val_loss: 0.4948 - val_mae: 0.5330\n",
      "Epoch 188/200\n",
      "39/39 - 0s - loss: 0.4758 - mae: 0.5282 - val_loss: 0.4927 - val_mae: 0.5300\n",
      "Epoch 189/200\n",
      "39/39 - 0s - loss: 0.4721 - mae: 0.5262 - val_loss: 0.4961 - val_mae: 0.5316\n",
      "Epoch 190/200\n",
      "39/39 - 0s - loss: 0.4731 - mae: 0.5284 - val_loss: 0.4983 - val_mae: 0.5322\n",
      "Epoch 191/200\n",
      "39/39 - 0s - loss: 0.4709 - mae: 0.5252 - val_loss: 0.4935 - val_mae: 0.5319\n",
      "Epoch 192/200\n",
      "39/39 - 0s - loss: 0.4699 - mae: 0.5247 - val_loss: 0.4936 - val_mae: 0.5325\n",
      "Epoch 193/200\n",
      "39/39 - 0s - loss: 0.4711 - mae: 0.5261 - val_loss: 0.4914 - val_mae: 0.5323\n",
      "Epoch 194/200\n",
      "39/39 - 0s - loss: 0.4693 - mae: 0.5246 - val_loss: 0.4916 - val_mae: 0.5311\n",
      "Epoch 195/200\n",
      "39/39 - 0s - loss: 0.4699 - mae: 0.5251 - val_loss: 0.4982 - val_mae: 0.5321\n",
      "Epoch 196/200\n",
      "39/39 - 0s - loss: 0.4729 - mae: 0.5268 - val_loss: 0.4938 - val_mae: 0.5334\n",
      "Epoch 197/200\n",
      "39/39 - 0s - loss: 0.4699 - mae: 0.5255 - val_loss: 0.5016 - val_mae: 0.5355\n",
      "Epoch 198/200\n",
      "39/39 - 0s - loss: 0.4700 - mae: 0.5247 - val_loss: 0.5008 - val_mae: 0.5349\n",
      "Epoch 199/200\n",
      "39/39 - 0s - loss: 0.4727 - mae: 0.5279 - val_loss: 0.4968 - val_mae: 0.5341\n",
      "Epoch 200/200\n",
      "39/39 - 0s - loss: 0.4683 - mae: 0.5241 - val_loss: 0.4947 - val_mae: 0.5332\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 985us/step - loss: 0.4907 - mae: 0.5355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb685ceaf0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_trans, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 - 0s - loss: 0.4863 - mae: 0.5267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4862551689147949, 0.526662290096283]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test,y_test,batch_size=42,verbose=2)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.title('Loss / Mean Squared Error')\n",
    "pyplot.plot(history.history['loss'], label='train_loss')\n",
    "pyplot.plot(history.history['val_loss'], label='train_val')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       ...,\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2178    7\n",
       "1867    6\n",
       "4388    5\n",
       "4277    5\n",
       "3770    7\n",
       "       ..\n",
       "2089    6\n",
       "1976    7\n",
       "6421    6\n",
       "1683    5\n",
       "2161    6\n",
       "Name: quality, Length: 1625, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2795838357108186"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score(y_test,y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5624615384615385"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2732245196749292"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_nn =  pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_nn['error'] = ('mse', 'r2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_nn['Full_NN'] = (0.56,0.27) \n",
    "df_score_nn['NN_redwine'] = (0.60,0.13) \n",
    "df_score_nn['NN_whitewine'] = (0.75,0.09) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>Full_NN</th>\n",
       "      <th>NN_redwine</th>\n",
       "      <th>NN_whitewine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  error  Full_NN  NN_redwine  NN_whitewine\n",
       "0   mse     0.56        0.60          0.75\n",
       "1    r2     0.27        0.13          0.09"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
