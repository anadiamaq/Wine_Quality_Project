{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality   type  \n",
       "0      8.8        6  white  \n",
       "1      9.5        6  white  \n",
       "2     10.1        6  white  \n",
       "3      9.9        6  white  \n",
       "4      9.9        6  white  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_white = pd.read_csv('data/whitewine-qa.csv')\n",
    "df_white.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_white['quality']\n",
    "X = df_white.drop(columns=['quality','type','citric_acid','chlorides', 'density', 'total_sulfur_dioxide'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "prep = StandardScaler()\n",
    "prep.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_shape=(7,),kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= 'mse',\n",
    "              optimizer= 'adam',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "29/29 - 0s - loss: 20.8422 - mae: 4.1190 - val_loss: 9.2278 - val_mae: 2.6148\n",
      "Epoch 2/200\n",
      "29/29 - 0s - loss: 7.1663 - mae: 2.2533 - val_loss: 5.7016 - val_mae: 2.0294\n",
      "Epoch 3/200\n",
      "29/29 - 0s - loss: 4.5152 - mae: 1.7584 - val_loss: 3.4302 - val_mae: 1.5426\n",
      "Epoch 4/200\n",
      "29/29 - 0s - loss: 2.5715 - mae: 1.2790 - val_loss: 1.8302 - val_mae: 1.0775\n",
      "Epoch 5/200\n",
      "29/29 - 0s - loss: 1.4345 - mae: 0.9095 - val_loss: 1.1589 - val_mae: 0.8248\n",
      "Epoch 6/200\n",
      "29/29 - 0s - loss: 1.0432 - mae: 0.7549 - val_loss: 0.9204 - val_mae: 0.7162\n",
      "Epoch 7/200\n",
      "29/29 - 0s - loss: 0.8873 - mae: 0.6833 - val_loss: 0.8248 - val_mae: 0.6729\n",
      "Epoch 8/200\n",
      "29/29 - 0s - loss: 0.8243 - mae: 0.6574 - val_loss: 0.7825 - val_mae: 0.6547\n",
      "Epoch 9/200\n",
      "29/29 - 0s - loss: 0.7931 - mae: 0.6469 - val_loss: 0.7672 - val_mae: 0.6487\n",
      "Epoch 10/200\n",
      "29/29 - 0s - loss: 0.7747 - mae: 0.6426 - val_loss: 0.7553 - val_mae: 0.6466\n",
      "Epoch 11/200\n",
      "29/29 - 0s - loss: 0.7613 - mae: 0.6402 - val_loss: 0.7337 - val_mae: 0.6370\n",
      "Epoch 12/200\n",
      "29/29 - 0s - loss: 0.7449 - mae: 0.6358 - val_loss: 0.7280 - val_mae: 0.6350\n",
      "Epoch 13/200\n",
      "29/29 - 0s - loss: 0.7347 - mae: 0.6331 - val_loss: 0.7142 - val_mae: 0.6290\n",
      "Epoch 14/200\n",
      "29/29 - 0s - loss: 0.7273 - mae: 0.6314 - val_loss: 0.7056 - val_mae: 0.6259\n",
      "Epoch 15/200\n",
      "29/29 - 0s - loss: 0.7146 - mae: 0.6283 - val_loss: 0.7031 - val_mae: 0.6238\n",
      "Epoch 16/200\n",
      "29/29 - 0s - loss: 0.7089 - mae: 0.6261 - val_loss: 0.6922 - val_mae: 0.6193\n",
      "Epoch 17/200\n",
      "29/29 - 0s - loss: 0.6965 - mae: 0.6214 - val_loss: 0.6875 - val_mae: 0.6173\n",
      "Epoch 18/200\n",
      "29/29 - 0s - loss: 0.6930 - mae: 0.6222 - val_loss: 0.6829 - val_mae: 0.6161\n",
      "Epoch 19/200\n",
      "29/29 - 0s - loss: 0.6891 - mae: 0.6194 - val_loss: 0.6797 - val_mae: 0.6137\n",
      "Epoch 20/200\n",
      "29/29 - 0s - loss: 0.6831 - mae: 0.6204 - val_loss: 0.6747 - val_mae: 0.6123\n",
      "Epoch 21/200\n",
      "29/29 - 0s - loss: 0.6769 - mae: 0.6169 - val_loss: 0.6711 - val_mae: 0.6104\n",
      "Epoch 22/200\n",
      "29/29 - 0s - loss: 0.6744 - mae: 0.6162 - val_loss: 0.6688 - val_mae: 0.6082\n",
      "Epoch 23/200\n",
      "29/29 - 0s - loss: 0.6687 - mae: 0.6144 - val_loss: 0.6651 - val_mae: 0.6081\n",
      "Epoch 24/200\n",
      "29/29 - 0s - loss: 0.6661 - mae: 0.6138 - val_loss: 0.6620 - val_mae: 0.6066\n",
      "Epoch 25/200\n",
      "29/29 - 0s - loss: 0.6650 - mae: 0.6136 - val_loss: 0.6609 - val_mae: 0.6076\n",
      "Epoch 26/200\n",
      "29/29 - 0s - loss: 0.6595 - mae: 0.6123 - val_loss: 0.6556 - val_mae: 0.6049\n",
      "Epoch 27/200\n",
      "29/29 - 0s - loss: 0.6565 - mae: 0.6113 - val_loss: 0.6543 - val_mae: 0.6028\n",
      "Epoch 28/200\n",
      "29/29 - 0s - loss: 0.6542 - mae: 0.6108 - val_loss: 0.6525 - val_mae: 0.6012\n",
      "Epoch 29/200\n",
      "29/29 - 0s - loss: 0.6519 - mae: 0.6092 - val_loss: 0.6503 - val_mae: 0.6020\n",
      "Epoch 30/200\n",
      "29/29 - 0s - loss: 0.6513 - mae: 0.6095 - val_loss: 0.6487 - val_mae: 0.6021\n",
      "Epoch 31/200\n",
      "29/29 - 0s - loss: 0.6490 - mae: 0.6073 - val_loss: 0.6487 - val_mae: 0.5993\n",
      "Epoch 32/200\n",
      "29/29 - 0s - loss: 0.6475 - mae: 0.6079 - val_loss: 0.6472 - val_mae: 0.6023\n",
      "Epoch 33/200\n",
      "29/29 - 0s - loss: 0.6420 - mae: 0.6060 - val_loss: 0.6430 - val_mae: 0.5993\n",
      "Epoch 34/200\n",
      "29/29 - 0s - loss: 0.6406 - mae: 0.6053 - val_loss: 0.6451 - val_mae: 0.6017\n",
      "Epoch 35/200\n",
      "29/29 - 0s - loss: 0.6435 - mae: 0.6074 - val_loss: 0.6426 - val_mae: 0.6002\n",
      "Epoch 36/200\n",
      "29/29 - 0s - loss: 0.6382 - mae: 0.6042 - val_loss: 0.6388 - val_mae: 0.5957\n",
      "Epoch 37/200\n",
      "29/29 - 0s - loss: 0.6368 - mae: 0.6039 - val_loss: 0.6432 - val_mae: 0.6012\n",
      "Epoch 38/200\n",
      "29/29 - 0s - loss: 0.6420 - mae: 0.6081 - val_loss: 0.6421 - val_mae: 0.6018\n",
      "Epoch 39/200\n",
      "29/29 - 0s - loss: 0.6374 - mae: 0.6049 - val_loss: 0.6348 - val_mae: 0.5953\n",
      "Epoch 40/200\n",
      "29/29 - 0s - loss: 0.6348 - mae: 0.6018 - val_loss: 0.6353 - val_mae: 0.5971\n",
      "Epoch 41/200\n",
      "29/29 - 0s - loss: 0.6314 - mae: 0.6019 - val_loss: 0.6393 - val_mae: 0.6001\n",
      "Epoch 42/200\n",
      "29/29 - 0s - loss: 0.6323 - mae: 0.6031 - val_loss: 0.6311 - val_mae: 0.5922\n",
      "Epoch 43/200\n",
      "29/29 - 0s - loss: 0.6306 - mae: 0.6013 - val_loss: 0.6336 - val_mae: 0.5972\n",
      "Epoch 44/200\n",
      "29/29 - 0s - loss: 0.6311 - mae: 0.6026 - val_loss: 0.6329 - val_mae: 0.5968\n",
      "Epoch 45/200\n",
      "29/29 - 0s - loss: 0.6299 - mae: 0.6018 - val_loss: 0.6289 - val_mae: 0.5926\n",
      "Epoch 46/200\n",
      "29/29 - 0s - loss: 0.6276 - mae: 0.6011 - val_loss: 0.6392 - val_mae: 0.5925\n",
      "Epoch 47/200\n",
      "29/29 - 0s - loss: 0.6264 - mae: 0.6012 - val_loss: 0.6276 - val_mae: 0.5911\n",
      "Epoch 48/200\n",
      "29/29 - 0s - loss: 0.6236 - mae: 0.5993 - val_loss: 0.6263 - val_mae: 0.5920\n",
      "Epoch 49/200\n",
      "29/29 - 0s - loss: 0.6220 - mae: 0.5982 - val_loss: 0.6269 - val_mae: 0.5903\n",
      "Epoch 50/200\n",
      "29/29 - 0s - loss: 0.6222 - mae: 0.5992 - val_loss: 0.6268 - val_mae: 0.5937\n",
      "Epoch 51/200\n",
      "29/29 - 0s - loss: 0.6223 - mae: 0.5989 - val_loss: 0.6290 - val_mae: 0.5955\n",
      "Epoch 52/200\n",
      "29/29 - 0s - loss: 0.6200 - mae: 0.5974 - val_loss: 0.6235 - val_mae: 0.5894\n",
      "Epoch 53/200\n",
      "29/29 - 0s - loss: 0.6194 - mae: 0.5982 - val_loss: 0.6230 - val_mae: 0.5894\n",
      "Epoch 54/200\n",
      "29/29 - 0s - loss: 0.6204 - mae: 0.5989 - val_loss: 0.6258 - val_mae: 0.5933\n",
      "Epoch 55/200\n",
      "29/29 - 0s - loss: 0.6204 - mae: 0.5979 - val_loss: 0.6291 - val_mae: 0.5966\n",
      "Epoch 56/200\n",
      "29/29 - 0s - loss: 0.6214 - mae: 0.5990 - val_loss: 0.6296 - val_mae: 0.5971\n",
      "Epoch 57/200\n",
      "29/29 - 0s - loss: 0.6221 - mae: 0.6002 - val_loss: 0.6340 - val_mae: 0.5900\n",
      "Epoch 58/200\n",
      "29/29 - 0s - loss: 0.6216 - mae: 0.5996 - val_loss: 0.6233 - val_mae: 0.5881\n",
      "Epoch 59/200\n",
      "29/29 - 0s - loss: 0.6185 - mae: 0.5975 - val_loss: 0.6219 - val_mae: 0.5917\n",
      "Epoch 60/200\n",
      "29/29 - 0s - loss: 0.6233 - mae: 0.5989 - val_loss: 0.6257 - val_mae: 0.5953\n",
      "Epoch 61/200\n",
      "29/29 - 0s - loss: 0.6206 - mae: 0.5983 - val_loss: 0.6289 - val_mae: 0.5975\n",
      "Epoch 62/200\n",
      "29/29 - 0s - loss: 0.6169 - mae: 0.5981 - val_loss: 0.6184 - val_mae: 0.5891\n",
      "Epoch 63/200\n",
      "29/29 - 0s - loss: 0.6140 - mae: 0.5949 - val_loss: 0.6201 - val_mae: 0.5904\n",
      "Epoch 64/200\n",
      "29/29 - 0s - loss: 0.6143 - mae: 0.5951 - val_loss: 0.6204 - val_mae: 0.5914\n",
      "Epoch 65/200\n",
      "29/29 - 0s - loss: 0.6120 - mae: 0.5957 - val_loss: 0.6172 - val_mae: 0.5890\n",
      "Epoch 66/200\n",
      "29/29 - 0s - loss: 0.6101 - mae: 0.5944 - val_loss: 0.6272 - val_mae: 0.5875\n",
      "Epoch 67/200\n",
      "29/29 - 0s - loss: 0.6158 - mae: 0.5960 - val_loss: 0.6175 - val_mae: 0.5872\n",
      "Epoch 68/200\n",
      "29/29 - 0s - loss: 0.6109 - mae: 0.5941 - val_loss: 0.6159 - val_mae: 0.5879\n",
      "Epoch 69/200\n",
      "29/29 - 0s - loss: 0.6146 - mae: 0.5957 - val_loss: 0.6173 - val_mae: 0.5860\n",
      "Epoch 70/200\n",
      "29/29 - 0s - loss: 0.6128 - mae: 0.5960 - val_loss: 0.6158 - val_mae: 0.5884\n",
      "Epoch 71/200\n",
      "29/29 - 0s - loss: 0.6091 - mae: 0.5937 - val_loss: 0.6176 - val_mae: 0.5867\n",
      "Epoch 72/200\n",
      "29/29 - 0s - loss: 0.6106 - mae: 0.5947 - val_loss: 0.6350 - val_mae: 0.5891\n",
      "Epoch 73/200\n",
      "29/29 - 0s - loss: 0.6133 - mae: 0.5956 - val_loss: 0.6249 - val_mae: 0.5862\n",
      "Epoch 74/200\n",
      "29/29 - 0s - loss: 0.6085 - mae: 0.5936 - val_loss: 0.6177 - val_mae: 0.5919\n",
      "Epoch 75/200\n",
      "29/29 - 0s - loss: 0.6069 - mae: 0.5933 - val_loss: 0.6145 - val_mae: 0.5853\n",
      "Epoch 76/200\n",
      "29/29 - 0s - loss: 0.6149 - mae: 0.5971 - val_loss: 0.6146 - val_mae: 0.5855\n",
      "Epoch 77/200\n",
      "29/29 - 0s - loss: 0.6069 - mae: 0.5936 - val_loss: 0.6128 - val_mae: 0.5878\n",
      "Epoch 78/200\n",
      "29/29 - 0s - loss: 0.6130 - mae: 0.5965 - val_loss: 0.6121 - val_mae: 0.5869\n",
      "Epoch 79/200\n",
      "29/29 - 0s - loss: 0.6047 - mae: 0.5922 - val_loss: 0.6259 - val_mae: 0.5970\n",
      "Epoch 80/200\n",
      "29/29 - 0s - loss: 0.6120 - mae: 0.5959 - val_loss: 0.6201 - val_mae: 0.5940\n",
      "Epoch 81/200\n",
      "29/29 - 0s - loss: 0.6042 - mae: 0.5910 - val_loss: 0.6127 - val_mae: 0.5861\n",
      "Epoch 82/200\n",
      "29/29 - 0s - loss: 0.6060 - mae: 0.5925 - val_loss: 0.6140 - val_mae: 0.5894\n",
      "Epoch 83/200\n",
      "29/29 - 0s - loss: 0.6040 - mae: 0.5924 - val_loss: 0.6136 - val_mae: 0.5853\n",
      "Epoch 84/200\n",
      "29/29 - 0s - loss: 0.6012 - mae: 0.5906 - val_loss: 0.6176 - val_mae: 0.5921\n",
      "Epoch 85/200\n",
      "29/29 - 0s - loss: 0.6028 - mae: 0.5922 - val_loss: 0.6140 - val_mae: 0.5854\n",
      "Epoch 86/200\n",
      "29/29 - 0s - loss: 0.6020 - mae: 0.5913 - val_loss: 0.6127 - val_mae: 0.5857\n",
      "Epoch 87/200\n",
      "29/29 - 0s - loss: 0.6071 - mae: 0.5937 - val_loss: 0.6140 - val_mae: 0.5852\n",
      "Epoch 88/200\n",
      "29/29 - 0s - loss: 0.6017 - mae: 0.5901 - val_loss: 0.6203 - val_mae: 0.5944\n",
      "Epoch 89/200\n",
      "29/29 - 0s - loss: 0.6018 - mae: 0.5907 - val_loss: 0.6100 - val_mae: 0.5858\n",
      "Epoch 90/200\n",
      "29/29 - 0s - loss: 0.5991 - mae: 0.5890 - val_loss: 0.6143 - val_mae: 0.5857\n",
      "Epoch 91/200\n",
      "29/29 - 0s - loss: 0.6006 - mae: 0.5907 - val_loss: 0.6192 - val_mae: 0.5844\n",
      "Epoch 92/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 0s - loss: 0.6037 - mae: 0.5907 - val_loss: 0.6120 - val_mae: 0.5847\n",
      "Epoch 93/200\n",
      "29/29 - 0s - loss: 0.6002 - mae: 0.5895 - val_loss: 0.6192 - val_mae: 0.5939\n",
      "Epoch 94/200\n",
      "29/29 - 0s - loss: 0.5986 - mae: 0.5889 - val_loss: 0.6097 - val_mae: 0.5863\n",
      "Epoch 95/200\n",
      "29/29 - 0s - loss: 0.5992 - mae: 0.5893 - val_loss: 0.6178 - val_mae: 0.5934\n",
      "Epoch 96/200\n",
      "29/29 - 0s - loss: 0.5965 - mae: 0.5878 - val_loss: 0.6112 - val_mae: 0.5882\n",
      "Epoch 97/200\n",
      "29/29 - 0s - loss: 0.5969 - mae: 0.5880 - val_loss: 0.6125 - val_mae: 0.5884\n",
      "Epoch 98/200\n",
      "29/29 - 0s - loss: 0.6001 - mae: 0.5907 - val_loss: 0.6136 - val_mae: 0.5864\n",
      "Epoch 99/200\n",
      "29/29 - 0s - loss: 0.5957 - mae: 0.5867 - val_loss: 0.6099 - val_mae: 0.5843\n",
      "Epoch 100/200\n",
      "29/29 - 0s - loss: 0.6006 - mae: 0.5902 - val_loss: 0.6113 - val_mae: 0.5862\n",
      "Epoch 101/200\n",
      "29/29 - 0s - loss: 0.5953 - mae: 0.5881 - val_loss: 0.6099 - val_mae: 0.5847\n",
      "Epoch 102/200\n",
      "29/29 - 0s - loss: 0.5955 - mae: 0.5878 - val_loss: 0.6107 - val_mae: 0.5850\n",
      "Epoch 103/200\n",
      "29/29 - 0s - loss: 0.5942 - mae: 0.5865 - val_loss: 0.6119 - val_mae: 0.5886\n",
      "Epoch 104/200\n",
      "29/29 - 0s - loss: 0.5964 - mae: 0.5883 - val_loss: 0.6279 - val_mae: 0.5873\n",
      "Epoch 105/200\n",
      "29/29 - 0s - loss: 0.6020 - mae: 0.5914 - val_loss: 0.6171 - val_mae: 0.5861\n",
      "Epoch 106/200\n",
      "29/29 - 0s - loss: 0.6294 - mae: 0.6010 - val_loss: 0.6352 - val_mae: 0.6048\n",
      "Epoch 107/200\n",
      "29/29 - 0s - loss: 0.5971 - mae: 0.5880 - val_loss: 0.6100 - val_mae: 0.5857\n",
      "Epoch 108/200\n",
      "29/29 - 0s - loss: 0.5942 - mae: 0.5870 - val_loss: 0.6124 - val_mae: 0.5839\n",
      "Epoch 109/200\n",
      "29/29 - 0s - loss: 0.5942 - mae: 0.5868 - val_loss: 0.6140 - val_mae: 0.5847\n",
      "Epoch 110/200\n",
      "29/29 - 0s - loss: 0.5966 - mae: 0.5885 - val_loss: 0.6116 - val_mae: 0.5832\n",
      "Epoch 111/200\n",
      "29/29 - 0s - loss: 0.5922 - mae: 0.5858 - val_loss: 0.6136 - val_mae: 0.5857\n",
      "Epoch 112/200\n",
      "29/29 - 0s - loss: 0.5952 - mae: 0.5882 - val_loss: 0.6085 - val_mae: 0.5868\n",
      "Epoch 113/200\n",
      "29/29 - 0s - loss: 0.5913 - mae: 0.5855 - val_loss: 0.6250 - val_mae: 0.6001\n",
      "Epoch 114/200\n",
      "29/29 - 0s - loss: 0.5970 - mae: 0.5881 - val_loss: 0.6099 - val_mae: 0.5884\n",
      "Epoch 115/200\n",
      "29/29 - 0s - loss: 0.5948 - mae: 0.5866 - val_loss: 0.6083 - val_mae: 0.5836\n",
      "Epoch 116/200\n",
      "29/29 - 0s - loss: 0.5925 - mae: 0.5871 - val_loss: 0.6149 - val_mae: 0.5932\n",
      "Epoch 117/200\n",
      "29/29 - 0s - loss: 0.5904 - mae: 0.5858 - val_loss: 0.6079 - val_mae: 0.5842\n",
      "Epoch 118/200\n",
      "29/29 - 0s - loss: 0.5955 - mae: 0.5873 - val_loss: 0.6085 - val_mae: 0.5825\n",
      "Epoch 119/200\n",
      "29/29 - 0s - loss: 0.5948 - mae: 0.5864 - val_loss: 0.6273 - val_mae: 0.5864\n",
      "Epoch 120/200\n",
      "29/29 - 0s - loss: 0.6125 - mae: 0.5972 - val_loss: 0.6163 - val_mae: 0.5944\n",
      "Epoch 121/200\n",
      "29/29 - 0s - loss: 0.5996 - mae: 0.5886 - val_loss: 0.6399 - val_mae: 0.6092\n",
      "Epoch 122/200\n",
      "29/29 - 0s - loss: 0.6108 - mae: 0.5965 - val_loss: 0.6480 - val_mae: 0.6149\n",
      "Epoch 123/200\n",
      "29/29 - 0s - loss: 0.6060 - mae: 0.5939 - val_loss: 0.6123 - val_mae: 0.5876\n",
      "Epoch 124/200\n",
      "29/29 - 0s - loss: 0.5892 - mae: 0.5852 - val_loss: 0.6354 - val_mae: 0.6068\n",
      "Epoch 125/200\n",
      "29/29 - 0s - loss: 0.5937 - mae: 0.5882 - val_loss: 0.6089 - val_mae: 0.5850\n",
      "Epoch 126/200\n",
      "29/29 - 0s - loss: 0.5882 - mae: 0.5842 - val_loss: 0.6126 - val_mae: 0.5922\n",
      "Epoch 127/200\n",
      "29/29 - 0s - loss: 0.5918 - mae: 0.5870 - val_loss: 0.6081 - val_mae: 0.5854\n",
      "Epoch 128/200\n",
      "29/29 - 0s - loss: 0.5869 - mae: 0.5841 - val_loss: 0.6067 - val_mae: 0.5859\n",
      "Epoch 129/200\n",
      "29/29 - 0s - loss: 0.5913 - mae: 0.5863 - val_loss: 0.6075 - val_mae: 0.5825\n",
      "Epoch 130/200\n",
      "29/29 - 0s - loss: 0.5879 - mae: 0.5850 - val_loss: 0.6060 - val_mae: 0.5840\n",
      "Epoch 131/200\n",
      "29/29 - 0s - loss: 0.5879 - mae: 0.5838 - val_loss: 0.6065 - val_mae: 0.5876\n",
      "Epoch 132/200\n",
      "29/29 - 0s - loss: 0.5876 - mae: 0.5844 - val_loss: 0.6058 - val_mae: 0.5860\n",
      "Epoch 133/200\n",
      "29/29 - 0s - loss: 0.5853 - mae: 0.5840 - val_loss: 0.6072 - val_mae: 0.5828\n",
      "Epoch 134/200\n",
      "29/29 - 0s - loss: 0.5893 - mae: 0.5858 - val_loss: 0.6175 - val_mae: 0.5963\n",
      "Epoch 135/200\n",
      "29/29 - 0s - loss: 0.5870 - mae: 0.5855 - val_loss: 0.6085 - val_mae: 0.5828\n",
      "Epoch 136/200\n",
      "29/29 - 0s - loss: 0.5995 - mae: 0.5898 - val_loss: 0.6126 - val_mae: 0.5928\n",
      "Epoch 137/200\n",
      "29/29 - 0s - loss: 0.5961 - mae: 0.5902 - val_loss: 0.6126 - val_mae: 0.5935\n",
      "Epoch 138/200\n",
      "29/29 - 0s - loss: 0.5844 - mae: 0.5828 - val_loss: 0.6094 - val_mae: 0.5830\n",
      "Epoch 139/200\n",
      "29/29 - 0s - loss: 0.5894 - mae: 0.5855 - val_loss: 0.6096 - val_mae: 0.5857\n",
      "Epoch 140/200\n",
      "29/29 - 0s - loss: 0.5891 - mae: 0.5866 - val_loss: 0.6065 - val_mae: 0.5880\n",
      "Epoch 141/200\n",
      "29/29 - 0s - loss: 0.5870 - mae: 0.5842 - val_loss: 0.6037 - val_mae: 0.5833\n",
      "Epoch 142/200\n",
      "29/29 - 0s - loss: 0.5870 - mae: 0.5840 - val_loss: 0.6038 - val_mae: 0.5846\n",
      "Epoch 143/200\n",
      "29/29 - 0s - loss: 0.5840 - mae: 0.5836 - val_loss: 0.6101 - val_mae: 0.5919\n",
      "Epoch 144/200\n",
      "29/29 - 0s - loss: 0.5859 - mae: 0.5834 - val_loss: 0.6045 - val_mae: 0.5859\n",
      "Epoch 145/200\n",
      "29/29 - 0s - loss: 0.5840 - mae: 0.5822 - val_loss: 0.6046 - val_mae: 0.5837\n",
      "Epoch 146/200\n",
      "29/29 - 0s - loss: 0.5817 - mae: 0.5828 - val_loss: 0.6079 - val_mae: 0.5902\n",
      "Epoch 147/200\n",
      "29/29 - 0s - loss: 0.5868 - mae: 0.5833 - val_loss: 0.6235 - val_mae: 0.6015\n",
      "Epoch 148/200\n",
      "29/29 - 0s - loss: 0.5980 - mae: 0.5906 - val_loss: 0.6312 - val_mae: 0.6063\n",
      "Epoch 149/200\n",
      "29/29 - 0s - loss: 0.5855 - mae: 0.5839 - val_loss: 0.6043 - val_mae: 0.5870\n",
      "Epoch 150/200\n",
      "29/29 - 0s - loss: 0.5816 - mae: 0.5830 - val_loss: 0.6166 - val_mae: 0.5964\n",
      "Epoch 151/200\n",
      "29/29 - 0s - loss: 0.5827 - mae: 0.5828 - val_loss: 0.6031 - val_mae: 0.5834\n",
      "Epoch 152/200\n",
      "29/29 - 0s - loss: 0.5862 - mae: 0.5852 - val_loss: 0.6146 - val_mae: 0.5955\n",
      "Epoch 153/200\n",
      "29/29 - 0s - loss: 0.5874 - mae: 0.5866 - val_loss: 0.6043 - val_mae: 0.5830\n",
      "Epoch 154/200\n",
      "29/29 - 0s - loss: 0.5819 - mae: 0.5829 - val_loss: 0.6026 - val_mae: 0.5838\n",
      "Epoch 155/200\n",
      "29/29 - 0s - loss: 0.5798 - mae: 0.5822 - val_loss: 0.6153 - val_mae: 0.5970\n",
      "Epoch 156/200\n",
      "29/29 - 0s - loss: 0.5854 - mae: 0.5847 - val_loss: 0.6060 - val_mae: 0.5846\n",
      "Epoch 157/200\n",
      "29/29 - 0s - loss: 0.5896 - mae: 0.5852 - val_loss: 0.6020 - val_mae: 0.5829\n",
      "Epoch 158/200\n",
      "29/29 - 0s - loss: 0.5812 - mae: 0.5844 - val_loss: 0.6030 - val_mae: 0.5836\n",
      "Epoch 159/200\n",
      "29/29 - 0s - loss: 0.5854 - mae: 0.5866 - val_loss: 0.6019 - val_mae: 0.5842\n",
      "Epoch 160/200\n",
      "29/29 - 0s - loss: 0.5866 - mae: 0.5855 - val_loss: 0.6013 - val_mae: 0.5854\n",
      "Epoch 161/200\n",
      "29/29 - 0s - loss: 0.5813 - mae: 0.5829 - val_loss: 0.6187 - val_mae: 0.5856\n",
      "Epoch 162/200\n",
      "29/29 - 0s - loss: 0.5805 - mae: 0.5821 - val_loss: 0.6044 - val_mae: 0.5829\n",
      "Epoch 163/200\n",
      "29/29 - 0s - loss: 0.5832 - mae: 0.5831 - val_loss: 0.6127 - val_mae: 0.5943\n",
      "Epoch 164/200\n",
      "29/29 - 0s - loss: 0.5820 - mae: 0.5823 - val_loss: 0.6143 - val_mae: 0.5958\n",
      "Epoch 165/200\n",
      "29/29 - 0s - loss: 0.5846 - mae: 0.5843 - val_loss: 0.6086 - val_mae: 0.5934\n",
      "Epoch 166/200\n",
      "29/29 - 0s - loss: 0.5984 - mae: 0.5899 - val_loss: 0.6052 - val_mae: 0.5901\n",
      "Epoch 167/200\n",
      "29/29 - 0s - loss: 0.5797 - mae: 0.5819 - val_loss: 0.6010 - val_mae: 0.5829\n",
      "Epoch 168/200\n",
      "29/29 - 0s - loss: 0.5787 - mae: 0.5819 - val_loss: 0.6094 - val_mae: 0.5830\n",
      "Epoch 169/200\n",
      "29/29 - 0s - loss: 0.5827 - mae: 0.5833 - val_loss: 0.6002 - val_mae: 0.5841\n",
      "Epoch 170/200\n",
      "29/29 - 0s - loss: 0.5805 - mae: 0.5827 - val_loss: 0.6075 - val_mae: 0.5834\n",
      "Epoch 171/200\n",
      "29/29 - 0s - loss: 0.5820 - mae: 0.5837 - val_loss: 0.6037 - val_mae: 0.5867\n",
      "Epoch 172/200\n",
      "29/29 - 0s - loss: 0.5783 - mae: 0.5824 - val_loss: 0.6051 - val_mae: 0.5894\n",
      "Epoch 173/200\n",
      "29/29 - 0s - loss: 0.5795 - mae: 0.5824 - val_loss: 0.6014 - val_mae: 0.5863\n",
      "Epoch 174/200\n",
      "29/29 - 0s - loss: 0.5789 - mae: 0.5832 - val_loss: 0.6030 - val_mae: 0.5830\n",
      "Epoch 175/200\n",
      "29/29 - 0s - loss: 0.5780 - mae: 0.5820 - val_loss: 0.6056 - val_mae: 0.5898\n",
      "Epoch 176/200\n",
      "29/29 - 0s - loss: 0.5765 - mae: 0.5834 - val_loss: 0.6117 - val_mae: 0.5954\n",
      "Epoch 177/200\n",
      "29/29 - 0s - loss: 0.5765 - mae: 0.5806 - val_loss: 0.5986 - val_mae: 0.5822\n",
      "Epoch 178/200\n",
      "29/29 - 0s - loss: 0.5774 - mae: 0.5820 - val_loss: 0.6009 - val_mae: 0.5863\n",
      "Epoch 179/200\n",
      "29/29 - 0s - loss: 0.5781 - mae: 0.5827 - val_loss: 0.6481 - val_mae: 0.5964\n",
      "Epoch 180/200\n",
      "29/29 - 0s - loss: 0.5878 - mae: 0.5862 - val_loss: 0.6048 - val_mae: 0.5896\n",
      "Epoch 181/200\n",
      "29/29 - 0s - loss: 0.5793 - mae: 0.5836 - val_loss: 0.6003 - val_mae: 0.5845\n",
      "Epoch 182/200\n",
      "29/29 - 0s - loss: 0.5808 - mae: 0.5821 - val_loss: 0.6034 - val_mae: 0.5902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200\n",
      "29/29 - 0s - loss: 0.5863 - mae: 0.5860 - val_loss: 0.6067 - val_mae: 0.5837\n",
      "Epoch 184/200\n",
      "29/29 - 0s - loss: 0.5784 - mae: 0.5828 - val_loss: 0.5995 - val_mae: 0.5862\n",
      "Epoch 185/200\n",
      "29/29 - 0s - loss: 0.5757 - mae: 0.5807 - val_loss: 0.5996 - val_mae: 0.5814\n",
      "Epoch 186/200\n",
      "29/29 - 0s - loss: 0.5845 - mae: 0.5858 - val_loss: 0.6209 - val_mae: 0.5999\n",
      "Epoch 187/200\n",
      "29/29 - 0s - loss: 0.5767 - mae: 0.5800 - val_loss: 0.6042 - val_mae: 0.5904\n",
      "Epoch 188/200\n",
      "29/29 - 0s - loss: 0.5795 - mae: 0.5827 - val_loss: 0.6119 - val_mae: 0.5937\n",
      "Epoch 189/200\n",
      "29/29 - 0s - loss: 0.5784 - mae: 0.5815 - val_loss: 0.6166 - val_mae: 0.6002\n",
      "Epoch 190/200\n",
      "29/29 - 0s - loss: 0.5889 - mae: 0.5855 - val_loss: 0.6050 - val_mae: 0.5832\n",
      "Epoch 191/200\n",
      "29/29 - 0s - loss: 0.5815 - mae: 0.5841 - val_loss: 0.6149 - val_mae: 0.5984\n",
      "Epoch 192/200\n",
      "29/29 - 0s - loss: 0.5778 - mae: 0.5825 - val_loss: 0.6002 - val_mae: 0.5838\n",
      "Epoch 193/200\n",
      "29/29 - 0s - loss: 0.5743 - mae: 0.5804 - val_loss: 0.5991 - val_mae: 0.5855\n",
      "Epoch 194/200\n",
      "29/29 - 0s - loss: 0.5766 - mae: 0.5824 - val_loss: 0.5997 - val_mae: 0.5828\n",
      "Epoch 195/200\n",
      "29/29 - 0s - loss: 0.5750 - mae: 0.5805 - val_loss: 0.6042 - val_mae: 0.5813\n",
      "Epoch 196/200\n",
      "29/29 - 0s - loss: 0.5793 - mae: 0.5815 - val_loss: 0.6095 - val_mae: 0.5926\n",
      "Epoch 197/200\n",
      "29/29 - 0s - loss: 0.5767 - mae: 0.5814 - val_loss: 0.6044 - val_mae: 0.5908\n",
      "Epoch 198/200\n",
      "29/29 - 0s - loss: 0.5786 - mae: 0.5849 - val_loss: 0.6146 - val_mae: 0.5985\n",
      "Epoch 199/200\n",
      "29/29 - 0s - loss: 0.5742 - mae: 0.5808 - val_loss: 0.5996 - val_mae: 0.5869\n",
      "Epoch 200/200\n",
      "29/29 - 0s - loss: 0.5767 - mae: 0.5832 - val_loss: 0.5980 - val_mae: 0.5824\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 0s 980us/step - loss: 0.6190 - mae: 0.5986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffb1c05f9a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 - 0s - loss: 0.6863 - mae: 0.6392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6863453388214111, 0.6391699314117432]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test,y_test,batch_size=42,verbose=2)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.title('Loss / Mean Squared Error')\n",
    "pyplot.plot(history.history['loss'], label='train_loss')\n",
    "pyplot.plot(history.history['val_loss'], label='train_val')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       ...,\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2908    6\n",
       "3884    6\n",
       "4411    7\n",
       "1034    3\n",
       "4363    5\n",
       "       ..\n",
       "2726    6\n",
       "4358    5\n",
       "3807    5\n",
       "4628    6\n",
       "4046    7\n",
       "Name: quality, Length: 1225, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1949892860369954"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score(y_test,y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7493877551020408"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09274193548387089"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
