{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>pH</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>type</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.4</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.56</td>\n",
       "      <td>34.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>7.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.68</td>\n",
       "      <td>67.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>7.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.26</td>\n",
       "      <td>5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>54.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>11.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.16</td>\n",
       "      <td>6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.58</td>\n",
       "      <td>60.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.4</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.56</td>\n",
       "      <td>34.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  chlorides  citric_acid  density  fixed_acidity  \\\n",
       "0      9.4      0.076         0.00   0.9978            7.4   \n",
       "1      9.8      0.098         0.00   0.9968            7.8   \n",
       "2      9.8      0.092         0.04   0.9970            7.8   \n",
       "3      9.8      0.075         0.56   0.9980           11.2   \n",
       "4      9.4      0.076         0.00   0.9978            7.4   \n",
       "\n",
       "   free_sulfur_dioxide    pH  quality  residual_sugar  sulphates  \\\n",
       "0                 11.0  3.51        5             1.9       0.56   \n",
       "1                 25.0  3.20        5             2.6       0.68   \n",
       "2                 15.0  3.26        5             2.3       0.65   \n",
       "3                 17.0  3.16        6             1.9       0.58   \n",
       "4                 11.0  3.51        5             1.9       0.56   \n",
       "\n",
       "   total_sulfur_dioxide type  volatile_acidity  \n",
       "0                  34.0  red              0.70  \n",
       "1                  67.0  red              0.88  \n",
       "2                  54.0  red              0.76  \n",
       "3                  60.0  red              0.28  \n",
       "4                  34.0  red              0.70  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_qa = pd.read_csv('data/wine-qa.csv')\n",
    "wine_qa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>pH</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.491801</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>0.318633</td>\n",
       "      <td>0.994697</td>\n",
       "      <td>7.215307</td>\n",
       "      <td>30.525319</td>\n",
       "      <td>3.218501</td>\n",
       "      <td>5.818378</td>\n",
       "      <td>5.443235</td>\n",
       "      <td>0.531268</td>\n",
       "      <td>115.744574</td>\n",
       "      <td>0.339666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.192712</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>0.145318</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>1.296434</td>\n",
       "      <td>17.749400</td>\n",
       "      <td>0.160787</td>\n",
       "      <td>0.873255</td>\n",
       "      <td>4.757804</td>\n",
       "      <td>0.148806</td>\n",
       "      <td>56.521855</td>\n",
       "      <td>0.164636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.500000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.300000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.300000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.996990</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.900000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.580000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           alcohol    chlorides  citric_acid      density  fixed_acidity  \\\n",
       "count  6497.000000  6497.000000  6497.000000  6497.000000    6497.000000   \n",
       "mean     10.491801     0.056034     0.318633     0.994697       7.215307   \n",
       "std       1.192712     0.035034     0.145318     0.002999       1.296434   \n",
       "min       8.000000     0.009000     0.000000     0.987110       3.800000   \n",
       "25%       9.500000     0.038000     0.250000     0.992340       6.400000   \n",
       "50%      10.300000     0.047000     0.310000     0.994890       7.000000   \n",
       "75%      11.300000     0.065000     0.390000     0.996990       7.700000   \n",
       "max      14.900000     0.611000     1.660000     1.038980      15.900000   \n",
       "\n",
       "       free_sulfur_dioxide           pH      quality  residual_sugar  \\\n",
       "count          6497.000000  6497.000000  6497.000000     6497.000000   \n",
       "mean             30.525319     3.218501     5.818378        5.443235   \n",
       "std              17.749400     0.160787     0.873255        4.757804   \n",
       "min               1.000000     2.720000     3.000000        0.600000   \n",
       "25%              17.000000     3.110000     5.000000        1.800000   \n",
       "50%              29.000000     3.210000     6.000000        3.000000   \n",
       "75%              41.000000     3.320000     6.000000        8.100000   \n",
       "max             289.000000     4.010000     9.000000       65.800000   \n",
       "\n",
       "         sulphates  total_sulfur_dioxide  volatile_acidity  \n",
       "count  6497.000000           6497.000000       6497.000000  \n",
       "mean      0.531268            115.744574          0.339666  \n",
       "std       0.148806             56.521855          0.164636  \n",
       "min       0.220000              6.000000          0.080000  \n",
       "25%       0.430000             77.000000          0.230000  \n",
       "50%       0.510000            118.000000          0.290000  \n",
       "75%       0.600000            156.000000          0.400000  \n",
       "max       2.000000            440.000000          1.580000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_qa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wine_qa['quality']\n",
    "X = wine_qa.drop(columns=['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.fit(X['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = label_encoder.transform(X['type'])\n",
    "X = X.drop(columns=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "prep = StandardScaler()\n",
    "prep.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.915464</td>\n",
       "      <td>0.569958</td>\n",
       "      <td>-2.192833</td>\n",
       "      <td>1.034993</td>\n",
       "      <td>0.142473</td>\n",
       "      <td>-1.100140</td>\n",
       "      <td>1.813090</td>\n",
       "      <td>-0.744778</td>\n",
       "      <td>0.193097</td>\n",
       "      <td>-1.446359</td>\n",
       "      <td>2.188833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.580068</td>\n",
       "      <td>1.197975</td>\n",
       "      <td>-2.192833</td>\n",
       "      <td>0.701486</td>\n",
       "      <td>0.451036</td>\n",
       "      <td>-0.311320</td>\n",
       "      <td>-0.115073</td>\n",
       "      <td>-0.597640</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>-0.862469</td>\n",
       "      <td>3.282235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.580068</td>\n",
       "      <td>1.026697</td>\n",
       "      <td>-1.917553</td>\n",
       "      <td>0.768188</td>\n",
       "      <td>0.451036</td>\n",
       "      <td>-0.874763</td>\n",
       "      <td>0.258120</td>\n",
       "      <td>-0.660699</td>\n",
       "      <td>0.797958</td>\n",
       "      <td>-1.092486</td>\n",
       "      <td>2.553300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.580068</td>\n",
       "      <td>0.541412</td>\n",
       "      <td>1.661085</td>\n",
       "      <td>1.101694</td>\n",
       "      <td>3.073817</td>\n",
       "      <td>-0.762074</td>\n",
       "      <td>-0.363868</td>\n",
       "      <td>-0.744778</td>\n",
       "      <td>0.327510</td>\n",
       "      <td>-0.986324</td>\n",
       "      <td>-0.362438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.915464</td>\n",
       "      <td>0.569958</td>\n",
       "      <td>-2.192833</td>\n",
       "      <td>1.034993</td>\n",
       "      <td>0.142473</td>\n",
       "      <td>-1.100140</td>\n",
       "      <td>1.813090</td>\n",
       "      <td>-0.744778</td>\n",
       "      <td>0.193097</td>\n",
       "      <td>-1.446359</td>\n",
       "      <td>2.188833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.915464  0.569958 -2.192833  1.034993  0.142473 -1.100140  1.813090   \n",
       "1 -0.580068  1.197975 -2.192833  0.701486  0.451036 -0.311320 -0.115073   \n",
       "2 -0.580068  1.026697 -1.917553  0.768188  0.451036 -0.874763  0.258120   \n",
       "3 -0.580068  0.541412  1.661085  1.101694  3.073817 -0.762074 -0.363868   \n",
       "4 -0.915464  0.569958 -2.192833  1.034993  0.142473 -1.100140  1.813090   \n",
       "\n",
       "          7         8         9        10  type  \n",
       "0 -0.744778  0.193097 -1.446359  2.188833     0  \n",
       "1 -0.597640  0.999579 -0.862469  3.282235     0  \n",
       "2 -0.660699  0.797958 -1.092486  2.553300     0  \n",
       "3 -0.744778  0.327510 -0.986324 -0.362438     0  \n",
       "4 -0.744778  0.193097 -1.446359  2.188833     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trans = pd.DataFrame(prep.transform(X))\n",
    "X_trans['type'] = color\n",
    "X_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trans,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>-0.747766</td>\n",
       "      <td>0.941059</td>\n",
       "      <td>1.179346</td>\n",
       "      <td>1.835408</td>\n",
       "      <td>3.922363</td>\n",
       "      <td>-1.438205</td>\n",
       "      <td>-0.177272</td>\n",
       "      <td>-0.681719</td>\n",
       "      <td>-0.613385</td>\n",
       "      <td>-1.800231</td>\n",
       "      <td>0.973942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5595</th>\n",
       "      <td>0.426120</td>\n",
       "      <td>-0.229336</td>\n",
       "      <td>0.147046</td>\n",
       "      <td>-0.048903</td>\n",
       "      <td>-0.397511</td>\n",
       "      <td>0.083090</td>\n",
       "      <td>0.195921</td>\n",
       "      <td>0.726602</td>\n",
       "      <td>0.058683</td>\n",
       "      <td>-0.083949</td>\n",
       "      <td>-0.362438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>1.013063</td>\n",
       "      <td>-0.571891</td>\n",
       "      <td>0.697606</td>\n",
       "      <td>-0.265683</td>\n",
       "      <td>0.913879</td>\n",
       "      <td>-1.325517</td>\n",
       "      <td>-0.363868</td>\n",
       "      <td>-0.072147</td>\n",
       "      <td>-0.075731</td>\n",
       "      <td>-0.685532</td>\n",
       "      <td>-0.969884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>-0.747766</td>\n",
       "      <td>-0.286429</td>\n",
       "      <td>-0.403514</td>\n",
       "      <td>0.918266</td>\n",
       "      <td>-0.783214</td>\n",
       "      <td>1.379008</td>\n",
       "      <td>-0.363868</td>\n",
       "      <td>1.609430</td>\n",
       "      <td>-0.815006</td>\n",
       "      <td>1.561559</td>\n",
       "      <td>-0.301694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3775</th>\n",
       "      <td>-1.083162</td>\n",
       "      <td>-0.400614</td>\n",
       "      <td>-1.298173</td>\n",
       "      <td>0.434681</td>\n",
       "      <td>-0.243230</td>\n",
       "      <td>-1.100140</td>\n",
       "      <td>0.071523</td>\n",
       "      <td>0.495385</td>\n",
       "      <td>-1.083833</td>\n",
       "      <td>0.022213</td>\n",
       "      <td>-0.119460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "580  -0.747766  0.941059  1.179346  1.835408  3.922363 -1.438205 -0.177272   \n",
       "5595  0.426120 -0.229336  0.147046 -0.048903 -0.397511  0.083090  0.195921   \n",
       "2415  1.013063 -0.571891  0.697606 -0.265683  0.913879 -1.325517 -0.363868   \n",
       "2406 -0.747766 -0.286429 -0.403514  0.918266 -0.783214  1.379008 -0.363868   \n",
       "3775 -1.083162 -0.400614 -1.298173  0.434681 -0.243230 -1.100140  0.071523   \n",
       "\n",
       "             7         8         9        10  type  \n",
       "580  -0.681719 -0.613385 -1.800231  0.973942     0  \n",
       "5595  0.726602  0.058683 -0.083949 -0.362438     1  \n",
       "2415 -0.072147 -0.075731 -0.685532 -0.969884     1  \n",
       "2406  1.609430 -0.815006  1.561559 -0.301694     1  \n",
       "3775  0.495385 -1.083833  0.022213 -0.119460     1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import deserialize as layer_from_config\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_shape=(12,), kernel_regularizer='l2'))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 91        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 255\n",
      "Trainable params: 255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential',\n",
       " 'layers': [{'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 12),\n",
       "    'dtype': 'float32',\n",
       "    'units': 12,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': {'class_name': 'L1L2',\n",
       "     'config': {'l1': 0.0, 'l2': 0.009999999776482582}},\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 7,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}],\n",
       " 'build_input_shape': TensorShape([None, 12])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.23686874, -0.19311607,  0.25608552,  0.45216107, -0.44883013,\n",
       "          0.12735248, -0.27799475, -0.34724903, -0.36516488, -0.13880157,\n",
       "          0.06434762, -0.08538723],\n",
       "        [ 0.45619643,  0.3062129 , -0.36823976,  0.09083998, -0.0962466 ,\n",
       "          0.28709912, -0.38253808,  0.21384323,  0.4487946 , -0.15352917,\n",
       "          0.34897137, -0.16057491],\n",
       "        [ 0.39637506,  0.30053723,  0.0657289 , -0.32518148,  0.19909   ,\n",
       "          0.25109065, -0.04374504, -0.30389845, -0.4958763 , -0.4813373 ,\n",
       "          0.14830625, -0.09838951],\n",
       "        [ 0.18361819,  0.03434992, -0.27300262, -0.46840084, -0.25263703,\n",
       "         -0.41598642, -0.46077287, -0.04716647, -0.00423789, -0.34675503,\n",
       "         -0.11975026, -0.14759278],\n",
       "        [ 0.37515664, -0.39420414,  0.37617946, -0.354519  ,  0.02532387,\n",
       "          0.44032753, -0.02766562, -0.32615924, -0.06457603,  0.227296  ,\n",
       "          0.3299955 ,  0.44607723],\n",
       "        [-0.37208664, -0.30729675, -0.20290005,  0.42685306, -0.44951248,\n",
       "         -0.4709648 ,  0.00506771, -0.3011495 ,  0.11663699,  0.3395232 ,\n",
       "          0.18600595,  0.32516134],\n",
       "        [ 0.34303284, -0.29608023,  0.17781258, -0.43846858, -0.48684406,\n",
       "          0.17714894, -0.10156894, -0.20272446, -0.1992315 , -0.03481054,\n",
       "          0.17789471,  0.37859535],\n",
       "        [-0.23636913,  0.24654925,  0.22689497,  0.43009663, -0.20585585,\n",
       "         -0.15588748,  0.20472276, -0.27669346,  0.08950341,  0.32386947,\n",
       "         -0.33324456,  0.22892666],\n",
       "        [-0.16400266, -0.36610162,  0.3779608 ,  0.471709  , -0.08942688,\n",
       "          0.14097822,  0.00488365,  0.00093424, -0.0266453 ,  0.30038464,\n",
       "          0.20284033,  0.2566185 ],\n",
       "        [-0.442021  ,  0.05212295,  0.32900155,  0.44485962, -0.4558549 ,\n",
       "          0.33103597,  0.09660316, -0.41960692,  0.39413798,  0.3106314 ,\n",
       "         -0.33424056, -0.1626494 ],\n",
       "        [-0.24115407,  0.4602207 ,  0.49076343, -0.23807621, -0.3624016 ,\n",
       "         -0.13129747,  0.46161783,  0.19630146,  0.48974347, -0.417974  ,\n",
       "         -0.22493076, -0.2266382 ],\n",
       "        [ 0.07029271, -0.48934793,  0.47004294,  0.4616301 ,  0.45653605,\n",
       "         -0.01912987, -0.26799023, -0.34723318, -0.4962381 , -0.46157622,\n",
       "         -0.3368361 , -0.12912607]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.5119241 , -0.50690645, -0.19727984, -0.20443287,  0.22416377,\n",
       "          0.2711159 , -0.12710556],\n",
       "        [ 0.15499598, -0.2636216 , -0.31484902, -0.44804516, -0.45801753,\n",
       "          0.07088327, -0.41382098],\n",
       "        [ 0.20295805,  0.0386349 , -0.25486377,  0.2739662 ,  0.299623  ,\n",
       "          0.2441482 ,  0.26657343],\n",
       "        [-0.45216933,  0.30255854,  0.40912664, -0.07060167, -0.5582654 ,\n",
       "         -0.00078917, -0.08921412],\n",
       "        [-0.05497813, -0.16320038, -0.29954505, -0.39630744, -0.04104292,\n",
       "          0.33859825, -0.31044522],\n",
       "        [-0.20679668, -0.12290451, -0.21695474, -0.29097515, -0.5336252 ,\n",
       "          0.3210761 , -0.12361661],\n",
       "        [-0.09603837,  0.32441342, -0.071116  , -0.15234265, -0.49664885,\n",
       "         -0.28621715,  0.50200945],\n",
       "        [ 0.44141227,  0.31548744,  0.07347447,  0.05771083, -0.00281239,\n",
       "          0.28850698,  0.45974773],\n",
       "        [ 0.10413837,  0.16814917, -0.27596703,  0.40743446, -0.37834412,\n",
       "         -0.34849638, -0.00210375],\n",
       "        [-0.43215984, -0.1657252 , -0.38901347, -0.48422462, -0.13701686,\n",
       "         -0.25405252,  0.35204726],\n",
       "        [ 0.18285197,  0.48634166, -0.35934955, -0.2489196 ,  0.5572513 ,\n",
       "         -0.36976755,  0.23130172],\n",
       "        [-0.4840423 ,  0.17980474,  0.22712177,  0.02914917, -0.2609849 ,\n",
       "         -0.50372   , -0.07594264]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.79572505],\n",
       "        [-0.17806226],\n",
       "        [ 0.06281346],\n",
       "        [ 0.06576443],\n",
       "        [ 0.3437894 ],\n",
       "        [-0.19019526],\n",
       "        [ 0.07703102]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg, bs = model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg.shape # 1 weight per input per neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79572505]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg[:1,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.shape # 1 bias per neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>-0.747766</td>\n",
       "      <td>0.941059</td>\n",
       "      <td>1.179346</td>\n",
       "      <td>1.835408</td>\n",
       "      <td>3.922363</td>\n",
       "      <td>-1.438205</td>\n",
       "      <td>-0.177272</td>\n",
       "      <td>-0.681719</td>\n",
       "      <td>-0.613385</td>\n",
       "      <td>-1.800231</td>\n",
       "      <td>0.973942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5595</th>\n",
       "      <td>0.426120</td>\n",
       "      <td>-0.229336</td>\n",
       "      <td>0.147046</td>\n",
       "      <td>-0.048903</td>\n",
       "      <td>-0.397511</td>\n",
       "      <td>0.083090</td>\n",
       "      <td>0.195921</td>\n",
       "      <td>0.726602</td>\n",
       "      <td>0.058683</td>\n",
       "      <td>-0.083949</td>\n",
       "      <td>-0.362438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>1.013063</td>\n",
       "      <td>-0.571891</td>\n",
       "      <td>0.697606</td>\n",
       "      <td>-0.265683</td>\n",
       "      <td>0.913879</td>\n",
       "      <td>-1.325517</td>\n",
       "      <td>-0.363868</td>\n",
       "      <td>-0.072147</td>\n",
       "      <td>-0.075731</td>\n",
       "      <td>-0.685532</td>\n",
       "      <td>-0.969884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>-0.747766</td>\n",
       "      <td>-0.286429</td>\n",
       "      <td>-0.403514</td>\n",
       "      <td>0.918266</td>\n",
       "      <td>-0.783214</td>\n",
       "      <td>1.379008</td>\n",
       "      <td>-0.363868</td>\n",
       "      <td>1.609430</td>\n",
       "      <td>-0.815006</td>\n",
       "      <td>1.561559</td>\n",
       "      <td>-0.301694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3775</th>\n",
       "      <td>-1.083162</td>\n",
       "      <td>-0.400614</td>\n",
       "      <td>-1.298173</td>\n",
       "      <td>0.434681</td>\n",
       "      <td>-0.243230</td>\n",
       "      <td>-1.100140</td>\n",
       "      <td>0.071523</td>\n",
       "      <td>0.495385</td>\n",
       "      <td>-1.083833</td>\n",
       "      <td>0.022213</td>\n",
       "      <td>-0.119460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "580  -0.747766  0.941059  1.179346  1.835408  3.922363 -1.438205 -0.177272   \n",
       "5595  0.426120 -0.229336  0.147046 -0.048903 -0.397511  0.083090  0.195921   \n",
       "2415  1.013063 -0.571891  0.697606 -0.265683  0.913879 -1.325517 -0.363868   \n",
       "2406 -0.747766 -0.286429 -0.403514  0.918266 -0.783214  1.379008 -0.363868   \n",
       "3775 -1.083162 -0.400614 -1.298173  0.434681 -0.243230 -1.100140  0.071523   \n",
       "\n",
       "             7         8         9        10  type  \n",
       "580  -0.681719 -0.613385 -1.800231  0.973942     0  \n",
       "5595  0.726602  0.058683 -0.083949 -0.362438     1  \n",
       "2415 -0.072147 -0.075731 -0.685532 -0.969884     1  \n",
       "2406  1.609430 -0.815006  1.561559 -0.301694     1  \n",
       "3775  0.495385 -1.083833  0.022213 -0.119460     1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.016026</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>-0.003891</td>\n",
       "      <td>-0.010268</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>-0.004830</td>\n",
       "      <td>-0.010745</td>\n",
       "      <td>-0.001289</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0.753900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.995389</td>\n",
       "      <td>1.000496</td>\n",
       "      <td>1.007176</td>\n",
       "      <td>0.977487</td>\n",
       "      <td>0.982927</td>\n",
       "      <td>0.977455</td>\n",
       "      <td>0.996934</td>\n",
       "      <td>0.989782</td>\n",
       "      <td>0.997873</td>\n",
       "      <td>0.998497</td>\n",
       "      <td>1.010191</td>\n",
       "      <td>0.430782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.753954</td>\n",
       "      <td>-1.257000</td>\n",
       "      <td>-2.192833</td>\n",
       "      <td>-2.530192</td>\n",
       "      <td>-2.634589</td>\n",
       "      <td>-1.663583</td>\n",
       "      <td>-2.976217</td>\n",
       "      <td>-1.018034</td>\n",
       "      <td>-2.091935</td>\n",
       "      <td>-1.941780</td>\n",
       "      <td>-1.577330</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.831615</td>\n",
       "      <td>-0.514799</td>\n",
       "      <td>-0.472334</td>\n",
       "      <td>-0.765942</td>\n",
       "      <td>-0.628933</td>\n",
       "      <td>-0.762074</td>\n",
       "      <td>-0.674862</td>\n",
       "      <td>-0.765798</td>\n",
       "      <td>-0.680592</td>\n",
       "      <td>-0.670050</td>\n",
       "      <td>-0.666161</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.160823</td>\n",
       "      <td>-0.257883</td>\n",
       "      <td>-0.059414</td>\n",
       "      <td>0.054484</td>\n",
       "      <td>-0.166089</td>\n",
       "      <td>-0.085943</td>\n",
       "      <td>-0.052874</td>\n",
       "      <td>-0.534581</td>\n",
       "      <td>-0.210144</td>\n",
       "      <td>0.039907</td>\n",
       "      <td>-0.301694</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.677667</td>\n",
       "      <td>0.255949</td>\n",
       "      <td>0.491146</td>\n",
       "      <td>0.768188</td>\n",
       "      <td>0.373895</td>\n",
       "      <td>0.590188</td>\n",
       "      <td>0.631312</td>\n",
       "      <td>0.558444</td>\n",
       "      <td>0.461924</td>\n",
       "      <td>0.712265</td>\n",
       "      <td>0.366496</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.941590</td>\n",
       "      <td>15.813640</td>\n",
       "      <td>9.231281</td>\n",
       "      <td>5.203824</td>\n",
       "      <td>6.468004</td>\n",
       "      <td>6.534509</td>\n",
       "      <td>4.923029</td>\n",
       "      <td>5.498078</td>\n",
       "      <td>9.870879</td>\n",
       "      <td>4.436775</td>\n",
       "      <td>7.534354</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  4872.000000  4872.000000  4872.000000  4872.000000  4872.000000   \n",
       "mean     -0.016026     0.006686     0.002471     0.002101    -0.003891   \n",
       "std       0.995389     1.000496     1.007176     0.977487     0.982927   \n",
       "min      -1.753954    -1.257000    -2.192833    -2.530192    -2.634589   \n",
       "25%      -0.831615    -0.514799    -0.472334    -0.765942    -0.628933   \n",
       "50%      -0.160823    -0.257883    -0.059414     0.054484    -0.166089   \n",
       "75%       0.677667     0.255949     0.491146     0.768188     0.373895   \n",
       "max       2.941590    15.813640     9.231281     5.203824     6.468004   \n",
       "\n",
       "                 5            6            7            8            9  \\\n",
       "count  4872.000000  4872.000000  4872.000000  4872.000000  4872.000000   \n",
       "mean     -0.010268     0.000643    -0.004830    -0.010745    -0.001289   \n",
       "std       0.977455     0.996934     0.989782     0.997873     0.998497   \n",
       "min      -1.663583    -2.976217    -1.018034    -2.091935    -1.941780   \n",
       "25%      -0.762074    -0.674862    -0.765798    -0.680592    -0.670050   \n",
       "50%      -0.085943    -0.052874    -0.534581    -0.210144     0.039907   \n",
       "75%       0.590188     0.631312     0.558444     0.461924     0.712265   \n",
       "max       6.534509     4.923029     5.498078     9.870879     4.436775   \n",
       "\n",
       "                10         type  \n",
       "count  4872.000000  4872.000000  \n",
       "mean      0.008001     0.753900  \n",
       "std       1.010191     0.430782  \n",
       "min      -1.577330     0.000000  \n",
       "25%      -0.666161     1.000000  \n",
       "50%      -0.301694     1.000000  \n",
       "75%       0.366496     1.000000  \n",
       "max       7.534354     1.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= 'mse',\n",
    "              optimizer= 'adam',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./logs\", histogram_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "39/39 - 1s - loss: 30.1151 - mae: 5.3200 - val_loss: 28.5518 - val_mae: 5.1323\n",
      "Epoch 2/200\n",
      "39/39 - 0s - loss: 26.1131 - mae: 4.8185 - val_loss: 24.1813 - val_mae: 4.5552\n",
      "Epoch 3/200\n",
      "39/39 - 0s - loss: 21.3529 - mae: 4.2008 - val_loss: 18.6717 - val_mae: 3.8795\n",
      "Epoch 4/200\n",
      "39/39 - 0s - loss: 14.9560 - mae: 3.4191 - val_loss: 11.3318 - val_mae: 2.9452\n",
      "Epoch 5/200\n",
      "39/39 - 0s - loss: 7.7744 - mae: 2.3636 - val_loss: 4.8249 - val_mae: 1.8100\n",
      "Epoch 6/200\n",
      "39/39 - 0s - loss: 3.1764 - mae: 1.3951 - val_loss: 2.3708 - val_mae: 1.1400\n",
      "Epoch 7/200\n",
      "39/39 - 0s - loss: 1.9999 - mae: 1.0546 - val_loss: 2.0377 - val_mae: 1.0359\n",
      "Epoch 8/200\n",
      "39/39 - 0s - loss: 1.7745 - mae: 0.9917 - val_loss: 1.8771 - val_mae: 0.9905\n",
      "Epoch 9/200\n",
      "39/39 - 0s - loss: 1.6282 - mae: 0.9490 - val_loss: 1.7408 - val_mae: 0.9486\n",
      "Epoch 10/200\n",
      "39/39 - 0s - loss: 1.5098 - mae: 0.9099 - val_loss: 1.6276 - val_mae: 0.9144\n",
      "Epoch 11/200\n",
      "39/39 - 0s - loss: 1.4112 - mae: 0.8806 - val_loss: 1.5280 - val_mae: 0.8826\n",
      "Epoch 12/200\n",
      "39/39 - 0s - loss: 1.3258 - mae: 0.8487 - val_loss: 1.4459 - val_mae: 0.8551\n",
      "Epoch 13/200\n",
      "39/39 - 0s - loss: 1.2586 - mae: 0.8245 - val_loss: 1.3779 - val_mae: 0.8336\n",
      "Epoch 14/200\n",
      "39/39 - 0s - loss: 1.2006 - mae: 0.8038 - val_loss: 1.3176 - val_mae: 0.8132\n",
      "Epoch 15/200\n",
      "39/39 - 0s - loss: 1.1541 - mae: 0.7858 - val_loss: 1.2651 - val_mae: 0.7958\n",
      "Epoch 16/200\n",
      "39/39 - 0s - loss: 1.1105 - mae: 0.7711 - val_loss: 1.2209 - val_mae: 0.7811\n",
      "Epoch 17/200\n",
      "39/39 - 0s - loss: 1.0719 - mae: 0.7553 - val_loss: 1.1767 - val_mae: 0.7665\n",
      "Epoch 18/200\n",
      "39/39 - 0s - loss: 1.0371 - mae: 0.7426 - val_loss: 1.1390 - val_mae: 0.7533\n",
      "Epoch 19/200\n",
      "39/39 - 0s - loss: 1.0068 - mae: 0.7298 - val_loss: 1.1026 - val_mae: 0.7417\n",
      "Epoch 20/200\n",
      "39/39 - 0s - loss: 0.9788 - mae: 0.7187 - val_loss: 1.0702 - val_mae: 0.7312\n",
      "Epoch 21/200\n",
      "39/39 - 0s - loss: 0.9512 - mae: 0.7080 - val_loss: 1.0426 - val_mae: 0.7210\n",
      "Epoch 22/200\n",
      "39/39 - 0s - loss: 0.9274 - mae: 0.6985 - val_loss: 1.0138 - val_mae: 0.7115\n",
      "Epoch 23/200\n",
      "39/39 - 0s - loss: 0.9070 - mae: 0.6900 - val_loss: 0.9910 - val_mae: 0.7030\n",
      "Epoch 24/200\n",
      "39/39 - 0s - loss: 0.8859 - mae: 0.6812 - val_loss: 0.9678 - val_mae: 0.6946\n",
      "Epoch 25/200\n",
      "39/39 - 0s - loss: 0.8684 - mae: 0.6741 - val_loss: 0.9488 - val_mae: 0.6869\n",
      "Epoch 26/200\n",
      "39/39 - 0s - loss: 0.8511 - mae: 0.6677 - val_loss: 0.9312 - val_mae: 0.6794\n",
      "Epoch 27/200\n",
      "39/39 - 0s - loss: 0.8362 - mae: 0.6612 - val_loss: 0.9141 - val_mae: 0.6735\n",
      "Epoch 28/200\n",
      "39/39 - 0s - loss: 0.8227 - mae: 0.6567 - val_loss: 0.8985 - val_mae: 0.6672\n",
      "Epoch 29/200\n",
      "39/39 - 0s - loss: 0.8107 - mae: 0.6528 - val_loss: 0.8833 - val_mae: 0.6623\n",
      "Epoch 30/200\n",
      "39/39 - 0s - loss: 0.7967 - mae: 0.6462 - val_loss: 0.8700 - val_mae: 0.6579\n",
      "Epoch 31/200\n",
      "39/39 - 0s - loss: 0.7855 - mae: 0.6422 - val_loss: 0.8588 - val_mae: 0.6530\n",
      "Epoch 32/200\n",
      "39/39 - 0s - loss: 0.7744 - mae: 0.6372 - val_loss: 0.8447 - val_mae: 0.6484\n",
      "Epoch 33/200\n",
      "39/39 - 0s - loss: 0.7663 - mae: 0.6348 - val_loss: 0.8352 - val_mae: 0.6427\n",
      "Epoch 34/200\n",
      "39/39 - 0s - loss: 0.7552 - mae: 0.6303 - val_loss: 0.8249 - val_mae: 0.6402\n",
      "Epoch 35/200\n",
      "39/39 - 0s - loss: 0.7455 - mae: 0.6260 - val_loss: 0.8139 - val_mae: 0.6379\n",
      "Epoch 36/200\n",
      "39/39 - 0s - loss: 0.7372 - mae: 0.6239 - val_loss: 0.8022 - val_mae: 0.6329\n",
      "Epoch 37/200\n",
      "39/39 - 0s - loss: 0.7287 - mae: 0.6190 - val_loss: 0.7935 - val_mae: 0.6294\n",
      "Epoch 38/200\n",
      "39/39 - 0s - loss: 0.7198 - mae: 0.6159 - val_loss: 0.7846 - val_mae: 0.6268\n",
      "Epoch 39/200\n",
      "39/39 - 0s - loss: 0.7118 - mae: 0.6121 - val_loss: 0.7776 - val_mae: 0.6238\n",
      "Epoch 40/200\n",
      "39/39 - 0s - loss: 0.7048 - mae: 0.6091 - val_loss: 0.7685 - val_mae: 0.6205\n",
      "Epoch 41/200\n",
      "39/39 - 0s - loss: 0.6975 - mae: 0.6072 - val_loss: 0.7603 - val_mae: 0.6186\n",
      "Epoch 42/200\n",
      "39/39 - 0s - loss: 0.6898 - mae: 0.6033 - val_loss: 0.7516 - val_mae: 0.6144\n",
      "Epoch 43/200\n",
      "39/39 - 0s - loss: 0.6836 - mae: 0.6014 - val_loss: 0.7433 - val_mae: 0.6110\n",
      "Epoch 44/200\n",
      "39/39 - 0s - loss: 0.6772 - mae: 0.5978 - val_loss: 0.7396 - val_mae: 0.6112\n",
      "Epoch 45/200\n",
      "39/39 - 0s - loss: 0.6698 - mae: 0.5944 - val_loss: 0.7339 - val_mae: 0.6078\n",
      "Epoch 46/200\n",
      "39/39 - 1s - loss: 0.6649 - mae: 0.5932 - val_loss: 0.7253 - val_mae: 0.6050\n",
      "Epoch 47/200\n",
      "39/39 - 1s - loss: 0.6581 - mae: 0.5895 - val_loss: 0.7174 - val_mae: 0.6019\n",
      "Epoch 48/200\n",
      "39/39 - 0s - loss: 0.6518 - mae: 0.5870 - val_loss: 0.7151 - val_mae: 0.6014\n",
      "Epoch 49/200\n",
      "39/39 - 0s - loss: 0.6465 - mae: 0.5850 - val_loss: 0.7075 - val_mae: 0.5994\n",
      "Epoch 50/200\n",
      "39/39 - 0s - loss: 0.6409 - mae: 0.5824 - val_loss: 0.7052 - val_mae: 0.5990\n",
      "Epoch 51/200\n",
      "39/39 - 0s - loss: 0.6351 - mae: 0.5807 - val_loss: 0.6996 - val_mae: 0.5974\n",
      "Epoch 52/200\n",
      "39/39 - 0s - loss: 0.6299 - mae: 0.5779 - val_loss: 0.6957 - val_mae: 0.5964\n",
      "Epoch 53/200\n",
      "39/39 - 0s - loss: 0.6249 - mae: 0.5769 - val_loss: 0.6852 - val_mae: 0.5910\n",
      "Epoch 54/200\n",
      "39/39 - 0s - loss: 0.6201 - mae: 0.5750 - val_loss: 0.6799 - val_mae: 0.5891\n",
      "Epoch 55/200\n",
      "39/39 - 0s - loss: 0.6148 - mae: 0.5716 - val_loss: 0.6785 - val_mae: 0.5889\n",
      "Epoch 56/200\n",
      "39/39 - 0s - loss: 0.6101 - mae: 0.5707 - val_loss: 0.6729 - val_mae: 0.5869\n",
      "Epoch 57/200\n",
      "39/39 - 0s - loss: 0.6080 - mae: 0.5693 - val_loss: 0.6678 - val_mae: 0.5853\n",
      "Epoch 58/200\n",
      "39/39 - 0s - loss: 0.6034 - mae: 0.5688 - val_loss: 0.6649 - val_mae: 0.5841\n",
      "Epoch 59/200\n",
      "39/39 - 0s - loss: 0.5992 - mae: 0.5662 - val_loss: 0.6654 - val_mae: 0.5858\n",
      "Epoch 60/200\n",
      "39/39 - 0s - loss: 0.5942 - mae: 0.5640 - val_loss: 0.6536 - val_mae: 0.5804\n",
      "Epoch 61/200\n",
      "39/39 - 0s - loss: 0.5929 - mae: 0.5646 - val_loss: 0.6576 - val_mae: 0.5830\n",
      "Epoch 62/200\n",
      "39/39 - 0s - loss: 0.5893 - mae: 0.5624 - val_loss: 0.6485 - val_mae: 0.5794\n",
      "Epoch 63/200\n",
      "39/39 - 0s - loss: 0.5843 - mae: 0.5605 - val_loss: 0.6436 - val_mae: 0.5772\n",
      "Epoch 64/200\n",
      "39/39 - 0s - loss: 0.5833 - mae: 0.5602 - val_loss: 0.6489 - val_mae: 0.5810\n",
      "Epoch 65/200\n",
      "39/39 - 0s - loss: 0.5802 - mae: 0.5579 - val_loss: 0.6387 - val_mae: 0.5765\n",
      "Epoch 66/200\n",
      "39/39 - 0s - loss: 0.5771 - mae: 0.5582 - val_loss: 0.6442 - val_mae: 0.5798\n",
      "Epoch 67/200\n",
      "39/39 - 0s - loss: 0.5749 - mae: 0.5574 - val_loss: 0.6314 - val_mae: 0.5744\n",
      "Epoch 68/200\n",
      "39/39 - 0s - loss: 0.5707 - mae: 0.5557 - val_loss: 0.6330 - val_mae: 0.5759\n",
      "Epoch 69/200\n",
      "39/39 - 0s - loss: 0.5710 - mae: 0.5564 - val_loss: 0.6313 - val_mae: 0.5757\n",
      "Epoch 70/200\n",
      "39/39 - 0s - loss: 0.5684 - mae: 0.5555 - val_loss: 0.6230 - val_mae: 0.5717\n",
      "Epoch 71/200\n",
      "39/39 - 0s - loss: 0.5679 - mae: 0.5546 - val_loss: 0.6233 - val_mae: 0.5724\n",
      "Epoch 72/200\n",
      "39/39 - 0s - loss: 0.5615 - mae: 0.5529 - val_loss: 0.6209 - val_mae: 0.5717\n",
      "Epoch 73/200\n",
      "39/39 - 0s - loss: 0.5585 - mae: 0.5518 - val_loss: 0.6187 - val_mae: 0.5708\n",
      "Epoch 74/200\n",
      "39/39 - 0s - loss: 0.5572 - mae: 0.5509 - val_loss: 0.6169 - val_mae: 0.5706\n",
      "Epoch 75/200\n",
      "39/39 - 0s - loss: 0.5607 - mae: 0.5529 - val_loss: 0.6158 - val_mae: 0.5710\n",
      "Epoch 76/200\n",
      "39/39 - 0s - loss: 0.5524 - mae: 0.5496 - val_loss: 0.6186 - val_mae: 0.5731\n",
      "Epoch 77/200\n",
      "39/39 - 0s - loss: 0.5553 - mae: 0.5526 - val_loss: 0.6109 - val_mae: 0.5689\n",
      "Epoch 78/200\n",
      "39/39 - 0s - loss: 0.5501 - mae: 0.5490 - val_loss: 0.6090 - val_mae: 0.5679\n",
      "Epoch 79/200\n",
      "39/39 - 0s - loss: 0.5489 - mae: 0.5487 - val_loss: 0.6064 - val_mae: 0.5673\n",
      "Epoch 80/200\n",
      "39/39 - 0s - loss: 0.5465 - mae: 0.5480 - val_loss: 0.6043 - val_mae: 0.5674\n",
      "Epoch 81/200\n",
      "39/39 - 0s - loss: 0.5527 - mae: 0.5518 - val_loss: 0.6070 - val_mae: 0.5696\n",
      "Epoch 82/200\n",
      "39/39 - 0s - loss: 0.5442 - mae: 0.5481 - val_loss: 0.6022 - val_mae: 0.5671\n",
      "Epoch 83/200\n",
      "39/39 - 0s - loss: 0.5432 - mae: 0.5477 - val_loss: 0.5998 - val_mae: 0.5663\n",
      "Epoch 84/200\n",
      "39/39 - 0s - loss: 0.5385 - mae: 0.5454 - val_loss: 0.5957 - val_mae: 0.5641\n",
      "Epoch 85/200\n",
      "39/39 - 0s - loss: 0.5390 - mae: 0.5449 - val_loss: 0.5956 - val_mae: 0.5646\n",
      "Epoch 86/200\n",
      "39/39 - 0s - loss: 0.5370 - mae: 0.5451 - val_loss: 0.5916 - val_mae: 0.5620\n",
      "Epoch 87/200\n",
      "39/39 - 0s - loss: 0.5359 - mae: 0.5443 - val_loss: 0.5871 - val_mae: 0.5609\n",
      "Epoch 88/200\n",
      "39/39 - 0s - loss: 0.5343 - mae: 0.5435 - val_loss: 0.5910 - val_mae: 0.5635\n",
      "Epoch 89/200\n",
      "39/39 - 0s - loss: 0.5328 - mae: 0.5436 - val_loss: 0.5899 - val_mae: 0.5628\n",
      "Epoch 90/200\n",
      "39/39 - 0s - loss: 0.5311 - mae: 0.5424 - val_loss: 0.5867 - val_mae: 0.5613\n",
      "Epoch 91/200\n",
      "39/39 - 0s - loss: 0.5319 - mae: 0.5428 - val_loss: 0.5861 - val_mae: 0.5612\n",
      "Epoch 92/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 - 0s - loss: 0.5292 - mae: 0.5412 - val_loss: 0.5823 - val_mae: 0.5600\n",
      "Epoch 93/200\n",
      "39/39 - 0s - loss: 0.5269 - mae: 0.5403 - val_loss: 0.5822 - val_mae: 0.5609\n",
      "Epoch 94/200\n",
      "39/39 - 0s - loss: 0.5297 - mae: 0.5430 - val_loss: 0.5811 - val_mae: 0.5599\n",
      "Epoch 95/200\n",
      "39/39 - 0s - loss: 0.5262 - mae: 0.5414 - val_loss: 0.5848 - val_mae: 0.5617\n",
      "Epoch 96/200\n",
      "39/39 - 0s - loss: 0.5239 - mae: 0.5401 - val_loss: 0.5810 - val_mae: 0.5608\n",
      "Epoch 97/200\n",
      "39/39 - 0s - loss: 0.5231 - mae: 0.5408 - val_loss: 0.5835 - val_mae: 0.5612\n",
      "Epoch 98/200\n",
      "39/39 - 0s - loss: 0.5236 - mae: 0.5406 - val_loss: 0.5800 - val_mae: 0.5599\n",
      "Epoch 99/200\n",
      "39/39 - 0s - loss: 0.5226 - mae: 0.5399 - val_loss: 0.5768 - val_mae: 0.5586\n",
      "Epoch 100/200\n",
      "39/39 - 0s - loss: 0.5218 - mae: 0.5398 - val_loss: 0.5862 - val_mae: 0.5651\n",
      "Epoch 101/200\n",
      "39/39 - 0s - loss: 0.5223 - mae: 0.5422 - val_loss: 0.5738 - val_mae: 0.5573\n",
      "Epoch 102/200\n",
      "39/39 - 0s - loss: 0.5197 - mae: 0.5397 - val_loss: 0.5709 - val_mae: 0.5575\n",
      "Epoch 103/200\n",
      "39/39 - 0s - loss: 0.5196 - mae: 0.5386 - val_loss: 0.5710 - val_mae: 0.5578\n",
      "Epoch 104/200\n",
      "39/39 - 0s - loss: 0.5195 - mae: 0.5401 - val_loss: 0.5761 - val_mae: 0.5594\n",
      "Epoch 105/200\n",
      "39/39 - 0s - loss: 0.5167 - mae: 0.5381 - val_loss: 0.5687 - val_mae: 0.5564\n",
      "Epoch 106/200\n",
      "39/39 - 0s - loss: 0.5149 - mae: 0.5378 - val_loss: 0.5743 - val_mae: 0.5595\n",
      "Epoch 107/200\n",
      "39/39 - 0s - loss: 0.5153 - mae: 0.5380 - val_loss: 0.5697 - val_mae: 0.5590\n",
      "Epoch 108/200\n",
      "39/39 - 0s - loss: 0.5144 - mae: 0.5383 - val_loss: 0.5680 - val_mae: 0.5558\n",
      "Epoch 109/200\n",
      "39/39 - 0s - loss: 0.5143 - mae: 0.5385 - val_loss: 0.5675 - val_mae: 0.5564\n",
      "Epoch 110/200\n",
      "39/39 - 0s - loss: 0.5136 - mae: 0.5372 - val_loss: 0.5642 - val_mae: 0.5560\n",
      "Epoch 111/200\n",
      "39/39 - 0s - loss: 0.5147 - mae: 0.5395 - val_loss: 0.5656 - val_mae: 0.5572\n",
      "Epoch 112/200\n",
      "39/39 - 0s - loss: 0.5126 - mae: 0.5377 - val_loss: 0.5673 - val_mae: 0.5582\n",
      "Epoch 113/200\n",
      "39/39 - 0s - loss: 0.5099 - mae: 0.5366 - val_loss: 0.5615 - val_mae: 0.5556\n",
      "Epoch 114/200\n",
      "39/39 - 0s - loss: 0.5128 - mae: 0.5381 - val_loss: 0.5611 - val_mae: 0.5555\n",
      "Epoch 115/200\n",
      "39/39 - 0s - loss: 0.5095 - mae: 0.5374 - val_loss: 0.5589 - val_mae: 0.5541\n",
      "Epoch 116/200\n",
      "39/39 - 0s - loss: 0.5121 - mae: 0.5382 - val_loss: 0.5590 - val_mae: 0.5537\n",
      "Epoch 117/200\n",
      "39/39 - 0s - loss: 0.5074 - mae: 0.5362 - val_loss: 0.5598 - val_mae: 0.5551\n",
      "Epoch 118/200\n",
      "39/39 - 0s - loss: 0.5081 - mae: 0.5372 - val_loss: 0.5590 - val_mae: 0.5542\n",
      "Epoch 119/200\n",
      "39/39 - 0s - loss: 0.5060 - mae: 0.5349 - val_loss: 0.5657 - val_mae: 0.5574\n",
      "Epoch 120/200\n",
      "39/39 - 0s - loss: 0.5072 - mae: 0.5373 - val_loss: 0.5638 - val_mae: 0.5554\n",
      "Epoch 121/200\n",
      "39/39 - 0s - loss: 0.5058 - mae: 0.5353 - val_loss: 0.5562 - val_mae: 0.5528\n",
      "Epoch 122/200\n",
      "39/39 - 0s - loss: 0.5079 - mae: 0.5362 - val_loss: 0.5564 - val_mae: 0.5538\n",
      "Epoch 123/200\n",
      "39/39 - 0s - loss: 0.5051 - mae: 0.5369 - val_loss: 0.5559 - val_mae: 0.5539\n",
      "Epoch 124/200\n",
      "39/39 - 0s - loss: 0.5034 - mae: 0.5354 - val_loss: 0.5525 - val_mae: 0.5525\n",
      "Epoch 125/200\n",
      "39/39 - 0s - loss: 0.5035 - mae: 0.5364 - val_loss: 0.5557 - val_mae: 0.5545\n",
      "Epoch 126/200\n",
      "39/39 - 0s - loss: 0.5069 - mae: 0.5370 - val_loss: 0.5553 - val_mae: 0.5534\n",
      "Epoch 127/200\n",
      "39/39 - 0s - loss: 0.5021 - mae: 0.5342 - val_loss: 0.5551 - val_mae: 0.5538\n",
      "Epoch 128/200\n",
      "39/39 - 0s - loss: 0.5028 - mae: 0.5349 - val_loss: 0.5559 - val_mae: 0.5537\n",
      "Epoch 129/200\n",
      "39/39 - 0s - loss: 0.5024 - mae: 0.5365 - val_loss: 0.5544 - val_mae: 0.5523\n",
      "Epoch 130/200\n",
      "39/39 - 0s - loss: 0.5032 - mae: 0.5355 - val_loss: 0.5601 - val_mae: 0.5547\n",
      "Epoch 131/200\n",
      "39/39 - 0s - loss: 0.5010 - mae: 0.5354 - val_loss: 0.5521 - val_mae: 0.5508\n",
      "Epoch 132/200\n",
      "39/39 - 0s - loss: 0.5059 - mae: 0.5362 - val_loss: 0.5553 - val_mae: 0.5517\n",
      "Epoch 133/200\n",
      "39/39 - 0s - loss: 0.5000 - mae: 0.5342 - val_loss: 0.5500 - val_mae: 0.5515\n",
      "Epoch 134/200\n",
      "39/39 - 0s - loss: 0.4977 - mae: 0.5340 - val_loss: 0.5528 - val_mae: 0.5538\n",
      "Epoch 135/200\n",
      "39/39 - 0s - loss: 0.4997 - mae: 0.5352 - val_loss: 0.5485 - val_mae: 0.5525\n",
      "Epoch 136/200\n",
      "39/39 - 0s - loss: 0.4980 - mae: 0.5342 - val_loss: 0.5516 - val_mae: 0.5544\n",
      "Epoch 137/200\n",
      "39/39 - 0s - loss: 0.4980 - mae: 0.5354 - val_loss: 0.5449 - val_mae: 0.5512\n",
      "Epoch 138/200\n",
      "39/39 - 0s - loss: 0.4985 - mae: 0.5347 - val_loss: 0.5444 - val_mae: 0.5512\n",
      "Epoch 139/200\n",
      "39/39 - 0s - loss: 0.4967 - mae: 0.5338 - val_loss: 0.5541 - val_mae: 0.5566\n",
      "Epoch 140/200\n",
      "39/39 - 0s - loss: 0.4957 - mae: 0.5334 - val_loss: 0.5472 - val_mae: 0.5498\n",
      "Epoch 141/200\n",
      "39/39 - 0s - loss: 0.4983 - mae: 0.5357 - val_loss: 0.5439 - val_mae: 0.5488\n",
      "Epoch 142/200\n",
      "39/39 - 0s - loss: 0.4982 - mae: 0.5356 - val_loss: 0.5479 - val_mae: 0.5523\n",
      "Epoch 143/200\n",
      "39/39 - 1s - loss: 0.4984 - mae: 0.5348 - val_loss: 0.5434 - val_mae: 0.5502\n",
      "Epoch 144/200\n",
      "39/39 - 0s - loss: 0.4950 - mae: 0.5339 - val_loss: 0.5497 - val_mae: 0.5544\n",
      "Epoch 145/200\n",
      "39/39 - 0s - loss: 0.4961 - mae: 0.5356 - val_loss: 0.5423 - val_mae: 0.5497\n",
      "Epoch 146/200\n",
      "39/39 - 0s - loss: 0.4937 - mae: 0.5331 - val_loss: 0.5391 - val_mae: 0.5485\n",
      "Epoch 147/200\n",
      "39/39 - 0s - loss: 0.4937 - mae: 0.5328 - val_loss: 0.5396 - val_mae: 0.5489\n",
      "Epoch 148/200\n",
      "39/39 - 0s - loss: 0.4944 - mae: 0.5343 - val_loss: 0.5370 - val_mae: 0.5473\n",
      "Epoch 149/200\n",
      "39/39 - 0s - loss: 0.4953 - mae: 0.5356 - val_loss: 0.5414 - val_mae: 0.5503\n",
      "Epoch 150/200\n",
      "39/39 - 0s - loss: 0.4934 - mae: 0.5334 - val_loss: 0.5409 - val_mae: 0.5486\n",
      "Epoch 151/200\n",
      "39/39 - 0s - loss: 0.4906 - mae: 0.5324 - val_loss: 0.5372 - val_mae: 0.5482\n",
      "Epoch 152/200\n",
      "39/39 - 0s - loss: 0.4945 - mae: 0.5354 - val_loss: 0.5382 - val_mae: 0.5484\n",
      "Epoch 153/200\n",
      "39/39 - 0s - loss: 0.4927 - mae: 0.5347 - val_loss: 0.5394 - val_mae: 0.5505\n",
      "Epoch 154/200\n",
      "39/39 - 0s - loss: 0.4893 - mae: 0.5317 - val_loss: 0.5383 - val_mae: 0.5487\n",
      "Epoch 155/200\n",
      "39/39 - 0s - loss: 0.4896 - mae: 0.5316 - val_loss: 0.5407 - val_mae: 0.5522\n",
      "Epoch 156/200\n",
      "39/39 - 0s - loss: 0.4935 - mae: 0.5349 - val_loss: 0.5376 - val_mae: 0.5490\n",
      "Epoch 157/200\n",
      "39/39 - 0s - loss: 0.4944 - mae: 0.5351 - val_loss: 0.5339 - val_mae: 0.5485\n",
      "Epoch 158/200\n",
      "39/39 - 0s - loss: 0.4883 - mae: 0.5320 - val_loss: 0.5366 - val_mae: 0.5497\n",
      "Epoch 159/200\n",
      "39/39 - 0s - loss: 0.4877 - mae: 0.5322 - val_loss: 0.5338 - val_mae: 0.5474\n",
      "Epoch 160/200\n",
      "39/39 - 0s - loss: 0.4873 - mae: 0.5316 - val_loss: 0.5347 - val_mae: 0.5480\n",
      "Epoch 161/200\n",
      "39/39 - 0s - loss: 0.4868 - mae: 0.5306 - val_loss: 0.5394 - val_mae: 0.5521\n",
      "Epoch 162/200\n",
      "39/39 - 0s - loss: 0.4901 - mae: 0.5343 - val_loss: 0.5456 - val_mae: 0.5536\n",
      "Epoch 163/200\n",
      "39/39 - 0s - loss: 0.4887 - mae: 0.5331 - val_loss: 0.5352 - val_mae: 0.5492\n",
      "Epoch 164/200\n",
      "39/39 - 0s - loss: 0.4858 - mae: 0.5314 - val_loss: 0.5359 - val_mae: 0.5486\n",
      "Epoch 165/200\n",
      "39/39 - 0s - loss: 0.4873 - mae: 0.5335 - val_loss: 0.5359 - val_mae: 0.5485\n",
      "Epoch 166/200\n",
      "39/39 - 0s - loss: 0.4863 - mae: 0.5321 - val_loss: 0.5343 - val_mae: 0.5486\n",
      "Epoch 167/200\n",
      "39/39 - 0s - loss: 0.4856 - mae: 0.5312 - val_loss: 0.5325 - val_mae: 0.5478\n",
      "Epoch 168/200\n",
      "39/39 - 0s - loss: 0.4856 - mae: 0.5310 - val_loss: 0.5422 - val_mae: 0.5524\n",
      "Epoch 169/200\n",
      "39/39 - 0s - loss: 0.4870 - mae: 0.5331 - val_loss: 0.5325 - val_mae: 0.5479\n",
      "Epoch 170/200\n",
      "39/39 - 0s - loss: 0.4877 - mae: 0.5325 - val_loss: 0.5394 - val_mae: 0.5528\n",
      "Epoch 171/200\n",
      "39/39 - 0s - loss: 0.4857 - mae: 0.5320 - val_loss: 0.5288 - val_mae: 0.5464\n",
      "Epoch 172/200\n",
      "39/39 - 0s - loss: 0.4847 - mae: 0.5316 - val_loss: 0.5335 - val_mae: 0.5500\n",
      "Epoch 173/200\n",
      "39/39 - 0s - loss: 0.4914 - mae: 0.5365 - val_loss: 0.5317 - val_mae: 0.5474\n",
      "Epoch 174/200\n",
      "39/39 - 0s - loss: 0.4860 - mae: 0.5318 - val_loss: 0.5281 - val_mae: 0.5463\n",
      "Epoch 175/200\n",
      "39/39 - 0s - loss: 0.4843 - mae: 0.5319 - val_loss: 0.5275 - val_mae: 0.5454\n",
      "Epoch 176/200\n",
      "39/39 - 0s - loss: 0.4841 - mae: 0.5309 - val_loss: 0.5298 - val_mae: 0.5469\n",
      "Epoch 177/200\n",
      "39/39 - 0s - loss: 0.4837 - mae: 0.5313 - val_loss: 0.5313 - val_mae: 0.5494\n",
      "Epoch 178/200\n",
      "39/39 - 0s - loss: 0.4815 - mae: 0.5302 - val_loss: 0.5298 - val_mae: 0.5478\n",
      "Epoch 179/200\n",
      "39/39 - 0s - loss: 0.4808 - mae: 0.5309 - val_loss: 0.5339 - val_mae: 0.5504\n",
      "Epoch 180/200\n",
      "39/39 - 0s - loss: 0.4830 - mae: 0.5316 - val_loss: 0.5299 - val_mae: 0.5475\n",
      "Epoch 181/200\n",
      "39/39 - 0s - loss: 0.4822 - mae: 0.5310 - val_loss: 0.5296 - val_mae: 0.5497\n",
      "Epoch 182/200\n",
      "39/39 - 0s - loss: 0.4814 - mae: 0.5302 - val_loss: 0.5259 - val_mae: 0.5462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200\n",
      "39/39 - 0s - loss: 0.4811 - mae: 0.5309 - val_loss: 0.5266 - val_mae: 0.5467\n",
      "Epoch 184/200\n",
      "39/39 - 0s - loss: 0.4806 - mae: 0.5305 - val_loss: 0.5265 - val_mae: 0.5461\n",
      "Epoch 185/200\n",
      "39/39 - 0s - loss: 0.4798 - mae: 0.5300 - val_loss: 0.5292 - val_mae: 0.5472\n",
      "Epoch 186/200\n",
      "39/39 - 0s - loss: 0.4797 - mae: 0.5297 - val_loss: 0.5278 - val_mae: 0.5471\n",
      "Epoch 187/200\n",
      "39/39 - 0s - loss: 0.4855 - mae: 0.5311 - val_loss: 0.5243 - val_mae: 0.5455\n",
      "Epoch 188/200\n",
      "39/39 - 0s - loss: 0.4808 - mae: 0.5300 - val_loss: 0.5298 - val_mae: 0.5475\n",
      "Epoch 189/200\n",
      "39/39 - 0s - loss: 0.4799 - mae: 0.5306 - val_loss: 0.5340 - val_mae: 0.5503\n",
      "Epoch 190/200\n",
      "39/39 - 0s - loss: 0.4852 - mae: 0.5333 - val_loss: 0.5328 - val_mae: 0.5485\n",
      "Epoch 191/200\n",
      "39/39 - 0s - loss: 0.4784 - mae: 0.5288 - val_loss: 0.5290 - val_mae: 0.5477\n",
      "Epoch 192/200\n",
      "39/39 - 0s - loss: 0.4799 - mae: 0.5301 - val_loss: 0.5266 - val_mae: 0.5468\n",
      "Epoch 193/200\n",
      "39/39 - 0s - loss: 0.4784 - mae: 0.5301 - val_loss: 0.5384 - val_mae: 0.5521\n",
      "Epoch 194/200\n",
      "39/39 - 0s - loss: 0.4804 - mae: 0.5317 - val_loss: 0.5237 - val_mae: 0.5457\n",
      "Epoch 195/200\n",
      "39/39 - 0s - loss: 0.4800 - mae: 0.5299 - val_loss: 0.5234 - val_mae: 0.5452\n",
      "Epoch 196/200\n",
      "39/39 - 0s - loss: 0.4778 - mae: 0.5304 - val_loss: 0.5270 - val_mae: 0.5476\n",
      "Epoch 197/200\n",
      "39/39 - 0s - loss: 0.4792 - mae: 0.5300 - val_loss: 0.5264 - val_mae: 0.5458\n",
      "Epoch 198/200\n",
      "39/39 - 0s - loss: 0.4820 - mae: 0.5312 - val_loss: 0.5267 - val_mae: 0.5461\n",
      "Epoch 199/200\n",
      "39/39 - 0s - loss: 0.4769 - mae: 0.5297 - val_loss: 0.5251 - val_mae: 0.5457\n",
      "Epoch 200/200\n",
      "39/39 - 0s - loss: 0.4772 - mae: 0.5291 - val_loss: 0.5244 - val_mae: 0.5457\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=200, \n",
    "                    batch_size=128, \n",
    "                    verbose=2, \n",
    "                    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 1s 3ms/step - loss: 0.5030 - mae: 0.5416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc480325790>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_trans, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 - 0s - loss: 0.5195 - mae: 0.5464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5195215344429016, 0.5463820695877075]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test,y_test,batch_size=42,verbose=2)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.title('Loss / Mean Squared Error')\n",
    "pyplot.plot(history.history['loss'], label='train_loss')\n",
    "pyplot.plot(history.history['val_loss'], label='train_val')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       ...,\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_score(y_test,y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_nn =  pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_nn['error'] = ('mse', 'r2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_nn['Full_NN'] = (0.57,0.28) \n",
    "df_score_nn['NN_redwine'] = (0.60,0.13) \n",
    "df_score_nn['NN_whitewine'] = (0.75,0.09) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
