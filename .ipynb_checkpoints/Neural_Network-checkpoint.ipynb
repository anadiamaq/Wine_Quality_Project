{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>pH</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>type</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.4</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.56</td>\n",
       "      <td>34.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>7.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.68</td>\n",
       "      <td>67.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>7.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.26</td>\n",
       "      <td>5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>54.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>11.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.16</td>\n",
       "      <td>6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.58</td>\n",
       "      <td>60.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.4</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.56</td>\n",
       "      <td>34.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  chlorides  citric_acid  density  fixed_acidity  \\\n",
       "0      9.4      0.076         0.00   0.9978            7.4   \n",
       "1      9.8      0.098         0.00   0.9968            7.8   \n",
       "2      9.8      0.092         0.04   0.9970            7.8   \n",
       "3      9.8      0.075         0.56   0.9980           11.2   \n",
       "4      9.4      0.076         0.00   0.9978            7.4   \n",
       "\n",
       "   free_sulfur_dioxide    pH  quality  residual_sugar  sulphates  \\\n",
       "0                 11.0  3.51        5             1.9       0.56   \n",
       "1                 25.0  3.20        5             2.6       0.68   \n",
       "2                 15.0  3.26        5             2.3       0.65   \n",
       "3                 17.0  3.16        6             1.9       0.58   \n",
       "4                 11.0  3.51        5             1.9       0.56   \n",
       "\n",
       "   total_sulfur_dioxide type  volatile_acidity  \n",
       "0                  34.0  red              0.70  \n",
       "1                  67.0  red              0.88  \n",
       "2                  54.0  red              0.76  \n",
       "3                  60.0  red              0.28  \n",
       "4                  34.0  red              0.70  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_qa = pd.read_csv('data/wine-qa.csv')\n",
    "wine_qa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>pH</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.491801</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>0.318633</td>\n",
       "      <td>0.994697</td>\n",
       "      <td>7.215307</td>\n",
       "      <td>30.525319</td>\n",
       "      <td>3.218501</td>\n",
       "      <td>5.818378</td>\n",
       "      <td>5.443235</td>\n",
       "      <td>0.531268</td>\n",
       "      <td>115.744574</td>\n",
       "      <td>0.339666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.192712</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>0.145318</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>1.296434</td>\n",
       "      <td>17.749400</td>\n",
       "      <td>0.160787</td>\n",
       "      <td>0.873255</td>\n",
       "      <td>4.757804</td>\n",
       "      <td>0.148806</td>\n",
       "      <td>56.521855</td>\n",
       "      <td>0.164636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.500000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.300000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.300000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.996990</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.900000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.580000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           alcohol    chlorides  citric_acid      density  fixed_acidity  \\\n",
       "count  6497.000000  6497.000000  6497.000000  6497.000000    6497.000000   \n",
       "mean     10.491801     0.056034     0.318633     0.994697       7.215307   \n",
       "std       1.192712     0.035034     0.145318     0.002999       1.296434   \n",
       "min       8.000000     0.009000     0.000000     0.987110       3.800000   \n",
       "25%       9.500000     0.038000     0.250000     0.992340       6.400000   \n",
       "50%      10.300000     0.047000     0.310000     0.994890       7.000000   \n",
       "75%      11.300000     0.065000     0.390000     0.996990       7.700000   \n",
       "max      14.900000     0.611000     1.660000     1.038980      15.900000   \n",
       "\n",
       "       free_sulfur_dioxide           pH      quality  residual_sugar  \\\n",
       "count          6497.000000  6497.000000  6497.000000     6497.000000   \n",
       "mean             30.525319     3.218501     5.818378        5.443235   \n",
       "std              17.749400     0.160787     0.873255        4.757804   \n",
       "min               1.000000     2.720000     3.000000        0.600000   \n",
       "25%              17.000000     3.110000     5.000000        1.800000   \n",
       "50%              29.000000     3.210000     6.000000        3.000000   \n",
       "75%              41.000000     3.320000     6.000000        8.100000   \n",
       "max             289.000000     4.010000     9.000000       65.800000   \n",
       "\n",
       "         sulphates  total_sulfur_dioxide  volatile_acidity  \n",
       "count  6497.000000           6497.000000       6497.000000  \n",
       "mean      0.531268            115.744574          0.339666  \n",
       "std       0.148806             56.521855          0.164636  \n",
       "min       0.220000              6.000000          0.080000  \n",
       "25%       0.430000             77.000000          0.230000  \n",
       "50%       0.510000            118.000000          0.290000  \n",
       "75%       0.600000            156.000000          0.400000  \n",
       "max       2.000000            440.000000          1.580000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_qa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wine_qa['quality']\n",
    "X = wine_qa.drop(columns=['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.fit(X['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = label_encoder.transform(X['type'])\n",
    "X = X.drop(columns=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "prep = StandardScaler()\n",
    "prep.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.915464</td>\n",
       "      <td>0.569958</td>\n",
       "      <td>-2.192833</td>\n",
       "      <td>1.034993</td>\n",
       "      <td>0.142473</td>\n",
       "      <td>-1.100140</td>\n",
       "      <td>1.813090</td>\n",
       "      <td>-0.744778</td>\n",
       "      <td>0.193097</td>\n",
       "      <td>-1.446359</td>\n",
       "      <td>2.188833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.580068</td>\n",
       "      <td>1.197975</td>\n",
       "      <td>-2.192833</td>\n",
       "      <td>0.701486</td>\n",
       "      <td>0.451036</td>\n",
       "      <td>-0.311320</td>\n",
       "      <td>-0.115073</td>\n",
       "      <td>-0.597640</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>-0.862469</td>\n",
       "      <td>3.282235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.580068</td>\n",
       "      <td>1.026697</td>\n",
       "      <td>-1.917553</td>\n",
       "      <td>0.768188</td>\n",
       "      <td>0.451036</td>\n",
       "      <td>-0.874763</td>\n",
       "      <td>0.258120</td>\n",
       "      <td>-0.660699</td>\n",
       "      <td>0.797958</td>\n",
       "      <td>-1.092486</td>\n",
       "      <td>2.553300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.580068</td>\n",
       "      <td>0.541412</td>\n",
       "      <td>1.661085</td>\n",
       "      <td>1.101694</td>\n",
       "      <td>3.073817</td>\n",
       "      <td>-0.762074</td>\n",
       "      <td>-0.363868</td>\n",
       "      <td>-0.744778</td>\n",
       "      <td>0.327510</td>\n",
       "      <td>-0.986324</td>\n",
       "      <td>-0.362438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.915464</td>\n",
       "      <td>0.569958</td>\n",
       "      <td>-2.192833</td>\n",
       "      <td>1.034993</td>\n",
       "      <td>0.142473</td>\n",
       "      <td>-1.100140</td>\n",
       "      <td>1.813090</td>\n",
       "      <td>-0.744778</td>\n",
       "      <td>0.193097</td>\n",
       "      <td>-1.446359</td>\n",
       "      <td>2.188833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.915464  0.569958 -2.192833  1.034993  0.142473 -1.100140  1.813090   \n",
       "1 -0.580068  1.197975 -2.192833  0.701486  0.451036 -0.311320 -0.115073   \n",
       "2 -0.580068  1.026697 -1.917553  0.768188  0.451036 -0.874763  0.258120   \n",
       "3 -0.580068  0.541412  1.661085  1.101694  3.073817 -0.762074 -0.363868   \n",
       "4 -0.915464  0.569958 -2.192833  1.034993  0.142473 -1.100140  1.813090   \n",
       "\n",
       "          7         8         9        10  type  \n",
       "0 -0.744778  0.193097 -1.446359  2.188833     0  \n",
       "1 -0.597640  0.999579 -0.862469  3.282235     0  \n",
       "2 -0.660699  0.797958 -1.092486  2.553300     0  \n",
       "3 -0.744778  0.327510 -0.986324 -0.362438     0  \n",
       "4 -0.744778  0.193097 -1.446359  2.188833     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trans = pd.DataFrame(prep.transform(X))\n",
    "X_trans['type'] = color\n",
    "X_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trans,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>-0.663917</td>\n",
       "      <td>0.427227</td>\n",
       "      <td>-0.747613</td>\n",
       "      <td>0.568084</td>\n",
       "      <td>0.296754</td>\n",
       "      <td>-1.325517</td>\n",
       "      <td>0.382517</td>\n",
       "      <td>-0.681719</td>\n",
       "      <td>0.125890</td>\n",
       "      <td>-1.552520</td>\n",
       "      <td>1.277665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>-0.076974</td>\n",
       "      <td>-0.600437</td>\n",
       "      <td>0.904066</td>\n",
       "      <td>0.768188</td>\n",
       "      <td>1.453864</td>\n",
       "      <td>-0.142287</td>\n",
       "      <td>-0.115073</td>\n",
       "      <td>1.083937</td>\n",
       "      <td>-0.478971</td>\n",
       "      <td>0.146068</td>\n",
       "      <td>-0.423183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>1.851553</td>\n",
       "      <td>-0.457706</td>\n",
       "      <td>0.078226</td>\n",
       "      <td>-1.786472</td>\n",
       "      <td>-0.937495</td>\n",
       "      <td>-0.874763</td>\n",
       "      <td>0.444716</td>\n",
       "      <td>-0.229795</td>\n",
       "      <td>-0.210144</td>\n",
       "      <td>-0.632451</td>\n",
       "      <td>-0.483928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>1.264610</td>\n",
       "      <td>0.655596</td>\n",
       "      <td>0.284686</td>\n",
       "      <td>0.484707</td>\n",
       "      <td>1.531004</td>\n",
       "      <td>-1.100140</td>\n",
       "      <td>0.693511</td>\n",
       "      <td>-0.681719</td>\n",
       "      <td>2.209301</td>\n",
       "      <td>-1.499439</td>\n",
       "      <td>-0.180205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.593818</td>\n",
       "      <td>0.512865</td>\n",
       "      <td>-0.678793</td>\n",
       "      <td>-0.105599</td>\n",
       "      <td>-0.320370</td>\n",
       "      <td>-0.874763</td>\n",
       "      <td>1.128903</td>\n",
       "      <td>-0.765798</td>\n",
       "      <td>1.940474</td>\n",
       "      <td>-1.623295</td>\n",
       "      <td>1.338409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "194  -0.663917  0.427227 -0.747613  0.568084  0.296754 -1.325517  0.382517   \n",
       "2373 -0.076974 -0.600437  0.904066  0.768188  1.453864 -0.142287 -0.115073   \n",
       "4920  1.851553 -0.457706  0.078226 -1.786472 -0.937495 -0.874763  0.444716   \n",
       "1093  1.264610  0.655596  0.284686  0.484707  1.531004 -1.100140  0.693511   \n",
       "859   0.593818  0.512865 -0.678793 -0.105599 -0.320370 -0.874763  1.128903   \n",
       "\n",
       "             7         8         9        10  type  \n",
       "194  -0.681719  0.125890 -1.552520  1.277665     0  \n",
       "2373  1.083937 -0.478971  0.146068 -0.423183     1  \n",
       "4920 -0.229795 -0.210144 -0.632451 -0.483928     1  \n",
       "1093 -0.681719  2.209301 -1.499439 -0.180205     0  \n",
       "859  -0.765798  1.940474 -1.623295  1.338409     0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_shape=(12,),kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 91        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 255\n",
      "Trainable params: 255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 12),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'dense_input'}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 12),\n",
       "    'dtype': 'float32',\n",
       "    'units': 12,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': {'class_name': 'L2',\n",
       "     'config': {'l2': 0.009999999776482582}},\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 7,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.32489467, -0.3816123 ,  0.01155984, -0.05468524, -0.35854065,\n",
       "         -0.43729675,  0.14738059,  0.04297781, -0.13706994, -0.48804808,\n",
       "         -0.02616823, -0.01783574],\n",
       "        [-0.42106175,  0.0520407 , -0.38673997,  0.18814743, -0.06988883,\n",
       "         -0.346089  , -0.25199425,  0.43764722, -0.18582845, -0.48245203,\n",
       "          0.32144642, -0.3283987 ],\n",
       "        [ 0.23891497, -0.37162912, -0.33758152,  0.17112947,  0.2357266 ,\n",
       "          0.27448606, -0.10147488,  0.05308211, -0.24381864, -0.28097713,\n",
       "         -0.37743723, -0.09607792],\n",
       "        [-0.23520589,  0.28093767, -0.1324352 , -0.1802113 , -0.21695757,\n",
       "         -0.08303058,  0.27687168, -0.05328441,  0.48272336,  0.34321046,\n",
       "         -0.2652613 , -0.45436203],\n",
       "        [ 0.47564673, -0.20601165, -0.20188451,  0.11617661, -0.39830816,\n",
       "         -0.1005367 , -0.03247261,  0.02821124,  0.28266668,  0.45902812,\n",
       "          0.02863681,  0.13234663],\n",
       "        [-0.11624444, -0.18806195,  0.22798407, -0.41850913,  0.18804514,\n",
       "         -0.17091024, -0.02538574, -0.25000072,  0.36861968,  0.16599429,\n",
       "         -0.47678852,  0.14259613],\n",
       "        [ 0.09894121,  0.25247037, -0.18626201,  0.20021021,  0.4937265 ,\n",
       "         -0.31545043, -0.4715495 ,  0.30608833, -0.28085303, -0.4116212 ,\n",
       "         -0.43526614, -0.27555954],\n",
       "        [ 0.17449057, -0.38343406, -0.03103149, -0.36676145,  0.21368074,\n",
       "          0.12391448, -0.23265207,  0.29080188, -0.2900219 , -0.02792537,\n",
       "          0.03742099,  0.45374238],\n",
       "        [ 0.36526108,  0.22445083,  0.17612946, -0.40480077, -0.35540175,\n",
       "          0.28075993,  0.25523722,  0.25443017, -0.15603888, -0.33596253,\n",
       "         -0.32223892,  0.20919883],\n",
       "        [-0.06092787,  0.36712015,  0.00236356,  0.22429717,  0.00922215,\n",
       "         -0.40733123,  0.10800338, -0.05348814, -0.20501077,  0.48351872,\n",
       "         -0.11955309, -0.09799814],\n",
       "        [ 0.21227312,  0.17192066, -0.28303254,  0.29246032,  0.25756347,\n",
       "          0.49247348,  0.17521083, -0.39815927,  0.15318227,  0.19051468,\n",
       "         -0.3484776 ,  0.42202866],\n",
       "        [ 0.47955465,  0.206007  , -0.16787565, -0.23845828, -0.14475644,\n",
       "          0.1852299 , -0.49587142,  0.37452197, -0.41118693, -0.2756517 ,\n",
       "          0.07905173, -0.29327857]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.45864764,  0.46940154, -0.14538401,  0.3873853 , -0.00857615,\n",
       "         -0.26590517,  0.30885112],\n",
       "        [-0.06982619, -0.12424242, -0.37619603, -0.5518064 , -0.40312564,\n",
       "          0.05081248, -0.0955748 ],\n",
       "        [-0.36046612,  0.38130933,  0.08787   , -0.35647354, -0.22323653,\n",
       "          0.09685701, -0.5431694 ],\n",
       "        [ 0.23829156, -0.55176175, -0.18393746,  0.39517587, -0.5347238 ,\n",
       "         -0.29607993, -0.16659486],\n",
       "        [ 0.25714344, -0.0232175 , -0.10919476, -0.26671064,  0.23635566,\n",
       "          0.12000275,  0.09733808],\n",
       "        [-0.26657572,  0.05897665,  0.34761548, -0.0082103 ,  0.03092784,\n",
       "          0.15151799, -0.54996043],\n",
       "        [-0.17960283,  0.19223285,  0.22470188, -0.544883  ,  0.044761  ,\n",
       "         -0.07093325, -0.49063367],\n",
       "        [ 0.2973945 ,  0.23278725,  0.3679955 , -0.32482192, -0.05351377,\n",
       "         -0.5605192 ,  0.43540537],\n",
       "        [-0.49045053,  0.1523062 , -0.27328557,  0.12296468,  0.37651998,\n",
       "         -0.5343262 , -0.4892888 ],\n",
       "        [ 0.27634835, -0.56128144,  0.22695607,  0.53424996,  0.41406834,\n",
       "         -0.30054092, -0.09619728],\n",
       "        [-0.40130126,  0.333018  ,  0.20991921,  0.1455676 ,  0.12092257,\n",
       "          0.14633471,  0.1154303 ],\n",
       "        [ 0.36327475,  0.40925682, -0.30895445, -0.02482605, -0.26039806,\n",
       "          0.27487928,  0.0219689 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.7406171 ],\n",
       "        [ 0.80923384],\n",
       "        [-0.68399584],\n",
       "        [ 0.25837404],\n",
       "        [-0.4554885 ],\n",
       "        [ 0.08373761],\n",
       "        [-0.7691055 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg, bs = model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg.shape # 1 weight per input per neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7406171]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg[:1,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.shape # 1 bias per neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>-0.663917</td>\n",
       "      <td>0.427227</td>\n",
       "      <td>-0.747613</td>\n",
       "      <td>0.568084</td>\n",
       "      <td>0.296754</td>\n",
       "      <td>-1.325517</td>\n",
       "      <td>0.382517</td>\n",
       "      <td>-0.681719</td>\n",
       "      <td>0.125890</td>\n",
       "      <td>-1.552520</td>\n",
       "      <td>1.277665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>-0.076974</td>\n",
       "      <td>-0.600437</td>\n",
       "      <td>0.904066</td>\n",
       "      <td>0.768188</td>\n",
       "      <td>1.453864</td>\n",
       "      <td>-0.142287</td>\n",
       "      <td>-0.115073</td>\n",
       "      <td>1.083937</td>\n",
       "      <td>-0.478971</td>\n",
       "      <td>0.146068</td>\n",
       "      <td>-0.423183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>1.851553</td>\n",
       "      <td>-0.457706</td>\n",
       "      <td>0.078226</td>\n",
       "      <td>-1.786472</td>\n",
       "      <td>-0.937495</td>\n",
       "      <td>-0.874763</td>\n",
       "      <td>0.444716</td>\n",
       "      <td>-0.229795</td>\n",
       "      <td>-0.210144</td>\n",
       "      <td>-0.632451</td>\n",
       "      <td>-0.483928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>1.264610</td>\n",
       "      <td>0.655596</td>\n",
       "      <td>0.284686</td>\n",
       "      <td>0.484707</td>\n",
       "      <td>1.531004</td>\n",
       "      <td>-1.100140</td>\n",
       "      <td>0.693511</td>\n",
       "      <td>-0.681719</td>\n",
       "      <td>2.209301</td>\n",
       "      <td>-1.499439</td>\n",
       "      <td>-0.180205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.593818</td>\n",
       "      <td>0.512865</td>\n",
       "      <td>-0.678793</td>\n",
       "      <td>-0.105599</td>\n",
       "      <td>-0.320370</td>\n",
       "      <td>-0.874763</td>\n",
       "      <td>1.128903</td>\n",
       "      <td>-0.765798</td>\n",
       "      <td>1.940474</td>\n",
       "      <td>-1.623295</td>\n",
       "      <td>1.338409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "194  -0.663917  0.427227 -0.747613  0.568084  0.296754 -1.325517  0.382517   \n",
       "2373 -0.076974 -0.600437  0.904066  0.768188  1.453864 -0.142287 -0.115073   \n",
       "4920  1.851553 -0.457706  0.078226 -1.786472 -0.937495 -0.874763  0.444716   \n",
       "1093  1.264610  0.655596  0.284686  0.484707  1.531004 -1.100140  0.693511   \n",
       "859   0.593818  0.512865 -0.678793 -0.105599 -0.320370 -0.874763  1.128903   \n",
       "\n",
       "             7         8         9        10  type  \n",
       "194  -0.681719  0.125890 -1.552520  1.277665     0  \n",
       "2373  1.083937 -0.478971  0.146068 -0.423183     1  \n",
       "4920 -0.229795 -0.210144 -0.632451 -0.483928     1  \n",
       "1093 -0.681719  2.209301 -1.499439 -0.180205     0  \n",
       "859  -0.765798  1.940474 -1.623295  1.338409     0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4872.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.005927</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>-0.011316</td>\n",
       "      <td>-0.000439</td>\n",
       "      <td>-0.011167</td>\n",
       "      <td>-0.005544</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>-0.004509</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.75431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000438</td>\n",
       "      <td>0.992112</td>\n",
       "      <td>0.995044</td>\n",
       "      <td>1.011521</td>\n",
       "      <td>1.005359</td>\n",
       "      <td>1.000103</td>\n",
       "      <td>0.997784</td>\n",
       "      <td>1.007667</td>\n",
       "      <td>1.011380</td>\n",
       "      <td>0.999782</td>\n",
       "      <td>1.010777</td>\n",
       "      <td>0.43054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.089350</td>\n",
       "      <td>-1.342639</td>\n",
       "      <td>-2.192833</td>\n",
       "      <td>-2.523522</td>\n",
       "      <td>-2.634589</td>\n",
       "      <td>-1.663583</td>\n",
       "      <td>-3.100615</td>\n",
       "      <td>-1.018034</td>\n",
       "      <td>-2.091935</td>\n",
       "      <td>-1.941780</td>\n",
       "      <td>-1.577330</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.831615</td>\n",
       "      <td>-0.514799</td>\n",
       "      <td>-0.541153</td>\n",
       "      <td>-0.794290</td>\n",
       "      <td>-0.628933</td>\n",
       "      <td>-0.762074</td>\n",
       "      <td>-0.674862</td>\n",
       "      <td>-0.765798</td>\n",
       "      <td>-0.680592</td>\n",
       "      <td>-0.678897</td>\n",
       "      <td>-0.666161</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.160823</td>\n",
       "      <td>-0.257883</td>\n",
       "      <td>-0.059414</td>\n",
       "      <td>0.041143</td>\n",
       "      <td>-0.166089</td>\n",
       "      <td>-0.085943</td>\n",
       "      <td>-0.052874</td>\n",
       "      <td>-0.513561</td>\n",
       "      <td>-0.142937</td>\n",
       "      <td>0.039907</td>\n",
       "      <td>-0.301694</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.677667</td>\n",
       "      <td>0.227403</td>\n",
       "      <td>0.491146</td>\n",
       "      <td>0.749011</td>\n",
       "      <td>0.373895</td>\n",
       "      <td>0.590188</td>\n",
       "      <td>0.631312</td>\n",
       "      <td>0.571582</td>\n",
       "      <td>0.461924</td>\n",
       "      <td>0.694571</td>\n",
       "      <td>0.366496</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.696231</td>\n",
       "      <td>15.813640</td>\n",
       "      <td>9.231281</td>\n",
       "      <td>14.768791</td>\n",
       "      <td>6.699425</td>\n",
       "      <td>14.563567</td>\n",
       "      <td>4.923029</td>\n",
       "      <td>12.686822</td>\n",
       "      <td>9.870879</td>\n",
       "      <td>5.737257</td>\n",
       "      <td>7.534354</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  4872.000000  4872.000000  4872.000000  4872.000000  4872.000000   \n",
       "mean     -0.005927    -0.003703    -0.011316    -0.000439    -0.011167   \n",
       "std       1.000438     0.992112     0.995044     1.011521     1.005359   \n",
       "min      -2.089350    -1.342639    -2.192833    -2.523522    -2.634589   \n",
       "25%      -0.831615    -0.514799    -0.541153    -0.794290    -0.628933   \n",
       "50%      -0.160823    -0.257883    -0.059414     0.041143    -0.166089   \n",
       "75%       0.677667     0.227403     0.491146     0.749011     0.373895   \n",
       "max       3.696231    15.813640     9.231281    14.768791     6.699425   \n",
       "\n",
       "                 5            6            7            8            9  \\\n",
       "count  4872.000000  4872.000000  4872.000000  4872.000000  4872.000000   \n",
       "mean     -0.005544     0.008954     0.002524     0.004388    -0.004509   \n",
       "std       1.000103     0.997784     1.007667     1.011380     0.999782   \n",
       "min      -1.663583    -3.100615    -1.018034    -2.091935    -1.941780   \n",
       "25%      -0.762074    -0.674862    -0.765798    -0.680592    -0.678897   \n",
       "50%      -0.085943    -0.052874    -0.513561    -0.142937     0.039907   \n",
       "75%       0.590188     0.631312     0.571582     0.461924     0.694571   \n",
       "max      14.563567     4.923029    12.686822     9.870879     5.737257   \n",
       "\n",
       "                10        type  \n",
       "count  4872.000000  4872.00000  \n",
       "mean      0.001829     0.75431  \n",
       "std       1.010777     0.43054  \n",
       "min      -1.577330     0.00000  \n",
       "25%      -0.666161     1.00000  \n",
       "50%      -0.301694     1.00000  \n",
       "75%       0.366496     1.00000  \n",
       "max       7.534354     1.00000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= 'mse',\n",
    "              optimizer= 'adam',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./logs\", histogram_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "39/39 - 0s - loss: 30.4141 - mae: 5.4344 - val_loss: 27.3676 - val_mae: 5.1390\n",
      "Epoch 2/200\n",
      "39/39 - 0s - loss: 23.9121 - mae: 4.7832 - val_loss: 20.1220 - val_mae: 4.3592\n",
      "Epoch 3/200\n",
      "39/39 - 0s - loss: 16.0502 - mae: 3.8459 - val_loss: 11.9322 - val_mae: 3.2494\n",
      "Epoch 4/200\n",
      "39/39 - 0s - loss: 8.2565 - mae: 2.5963 - val_loss: 5.3005 - val_mae: 1.9770\n",
      "Epoch 5/200\n",
      "39/39 - 0s - loss: 3.5715 - mae: 1.5363 - val_loss: 2.6597 - val_mae: 1.2740\n",
      "Epoch 6/200\n",
      "39/39 - 0s - loss: 2.2472 - mae: 1.1343 - val_loss: 2.1376 - val_mae: 1.1072\n",
      "Epoch 7/200\n",
      "39/39 - 0s - loss: 1.9633 - mae: 1.0347 - val_loss: 1.9408 - val_mae: 1.0439\n",
      "Epoch 8/200\n",
      "39/39 - 0s - loss: 1.7980 - mae: 0.9853 - val_loss: 1.7907 - val_mae: 1.0007\n",
      "Epoch 9/200\n",
      "39/39 - 0s - loss: 1.6655 - mae: 0.9443 - val_loss: 1.6765 - val_mae: 0.9653\n",
      "Epoch 10/200\n",
      "39/39 - 0s - loss: 1.5636 - mae: 0.9131 - val_loss: 1.5845 - val_mae: 0.9367\n",
      "Epoch 11/200\n",
      "39/39 - 0s - loss: 1.4783 - mae: 0.8853 - val_loss: 1.5022 - val_mae: 0.9093\n",
      "Epoch 12/200\n",
      "39/39 - 0s - loss: 1.4066 - mae: 0.8605 - val_loss: 1.4339 - val_mae: 0.8871\n",
      "Epoch 13/200\n",
      "39/39 - 0s - loss: 1.3437 - mae: 0.8394 - val_loss: 1.3761 - val_mae: 0.8679\n",
      "Epoch 14/200\n",
      "39/39 - 0s - loss: 1.2883 - mae: 0.8205 - val_loss: 1.3223 - val_mae: 0.8503\n",
      "Epoch 15/200\n",
      "39/39 - 0s - loss: 1.2387 - mae: 0.8022 - val_loss: 1.2752 - val_mae: 0.8343\n",
      "Epoch 16/200\n",
      "39/39 - 0s - loss: 1.1952 - mae: 0.7870 - val_loss: 1.2348 - val_mae: 0.8207\n",
      "Epoch 17/200\n",
      "39/39 - 0s - loss: 1.1563 - mae: 0.7738 - val_loss: 1.1958 - val_mae: 0.8067\n",
      "Epoch 18/200\n",
      "39/39 - 0s - loss: 1.1201 - mae: 0.7597 - val_loss: 1.1587 - val_mae: 0.7932\n",
      "Epoch 19/200\n",
      "39/39 - 0s - loss: 1.0857 - mae: 0.7485 - val_loss: 1.1227 - val_mae: 0.7795\n",
      "Epoch 20/200\n",
      "39/39 - 0s - loss: 1.0561 - mae: 0.7372 - val_loss: 1.0947 - val_mae: 0.7691\n",
      "Epoch 21/200\n",
      "39/39 - 0s - loss: 1.0260 - mae: 0.7264 - val_loss: 1.0651 - val_mae: 0.7568\n",
      "Epoch 22/200\n",
      "39/39 - 0s - loss: 1.0002 - mae: 0.7174 - val_loss: 1.0370 - val_mae: 0.7449\n",
      "Epoch 23/200\n",
      "39/39 - 0s - loss: 0.9755 - mae: 0.7071 - val_loss: 1.0163 - val_mae: 0.7364\n",
      "Epoch 24/200\n",
      "39/39 - 0s - loss: 0.9524 - mae: 0.7003 - val_loss: 0.9904 - val_mae: 0.7252\n",
      "Epoch 25/200\n",
      "39/39 - 0s - loss: 0.9298 - mae: 0.6912 - val_loss: 0.9744 - val_mae: 0.7195\n",
      "Epoch 26/200\n",
      "39/39 - 0s - loss: 0.9094 - mae: 0.6835 - val_loss: 0.9521 - val_mae: 0.7098\n",
      "Epoch 27/200\n",
      "39/39 - 0s - loss: 0.8915 - mae: 0.6767 - val_loss: 0.9321 - val_mae: 0.7004\n",
      "Epoch 28/200\n",
      "39/39 - 0s - loss: 0.8733 - mae: 0.6702 - val_loss: 0.9208 - val_mae: 0.6973\n",
      "Epoch 29/200\n",
      "39/39 - 0s - loss: 0.8580 - mae: 0.6640 - val_loss: 0.9013 - val_mae: 0.6876\n",
      "Epoch 30/200\n",
      "39/39 - 0s - loss: 0.8429 - mae: 0.6582 - val_loss: 0.8881 - val_mae: 0.6842\n",
      "Epoch 31/200\n",
      "39/39 - 0s - loss: 0.8270 - mae: 0.6530 - val_loss: 0.8721 - val_mae: 0.6760\n",
      "Epoch 32/200\n",
      "39/39 - 0s - loss: 0.8149 - mae: 0.6481 - val_loss: 0.8584 - val_mae: 0.6701\n",
      "Epoch 33/200\n",
      "39/39 - 0s - loss: 0.8014 - mae: 0.6431 - val_loss: 0.8457 - val_mae: 0.6648\n",
      "Epoch 34/200\n",
      "39/39 - 0s - loss: 0.7886 - mae: 0.6378 - val_loss: 0.8337 - val_mae: 0.6623\n",
      "Epoch 35/200\n",
      "39/39 - 0s - loss: 0.7772 - mae: 0.6336 - val_loss: 0.8198 - val_mae: 0.6561\n",
      "Epoch 36/200\n",
      "39/39 - 0s - loss: 0.7660 - mae: 0.6288 - val_loss: 0.8121 - val_mae: 0.6538\n",
      "Epoch 37/200\n",
      "39/39 - 0s - loss: 0.7562 - mae: 0.6258 - val_loss: 0.8000 - val_mae: 0.6479\n",
      "Epoch 38/200\n",
      "39/39 - 0s - loss: 0.7478 - mae: 0.6234 - val_loss: 0.7888 - val_mae: 0.6421\n",
      "Epoch 39/200\n",
      "39/39 - 0s - loss: 0.7353 - mae: 0.6167 - val_loss: 0.7801 - val_mae: 0.6398\n",
      "Epoch 40/200\n",
      "39/39 - 0s - loss: 0.7262 - mae: 0.6137 - val_loss: 0.7718 - val_mae: 0.6361\n",
      "Epoch 41/200\n",
      "39/39 - 0s - loss: 0.7181 - mae: 0.6110 - val_loss: 0.7646 - val_mae: 0.6329\n",
      "Epoch 42/200\n",
      "39/39 - 0s - loss: 0.7100 - mae: 0.6079 - val_loss: 0.7573 - val_mae: 0.6296\n",
      "Epoch 43/200\n",
      "39/39 - 0s - loss: 0.7028 - mae: 0.6052 - val_loss: 0.7476 - val_mae: 0.6253\n",
      "Epoch 44/200\n",
      "39/39 - 0s - loss: 0.6957 - mae: 0.6023 - val_loss: 0.7416 - val_mae: 0.6243\n",
      "Epoch 45/200\n",
      "39/39 - 0s - loss: 0.6871 - mae: 0.5990 - val_loss: 0.7336 - val_mae: 0.6205\n",
      "Epoch 46/200\n",
      "39/39 - 0s - loss: 0.6806 - mae: 0.5960 - val_loss: 0.7274 - val_mae: 0.6188\n",
      "Epoch 47/200\n",
      "39/39 - 0s - loss: 0.6739 - mae: 0.5941 - val_loss: 0.7216 - val_mae: 0.6158\n",
      "Epoch 48/200\n",
      "39/39 - 0s - loss: 0.6665 - mae: 0.5917 - val_loss: 0.7160 - val_mae: 0.6133\n",
      "Epoch 49/200\n",
      "39/39 - 0s - loss: 0.6621 - mae: 0.5899 - val_loss: 0.7098 - val_mae: 0.6112\n",
      "Epoch 50/200\n",
      "39/39 - 0s - loss: 0.6565 - mae: 0.5885 - val_loss: 0.7065 - val_mae: 0.6097\n",
      "Epoch 51/200\n",
      "39/39 - 0s - loss: 0.6473 - mae: 0.5851 - val_loss: 0.7042 - val_mae: 0.6101\n",
      "Epoch 52/200\n",
      "39/39 - 0s - loss: 0.6413 - mae: 0.5827 - val_loss: 0.6951 - val_mae: 0.6046\n",
      "Epoch 53/200\n",
      "39/39 - 0s - loss: 0.6370 - mae: 0.5809 - val_loss: 0.6912 - val_mae: 0.6042\n",
      "Epoch 54/200\n",
      "39/39 - 0s - loss: 0.6280 - mae: 0.5774 - val_loss: 0.6849 - val_mae: 0.6010\n",
      "Epoch 55/200\n",
      "39/39 - 0s - loss: 0.6245 - mae: 0.5770 - val_loss: 0.6813 - val_mae: 0.5995\n",
      "Epoch 56/200\n",
      "39/39 - 0s - loss: 0.6184 - mae: 0.5740 - val_loss: 0.6770 - val_mae: 0.5991\n",
      "Epoch 57/200\n",
      "39/39 - 0s - loss: 0.6130 - mae: 0.5730 - val_loss: 0.6725 - val_mae: 0.5974\n",
      "Epoch 58/200\n",
      "39/39 - 0s - loss: 0.6079 - mae: 0.5698 - val_loss: 0.6714 - val_mae: 0.5994\n",
      "Epoch 59/200\n",
      "39/39 - 0s - loss: 0.6038 - mae: 0.5686 - val_loss: 0.6648 - val_mae: 0.5946\n",
      "Epoch 60/200\n",
      "39/39 - 0s - loss: 0.5988 - mae: 0.5672 - val_loss: 0.6606 - val_mae: 0.5931\n",
      "Epoch 61/200\n",
      "39/39 - 0s - loss: 0.5942 - mae: 0.5657 - val_loss: 0.6577 - val_mae: 0.5923\n",
      "Epoch 62/200\n",
      "39/39 - 0s - loss: 0.5894 - mae: 0.5628 - val_loss: 0.6517 - val_mae: 0.5910\n",
      "Epoch 63/200\n",
      "39/39 - 0s - loss: 0.5889 - mae: 0.5631 - val_loss: 0.6488 - val_mae: 0.5876\n",
      "Epoch 64/200\n",
      "39/39 - 0s - loss: 0.5841 - mae: 0.5609 - val_loss: 0.6460 - val_mae: 0.5879\n",
      "Epoch 65/200\n",
      "39/39 - 0s - loss: 0.5772 - mae: 0.5584 - val_loss: 0.6399 - val_mae: 0.5839\n",
      "Epoch 66/200\n",
      "39/39 - 0s - loss: 0.5828 - mae: 0.5625 - val_loss: 0.6442 - val_mae: 0.5883\n",
      "Epoch 67/200\n",
      "39/39 - 0s - loss: 0.5733 - mae: 0.5572 - val_loss: 0.6369 - val_mae: 0.5846\n",
      "Epoch 68/200\n",
      "39/39 - 0s - loss: 0.5688 - mae: 0.5558 - val_loss: 0.6334 - val_mae: 0.5834\n",
      "Epoch 69/200\n",
      "39/39 - 0s - loss: 0.5654 - mae: 0.5543 - val_loss: 0.6276 - val_mae: 0.5800\n",
      "Epoch 70/200\n",
      "39/39 - 0s - loss: 0.5609 - mae: 0.5516 - val_loss: 0.6268 - val_mae: 0.5807\n",
      "Epoch 71/200\n",
      "39/39 - 0s - loss: 0.5599 - mae: 0.5510 - val_loss: 0.6208 - val_mae: 0.5780\n",
      "Epoch 72/200\n",
      "39/39 - 0s - loss: 0.5567 - mae: 0.5499 - val_loss: 0.6209 - val_mae: 0.5794\n",
      "Epoch 73/200\n",
      "39/39 - 0s - loss: 0.5552 - mae: 0.5504 - val_loss: 0.6181 - val_mae: 0.5780\n",
      "Epoch 74/200\n",
      "39/39 - 0s - loss: 0.5507 - mae: 0.5483 - val_loss: 0.6152 - val_mae: 0.5769\n",
      "Epoch 75/200\n",
      "39/39 - 0s - loss: 0.5497 - mae: 0.5482 - val_loss: 0.6163 - val_mae: 0.5790\n",
      "Epoch 76/200\n",
      "39/39 - 0s - loss: 0.5467 - mae: 0.5465 - val_loss: 0.6096 - val_mae: 0.5747\n",
      "Epoch 77/200\n",
      "39/39 - 0s - loss: 0.5447 - mae: 0.5453 - val_loss: 0.6093 - val_mae: 0.5748\n",
      "Epoch 78/200\n",
      "39/39 - 0s - loss: 0.5459 - mae: 0.5479 - val_loss: 0.6065 - val_mae: 0.5738\n",
      "Epoch 79/200\n",
      "39/39 - 0s - loss: 0.5418 - mae: 0.5453 - val_loss: 0.6068 - val_mae: 0.5746\n",
      "Epoch 80/200\n",
      "39/39 - 0s - loss: 0.5387 - mae: 0.5438 - val_loss: 0.6024 - val_mae: 0.5719\n",
      "Epoch 81/200\n",
      "39/39 - 0s - loss: 0.5367 - mae: 0.5432 - val_loss: 0.5996 - val_mae: 0.5704\n",
      "Epoch 82/200\n",
      "39/39 - 0s - loss: 0.5360 - mae: 0.5428 - val_loss: 0.6012 - val_mae: 0.5716\n",
      "Epoch 83/200\n",
      "39/39 - 0s - loss: 0.5332 - mae: 0.5414 - val_loss: 0.6003 - val_mae: 0.5730\n",
      "Epoch 84/200\n",
      "39/39 - 0s - loss: 0.5333 - mae: 0.5418 - val_loss: 0.6002 - val_mae: 0.5742\n",
      "Epoch 85/200\n",
      "39/39 - 0s - loss: 0.5352 - mae: 0.5432 - val_loss: 0.5947 - val_mae: 0.5694\n",
      "Epoch 86/200\n",
      "39/39 - 0s - loss: 0.5299 - mae: 0.5403 - val_loss: 0.5927 - val_mae: 0.5688\n",
      "Epoch 87/200\n",
      "39/39 - 0s - loss: 0.5288 - mae: 0.5409 - val_loss: 0.5916 - val_mae: 0.5677\n",
      "Epoch 88/200\n",
      "39/39 - 0s - loss: 0.5275 - mae: 0.5414 - val_loss: 0.5895 - val_mae: 0.5678\n",
      "Epoch 89/200\n",
      "39/39 - 0s - loss: 0.5253 - mae: 0.5404 - val_loss: 0.5881 - val_mae: 0.5666\n",
      "Epoch 90/200\n",
      "39/39 - 0s - loss: 0.5234 - mae: 0.5391 - val_loss: 0.5863 - val_mae: 0.5656\n",
      "Epoch 91/200\n",
      "39/39 - 0s - loss: 0.5226 - mae: 0.5394 - val_loss: 0.5873 - val_mae: 0.5665\n",
      "Epoch 92/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 - 0s - loss: 0.5211 - mae: 0.5388 - val_loss: 0.5845 - val_mae: 0.5652\n",
      "Epoch 93/200\n",
      "39/39 - 0s - loss: 0.5225 - mae: 0.5401 - val_loss: 0.5827 - val_mae: 0.5656\n",
      "Epoch 94/200\n",
      "39/39 - 0s - loss: 0.5200 - mae: 0.5388 - val_loss: 0.5820 - val_mae: 0.5655\n",
      "Epoch 95/200\n",
      "39/39 - 0s - loss: 0.5195 - mae: 0.5370 - val_loss: 0.5802 - val_mae: 0.5639\n",
      "Epoch 96/200\n",
      "39/39 - 0s - loss: 0.5173 - mae: 0.5373 - val_loss: 0.5785 - val_mae: 0.5628\n",
      "Epoch 97/200\n",
      "39/39 - 0s - loss: 0.5166 - mae: 0.5378 - val_loss: 0.5802 - val_mae: 0.5665\n",
      "Epoch 98/200\n",
      "39/39 - 0s - loss: 0.5161 - mae: 0.5375 - val_loss: 0.5756 - val_mae: 0.5628\n",
      "Epoch 99/200\n",
      "39/39 - 0s - loss: 0.5142 - mae: 0.5355 - val_loss: 0.5779 - val_mae: 0.5632\n",
      "Epoch 100/200\n",
      "39/39 - 0s - loss: 0.5136 - mae: 0.5365 - val_loss: 0.5772 - val_mae: 0.5650\n",
      "Epoch 101/200\n",
      "39/39 - 0s - loss: 0.5133 - mae: 0.5378 - val_loss: 0.5776 - val_mae: 0.5649\n",
      "Epoch 102/200\n",
      "39/39 - 0s - loss: 0.5116 - mae: 0.5358 - val_loss: 0.5734 - val_mae: 0.5627\n",
      "Epoch 103/200\n",
      "39/39 - 0s - loss: 0.5100 - mae: 0.5349 - val_loss: 0.5740 - val_mae: 0.5630\n",
      "Epoch 104/200\n",
      "39/39 - 0s - loss: 0.5091 - mae: 0.5347 - val_loss: 0.5709 - val_mae: 0.5619\n",
      "Epoch 105/200\n",
      "39/39 - 0s - loss: 0.5092 - mae: 0.5346 - val_loss: 0.5739 - val_mae: 0.5616\n",
      "Epoch 106/200\n",
      "39/39 - 0s - loss: 0.5092 - mae: 0.5354 - val_loss: 0.5724 - val_mae: 0.5632\n",
      "Epoch 107/200\n",
      "39/39 - 0s - loss: 0.5089 - mae: 0.5353 - val_loss: 0.5707 - val_mae: 0.5639\n",
      "Epoch 108/200\n",
      "39/39 - 0s - loss: 0.5095 - mae: 0.5363 - val_loss: 0.5688 - val_mae: 0.5622\n",
      "Epoch 109/200\n",
      "39/39 - 0s - loss: 0.5084 - mae: 0.5359 - val_loss: 0.5677 - val_mae: 0.5604\n",
      "Epoch 110/200\n",
      "39/39 - 0s - loss: 0.5044 - mae: 0.5330 - val_loss: 0.5670 - val_mae: 0.5618\n",
      "Epoch 111/200\n",
      "39/39 - 0s - loss: 0.5048 - mae: 0.5341 - val_loss: 0.5664 - val_mae: 0.5609\n",
      "Epoch 112/200\n",
      "39/39 - 0s - loss: 0.5039 - mae: 0.5336 - val_loss: 0.5653 - val_mae: 0.5614\n",
      "Epoch 113/200\n",
      "39/39 - 0s - loss: 0.5032 - mae: 0.5343 - val_loss: 0.5661 - val_mae: 0.5611\n",
      "Epoch 114/200\n",
      "39/39 - 0s - loss: 0.5027 - mae: 0.5322 - val_loss: 0.5663 - val_mae: 0.5625\n",
      "Epoch 115/200\n",
      "39/39 - 0s - loss: 0.5039 - mae: 0.5334 - val_loss: 0.5654 - val_mae: 0.5613\n",
      "Epoch 116/200\n",
      "39/39 - 0s - loss: 0.4988 - mae: 0.5305 - val_loss: 0.5632 - val_mae: 0.5606\n",
      "Epoch 117/200\n",
      "39/39 - 0s - loss: 0.5036 - mae: 0.5338 - val_loss: 0.5663 - val_mae: 0.5648\n",
      "Epoch 118/200\n",
      "39/39 - 0s - loss: 0.4995 - mae: 0.5322 - val_loss: 0.5611 - val_mae: 0.5593\n",
      "Epoch 119/200\n",
      "39/39 - 0s - loss: 0.4977 - mae: 0.5305 - val_loss: 0.5626 - val_mae: 0.5614\n",
      "Epoch 120/200\n",
      "39/39 - 0s - loss: 0.4976 - mae: 0.5306 - val_loss: 0.5610 - val_mae: 0.5586\n",
      "Epoch 121/200\n",
      "39/39 - 0s - loss: 0.4977 - mae: 0.5304 - val_loss: 0.5587 - val_mae: 0.5588\n",
      "Epoch 122/200\n",
      "39/39 - 0s - loss: 0.4944 - mae: 0.5285 - val_loss: 0.5621 - val_mae: 0.5629\n",
      "Epoch 123/200\n",
      "39/39 - 0s - loss: 0.4988 - mae: 0.5320 - val_loss: 0.5642 - val_mae: 0.5624\n",
      "Epoch 124/200\n",
      "39/39 - 0s - loss: 0.4976 - mae: 0.5317 - val_loss: 0.5593 - val_mae: 0.5626\n",
      "Epoch 125/200\n",
      "39/39 - 0s - loss: 0.4947 - mae: 0.5309 - val_loss: 0.5545 - val_mae: 0.5593\n",
      "Epoch 126/200\n",
      "39/39 - 0s - loss: 0.4943 - mae: 0.5305 - val_loss: 0.5639 - val_mae: 0.5653\n",
      "Epoch 127/200\n",
      "39/39 - 0s - loss: 0.5045 - mae: 0.5375 - val_loss: 0.5614 - val_mae: 0.5642\n",
      "Epoch 128/200\n",
      "39/39 - 0s - loss: 0.4951 - mae: 0.5304 - val_loss: 0.5526 - val_mae: 0.5582\n",
      "Epoch 129/200\n",
      "39/39 - 0s - loss: 0.4936 - mae: 0.5295 - val_loss: 0.5566 - val_mae: 0.5607\n",
      "Epoch 130/200\n",
      "39/39 - 0s - loss: 0.4917 - mae: 0.5291 - val_loss: 0.5511 - val_mae: 0.5584\n",
      "Epoch 131/200\n",
      "39/39 - 0s - loss: 0.4921 - mae: 0.5290 - val_loss: 0.5543 - val_mae: 0.5601\n",
      "Epoch 132/200\n",
      "39/39 - 0s - loss: 0.4918 - mae: 0.5298 - val_loss: 0.5538 - val_mae: 0.5614\n",
      "Epoch 133/200\n",
      "39/39 - 0s - loss: 0.4935 - mae: 0.5314 - val_loss: 0.5515 - val_mae: 0.5578\n",
      "Epoch 134/200\n",
      "39/39 - 0s - loss: 0.4916 - mae: 0.5287 - val_loss: 0.5548 - val_mae: 0.5593\n",
      "Epoch 135/200\n",
      "39/39 - 0s - loss: 0.4917 - mae: 0.5297 - val_loss: 0.5532 - val_mae: 0.5603\n",
      "Epoch 136/200\n",
      "39/39 - 0s - loss: 0.4901 - mae: 0.5286 - val_loss: 0.5523 - val_mae: 0.5596\n",
      "Epoch 137/200\n",
      "39/39 - 0s - loss: 0.4880 - mae: 0.5271 - val_loss: 0.5516 - val_mae: 0.5588\n",
      "Epoch 138/200\n",
      "39/39 - 0s - loss: 0.4908 - mae: 0.5307 - val_loss: 0.5524 - val_mae: 0.5620\n",
      "Epoch 139/200\n",
      "39/39 - 0s - loss: 0.4883 - mae: 0.5288 - val_loss: 0.5508 - val_mae: 0.5574\n",
      "Epoch 140/200\n",
      "39/39 - 0s - loss: 0.4888 - mae: 0.5276 - val_loss: 0.5532 - val_mae: 0.5620\n",
      "Epoch 141/200\n",
      "39/39 - 0s - loss: 0.4882 - mae: 0.5279 - val_loss: 0.5518 - val_mae: 0.5593\n",
      "Epoch 142/200\n",
      "39/39 - 0s - loss: 0.4861 - mae: 0.5270 - val_loss: 0.5499 - val_mae: 0.5596\n",
      "Epoch 143/200\n",
      "39/39 - 0s - loss: 0.4883 - mae: 0.5282 - val_loss: 0.5550 - val_mae: 0.5636\n",
      "Epoch 144/200\n",
      "39/39 - 0s - loss: 0.4888 - mae: 0.5286 - val_loss: 0.5471 - val_mae: 0.5588\n",
      "Epoch 145/200\n",
      "39/39 - 0s - loss: 0.4882 - mae: 0.5292 - val_loss: 0.5491 - val_mae: 0.5600\n",
      "Epoch 146/200\n",
      "39/39 - 0s - loss: 0.4868 - mae: 0.5279 - val_loss: 0.5529 - val_mae: 0.5586\n",
      "Epoch 147/200\n",
      "39/39 - 0s - loss: 0.4878 - mae: 0.5276 - val_loss: 0.5493 - val_mae: 0.5610\n",
      "Epoch 148/200\n",
      "39/39 - 0s - loss: 0.4885 - mae: 0.5287 - val_loss: 0.5455 - val_mae: 0.5559\n",
      "Epoch 149/200\n",
      "39/39 - 0s - loss: 0.4872 - mae: 0.5280 - val_loss: 0.5452 - val_mae: 0.5575\n",
      "Epoch 150/200\n",
      "39/39 - 0s - loss: 0.4844 - mae: 0.5271 - val_loss: 0.5512 - val_mae: 0.5624\n",
      "Epoch 151/200\n",
      "39/39 - 0s - loss: 0.4833 - mae: 0.5259 - val_loss: 0.5492 - val_mae: 0.5621\n",
      "Epoch 152/200\n",
      "39/39 - 0s - loss: 0.4842 - mae: 0.5269 - val_loss: 0.5463 - val_mae: 0.5588\n",
      "Epoch 153/200\n",
      "39/39 - 0s - loss: 0.4848 - mae: 0.5273 - val_loss: 0.5480 - val_mae: 0.5571\n",
      "Epoch 154/200\n",
      "39/39 - 0s - loss: 0.4826 - mae: 0.5253 - val_loss: 0.5473 - val_mae: 0.5608\n",
      "Epoch 155/200\n",
      "39/39 - 0s - loss: 0.4835 - mae: 0.5273 - val_loss: 0.5451 - val_mae: 0.5551\n",
      "Epoch 156/200\n",
      "39/39 - 0s - loss: 0.4835 - mae: 0.5256 - val_loss: 0.5453 - val_mae: 0.5596\n",
      "Epoch 157/200\n",
      "39/39 - 0s - loss: 0.4829 - mae: 0.5277 - val_loss: 0.5425 - val_mae: 0.5574\n",
      "Epoch 158/200\n",
      "39/39 - 0s - loss: 0.4823 - mae: 0.5252 - val_loss: 0.5487 - val_mae: 0.5618\n",
      "Epoch 159/200\n",
      "39/39 - 0s - loss: 0.4809 - mae: 0.5260 - val_loss: 0.5456 - val_mae: 0.5607\n",
      "Epoch 160/200\n",
      "39/39 - 0s - loss: 0.4822 - mae: 0.5265 - val_loss: 0.5482 - val_mae: 0.5589\n",
      "Epoch 161/200\n",
      "39/39 - 0s - loss: 0.4795 - mae: 0.5254 - val_loss: 0.5448 - val_mae: 0.5563\n",
      "Epoch 162/200\n",
      "39/39 - 0s - loss: 0.4815 - mae: 0.5258 - val_loss: 0.5421 - val_mae: 0.5559\n",
      "Epoch 163/200\n",
      "39/39 - 0s - loss: 0.4785 - mae: 0.5246 - val_loss: 0.5436 - val_mae: 0.5554\n",
      "Epoch 164/200\n",
      "39/39 - 0s - loss: 0.4796 - mae: 0.5256 - val_loss: 0.5445 - val_mae: 0.5554\n",
      "Epoch 165/200\n",
      "39/39 - 0s - loss: 0.4797 - mae: 0.5250 - val_loss: 0.5426 - val_mae: 0.5554\n",
      "Epoch 166/200\n",
      "39/39 - 0s - loss: 0.4801 - mae: 0.5261 - val_loss: 0.5422 - val_mae: 0.5571\n",
      "Epoch 167/200\n",
      "39/39 - 0s - loss: 0.4789 - mae: 0.5240 - val_loss: 0.5432 - val_mae: 0.5573\n",
      "Epoch 168/200\n",
      "39/39 - 0s - loss: 0.4778 - mae: 0.5239 - val_loss: 0.5450 - val_mae: 0.5584\n",
      "Epoch 169/200\n",
      "39/39 - 0s - loss: 0.4771 - mae: 0.5246 - val_loss: 0.5482 - val_mae: 0.5606\n",
      "Epoch 170/200\n",
      "39/39 - 0s - loss: 0.4765 - mae: 0.5242 - val_loss: 0.5426 - val_mae: 0.5577\n",
      "Epoch 171/200\n",
      "39/39 - 0s - loss: 0.4775 - mae: 0.5251 - val_loss: 0.5520 - val_mae: 0.5679\n",
      "Epoch 172/200\n",
      "39/39 - 0s - loss: 0.4758 - mae: 0.5240 - val_loss: 0.5491 - val_mae: 0.5654\n",
      "Epoch 173/200\n",
      "39/39 - 0s - loss: 0.4785 - mae: 0.5249 - val_loss: 0.5440 - val_mae: 0.5593\n",
      "Epoch 174/200\n",
      "39/39 - 0s - loss: 0.4760 - mae: 0.5237 - val_loss: 0.5510 - val_mae: 0.5646\n",
      "Epoch 175/200\n",
      "39/39 - 0s - loss: 0.4768 - mae: 0.5247 - val_loss: 0.5411 - val_mae: 0.5575\n",
      "Epoch 176/200\n",
      "39/39 - 0s - loss: 0.4792 - mae: 0.5254 - val_loss: 0.5414 - val_mae: 0.5561\n",
      "Epoch 177/200\n",
      "39/39 - 0s - loss: 0.4792 - mae: 0.5263 - val_loss: 0.5404 - val_mae: 0.5562\n",
      "Epoch 178/200\n",
      "39/39 - 0s - loss: 0.4748 - mae: 0.5233 - val_loss: 0.5431 - val_mae: 0.5578\n",
      "Epoch 179/200\n",
      "39/39 - 0s - loss: 0.4749 - mae: 0.5235 - val_loss: 0.5465 - val_mae: 0.5599\n",
      "Epoch 180/200\n",
      "39/39 - 0s - loss: 0.4733 - mae: 0.5230 - val_loss: 0.5465 - val_mae: 0.5626\n",
      "Epoch 181/200\n",
      "39/39 - 0s - loss: 0.4738 - mae: 0.5233 - val_loss: 0.5418 - val_mae: 0.5587\n",
      "Epoch 182/200\n",
      "39/39 - 0s - loss: 0.4717 - mae: 0.5231 - val_loss: 0.5409 - val_mae: 0.5564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200\n",
      "39/39 - 0s - loss: 0.4753 - mae: 0.5254 - val_loss: 0.5424 - val_mae: 0.5613\n",
      "Epoch 184/200\n",
      "39/39 - 0s - loss: 0.4728 - mae: 0.5228 - val_loss: 0.5502 - val_mae: 0.5651\n",
      "Epoch 185/200\n",
      "39/39 - 0s - loss: 0.4723 - mae: 0.5223 - val_loss: 0.5433 - val_mae: 0.5598\n",
      "Epoch 186/200\n",
      "39/39 - 0s - loss: 0.4769 - mae: 0.5263 - val_loss: 0.5453 - val_mae: 0.5598\n",
      "Epoch 187/200\n",
      "39/39 - 0s - loss: 0.4739 - mae: 0.5238 - val_loss: 0.5520 - val_mae: 0.5682\n",
      "Epoch 188/200\n",
      "39/39 - 0s - loss: 0.4730 - mae: 0.5234 - val_loss: 0.5437 - val_mae: 0.5612\n",
      "Epoch 189/200\n",
      "39/39 - 0s - loss: 0.4727 - mae: 0.5243 - val_loss: 0.5401 - val_mae: 0.5568\n",
      "Epoch 190/200\n",
      "39/39 - 0s - loss: 0.4704 - mae: 0.5211 - val_loss: 0.5413 - val_mae: 0.5602\n",
      "Epoch 191/200\n",
      "39/39 - 0s - loss: 0.4740 - mae: 0.5246 - val_loss: 0.5398 - val_mae: 0.5605\n",
      "Epoch 192/200\n",
      "39/39 - 0s - loss: 0.4709 - mae: 0.5222 - val_loss: 0.5422 - val_mae: 0.5577\n",
      "Epoch 193/200\n",
      "39/39 - 0s - loss: 0.4707 - mae: 0.5212 - val_loss: 0.5398 - val_mae: 0.5598\n",
      "Epoch 194/200\n",
      "39/39 - 0s - loss: 0.4692 - mae: 0.5218 - val_loss: 0.5418 - val_mae: 0.5558\n",
      "Epoch 195/200\n",
      "39/39 - 0s - loss: 0.4713 - mae: 0.5240 - val_loss: 0.5389 - val_mae: 0.5568\n",
      "Epoch 196/200\n",
      "39/39 - 0s - loss: 0.4701 - mae: 0.5222 - val_loss: 0.5396 - val_mae: 0.5582\n",
      "Epoch 197/200\n",
      "39/39 - 0s - loss: 0.4766 - mae: 0.5255 - val_loss: 0.5463 - val_mae: 0.5664\n",
      "Epoch 198/200\n",
      "39/39 - 0s - loss: 0.4713 - mae: 0.5237 - val_loss: 0.5385 - val_mae: 0.5570\n",
      "Epoch 199/200\n",
      "39/39 - 0s - loss: 0.4702 - mae: 0.5227 - val_loss: 0.5407 - val_mae: 0.5609\n",
      "Epoch 200/200\n",
      "39/39 - 0s - loss: 0.4728 - mae: 0.5264 - val_loss: 0.5390 - val_mae: 0.5578\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=200, \n",
    "                    batch_size=128, \n",
    "                    verbose=2, \n",
    "                    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 861us/step - loss: 0.4974 - mae: 0.5362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc83c6a59a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_trans, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 - 0s - loss: 0.5558 - mae: 0.5625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5558327436447144, 0.5624934434890747]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test,y_test,batch_size=42,verbose=2)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.title('Loss / Mean Squared Error')\n",
    "pyplot.plot(history.history['loss'], label='train_loss')\n",
    "pyplot.plot(history.history['val_loss'], label='train_val')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       ...,\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1779    6\n",
       "5570    6\n",
       "5178    7\n",
       "4572    6\n",
       "4264    5\n",
       "       ..\n",
       "662     6\n",
       "1044    6\n",
       "579     6\n",
       "2033    8\n",
       "6405    6\n",
       "Name: quality, Length: 1625, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24055219230188107"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score(y_test,y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.624"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2171368517475034"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_nn =  pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_nn['error'] = ('mse', 'r2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_nn['Full_NN'] = (0.57,0.28) \n",
    "df_score_nn['NN_redwine'] = (0.60,0.13) \n",
    "df_score_nn['NN_whitewine'] = (0.75,0.09) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>Full_NN</th>\n",
       "      <th>NN_redwine</th>\n",
       "      <th>NN_whitewine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  error  Full_NN  NN_redwine  NN_whitewine\n",
       "0   mse     0.57        0.60          0.75\n",
       "1    r2     0.28        0.13          0.09"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
